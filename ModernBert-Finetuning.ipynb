{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e919215-3e53-43c3-99f2-9ddc94a6cdf5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-26T12:30:48.359760Z",
     "iopub.status.busy": "2025-06-26T12:30:48.359473Z",
     "iopub.status.idle": "2025-06-26T12:30:48.603992Z",
     "shell.execute_reply": "2025-06-26T12:30:48.603001Z",
     "shell.execute_reply.started": "2025-06-26T12:30:48.359738Z"
    }
   },
   "source": [
    "# Finetune-ModenBert-For-Intent-Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480c5341-62a7-4fd1-a4cb-eb2c897dfb8a",
   "metadata": {},
   "source": [
    "The recent high-profile advances in LLMs have been in models like GPT, Llama, and Claude. Yet compact, task-specific models continue to play a vital role, especially for classification purposes when building practical and economical AI solutions. One key use case in modern applications is a Router Agent. A Router is a model that classifies user prompt ('intent') and forwards it to to the most appropriate Sub-Agent for handling. Smaller Models are very good fit for usecases where fast, accurate classification is essential.\n",
    "\n",
    "I'll show you how to customize ModernBERT for classifying user queries to create a smart LLM routing system. As an enhanced iteration of BERT technology, ModernBERT offers expanded context capacity of 8192 tokens, superior performance on tasks, and enhanced processing efficiency.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc674ff-ede3-4f62-9baf-c2de93b7c5c7",
   "metadata": {},
   "source": [
    "**A Brief Look at ModernBERT**\n",
    "\n",
    "ModernBERT represents a significant advancement in encoder model technology, offering full backwards compatibility while introducing several major architectural improvements over the original BERT. The model comes in two variations:\n",
    "\n",
    "    ModernBERT Base (149M parameters)\n",
    "    ModernBERT Large (395M parameters)\n",
    "\n",
    "Key Technical Innovations:\n",
    "- Rotary Positional Embeddings (RoPE) replace traditional positional encodings, enabling better understanding of word relationships and supporting longer sequences\n",
    "- Alternating Attention patterns that combine global and local attention every 3 layers, significantly improving processing efficiency\n",
    "- GeGLU layers replace traditional MLP layers, enhancing the original BERT's GeLU activation function\n",
    "- Streamlined architecture with removed bias terms for more efficient parameter usage\n",
    "- Additional normalization layer after embeddings for improved training stability\n",
    "- Advanced sequence packing and unpadding techniques that reduce computational waste\n",
    "- Hardware-optimized design that better aligns with modern GPU architectures\n",
    "\n",
    "The model sets new performance standards in classification, retrieval, and code comprehension tasks, operating 2-4 times faster than previous encoders. This combination of speed and accuracy makes it ideal for high-volume production applications such as LLM routing, where both performance metrics are crucial.\n",
    "\n",
    "What sets ModernBERT apart is its extensive training on 2 trillion tokens from diverse sources, including web content, programming code, and academic literature. This broad training foundation - significantly more varied than traditional BERT models' Wikipedia-centric approach - enables better understanding of user inputs across multiple domains. The model also features an impressive 8,192 token context length, which is 16 times larger than most existing encoders.\n",
    "\n",
    "For detailed information about ModernBERT's architecture and development, you can find documentation on the [Hugging Face hub](https://huggingface.co/blog/modernbert)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a162c8c-beba-4b69-89d4-dd240b1489f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-04T15:49:30.232045Z",
     "iopub.status.busy": "2025-08-04T15:49:30.231704Z",
     "iopub.status.idle": "2025-08-04T15:49:30.235499Z",
     "shell.execute_reply": "2025-08-04T15:49:30.234404Z",
     "shell.execute_reply.started": "2025-08-04T15:49:30.232021Z"
    }
   },
   "outputs": [],
   "source": [
    "# Install libraries\n",
    "# %pip install torch==2.6.0\n",
    "# %pip install -r requirements.txt\n",
    "# %pip install -U sagemaker awscli -q 2>&1 | grep -v \"warnings/venv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd43949d-0fae-4066-9b22-866327d9b84e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-04T15:49:31.149426Z",
     "iopub.status.busy": "2025-08-04T15:49:31.148663Z",
     "iopub.status.idle": "2025-08-04T15:49:36.754875Z",
     "shell.execute_reply": "2025-08-04T15:49:36.754173Z",
     "shell.execute_reply.started": "2025-08-04T15:49:31.149398Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.7.1+cu126'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d96d366f-8d3a-4dbb-99f4-c4c80db83768",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-04T15:49:38.807702Z",
     "iopub.status.busy": "2025-08-04T15:49:38.807253Z",
     "iopub.status.idle": "2025-08-04T15:49:42.773921Z",
     "shell.execute_reply": "2025-08-04T15:49:42.773027Z",
     "shell.execute_reply.started": "2025-08-04T15:49:38.807678Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "us-east-2\n",
      "sagemaker-us-east-2-207567795090\n",
      "arn:aws:iam::207567795090:role/service-role/AmazonSageMaker-ExecutionRole-20250620T155960\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import logging\n",
    "sagemaker_config_logger = logging.getLogger(\"sagemaker.config\")\n",
    "sagemaker_config_logger.setLevel(logging.WARNING)\n",
    "\n",
    "# Import SageMaker SDK, setup our session\n",
    "from sagemaker import get_execution_role, Session\n",
    "from sagemaker.pytorch import PyTorch\n",
    "import boto3\n",
    "\n",
    "sess = Session(boto_session=boto3.Session())\n",
    "default_bucket = sess.default_bucket()\n",
    "\n",
    "print(sess.boto_region_name)\n",
    "print(default_bucket)\n",
    "print(get_execution_role())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6612e0a2-c2a4-4224-99f4-8fa7f4793eb5",
   "metadata": {},
   "source": [
    "# 1. Dataset Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bbaabb5-c346-4e6e-a7f3-e119dd866936",
   "metadata": {},
   "source": [
    "## 1.1 Loading the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ab5d4ec-73f1-4b1f-916a-b102ba3f0d44",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-04T15:49:45.659229Z",
     "iopub.status.busy": "2025-08-04T15:49:45.658683Z",
     "iopub.status.idle": "2025-08-04T15:49:46.924647Z",
     "shell.execute_reply": "2025-08-04T15:49:46.923807Z",
     "shell.execute_reply.started": "2025-08-04T15:49:45.659205Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['instruction', 'intent', 'category', 'tags', 'response'],\n",
       "        num_rows: 31658\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    " \n",
    "# Dataset id from huggingface.co/dataset\n",
    "dataset_id = \"bitext/Bitext-travel-llm-chatbot-training-dataset\"\n",
    " \n",
    "# Load raw dataset\n",
    "raw_dataset = load_dataset(dataset_id)\n",
    "\n",
    "raw_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41cce0f-47d9-474a-9032-bde0487e3d30",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-04T11:50:14.951233Z",
     "iopub.status.busy": "2025-08-04T11:50:14.950942Z",
     "iopub.status.idle": "2025-08-04T11:50:14.954981Z",
     "shell.execute_reply": "2025-08-04T11:50:14.954089Z",
     "shell.execute_reply.started": "2025-08-04T11:50:14.951211Z"
    }
   },
   "source": [
    "## 1.2 Split Dataset into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "533e80ea-54f9-4c5f-861d-c10ab488d0fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-04T15:49:51.199244Z",
     "iopub.status.busy": "2025-08-04T15:49:51.198308Z",
     "iopub.status.idle": "2025-08-04T15:49:51.219684Z",
     "shell.execute_reply": "2025-08-04T15:49:51.218928Z",
     "shell.execute_reply.started": "2025-08-04T15:49:51.199212Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 25326\n",
      "Test set size: 6332\n"
     ]
    }
   ],
   "source": [
    "# Schuffle dataset then split into train and test with 80:20 split\n",
    "split_dataset = raw_dataset['train'].train_test_split(test_size=0.2, shuffle=True, seed=42)\n",
    "    \n",
    "# Create a new dataset dictionary with the splits\n",
    "raw_dataset = DatasetDict({\n",
    "    'train': split_dataset['train'],\n",
    "    'test': split_dataset['test']\n",
    "})\n",
    "\n",
    "\n",
    "# Now you can use dataset['train'] and dataset['test']\n",
    "print(f\"Train set size: {len(raw_dataset['train'])}\")\n",
    "print(f\"Test set size: {len(raw_dataset['test'])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93bf3c90-ee33-4ec1-8b37-8d6d94f2af17",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-04T15:49:52.638805Z",
     "iopub.status.busy": "2025-08-04T15:49:52.638434Z",
     "iopub.status.idle": "2025-08-04T15:49:52.644062Z",
     "shell.execute_reply": "2025-08-04T15:49:52.643114Z",
     "shell.execute_reply.started": "2025-08-04T15:49:52.638780Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['instruction', 'intent', 'category', 'tags', 'response'],\n",
       "        num_rows: 25326\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['instruction', 'intent', 'category', 'tags', 'response'],\n",
       "        num_rows: 6332\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74cfc33d-022b-45a4-b475-bfb7a49eb8b5",
   "metadata": {},
   "source": [
    "## 1.3 Modify column names and remove non-required columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51264e9b-5a70-48a8-9fbf-a27da7a74419",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-04T15:49:57.522722Z",
     "iopub.status.busy": "2025-08-04T15:49:57.522442Z",
     "iopub.status.idle": "2025-08-04T15:50:00.932574Z",
     "shell.execute_reply": "2025-08-04T15:50:00.931835Z",
     "shell.execute_reply.started": "2025-08-04T15:49:57.522702Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61f4468435004715bb4037d9737841da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/25326 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a3577502e3d45739bb04ee6428989c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6332 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Modified Dataset Structure:\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'labels'],\n",
      "        num_rows: 25326\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'labels'],\n",
      "        num_rows: 6332\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Function to modify the dataset\n",
    "def modify_dataset(example):\n",
    "    return {\n",
    "        'text': example['instruction'],  # rename instruction to prompt\n",
    "        'labels': example['category']\n",
    "    }\n",
    "\n",
    "# Apply the transformation to both train and test sets\n",
    "filtered_dataset = raw_dataset.map(modify_dataset, \n",
    "                             remove_columns=['intent', 'instruction', 'category', 'tags', 'response'])\n",
    "\n",
    "print(\"\\nModified Dataset Structure:\")\n",
    "print(filtered_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0484f63-b1bf-450f-a474-0fbf3600fb26",
   "metadata": {},
   "source": [
    "## 3.4 Inspect dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3303fb45-5bce-4d34-a131-664335d4897e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-04T15:50:03.981148Z",
     "iopub.status.busy": "2025-08-04T15:50:03.980776Z",
     "iopub.status.idle": "2025-08-04T15:50:05.690484Z",
     "shell.execute_reply": "2025-08-04T15:50:05.689428Z",
     "shell.execute_reply.started": "2025-08-04T15:50:03.981124Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I want to know more about my flight insurance ...</td>\n",
       "      <td>FLIGHT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i want information about the cancellation char...</td>\n",
       "      <td>CANCELLATION_FEE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id like to check in by phone where could i do it</td>\n",
       "      <td>CHECK_IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I'm looking for a fucking travel insurance, he...</td>\n",
       "      <td>TRIP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>could you help me getting my fucking boarding ...</td>\n",
       "      <td>BOARDING_PASS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text            labels\n",
       "0  I want to know more about my flight insurance ...            FLIGHT\n",
       "1  i want information about the cancellation char...  CANCELLATION_FEE\n",
       "2   id like to check in by phone where could i do it          CHECK_IN\n",
       "3  I'm looking for a fucking travel insurance, he...              TRIP\n",
       "4  could you help me getting my fucking boarding ...     BOARDING_PASS"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Convert to pandas DataFrames\n",
    "train_df = pd.DataFrame(filtered_dataset['train'])\n",
    "test_df = pd.DataFrame(filtered_dataset['test'])\n",
    "\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3013649e-af4b-4c17-ac44-887bb951216c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-04T15:50:51.301901Z",
     "iopub.status.busy": "2025-08-04T15:50:51.301066Z",
     "iopub.status.idle": "2025-08-04T15:50:51.305106Z",
     "shell.execute_reply": "2025-08-04T15:50:51.304377Z",
     "shell.execute_reply.started": "2025-08-04T15:50:51.301870Z"
    }
   },
   "source": [
    "## 3.5 Plot label distribution in train and test datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471d83d8-a9ec-434a-80c4-7fd2e2d63ba3",
   "metadata": {},
   "source": [
    "We notice from the plot below that train and test distributions are quite similar, which is good. However, we also notice a class imbalance where ~70% of the dataset queries are related to FLIGHT and TRIP topics. This is likely to have an adverse impact on the quality of our predictions if not taken into account during training. While in this notebook we will not account for the class imbalance, it's highly advised to check for class imbalance in your dataset and account for it in your loss function.See [here](https://discuss.huggingface.co/t/create-a-weighted-loss-function-to-handle-imbalance/138178) for inspiration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e5e3bec-2159-4d2f-b8ae-90c32ba82dbc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-04T15:50:12.052249Z",
     "iopub.status.busy": "2025-08-04T15:50:12.051769Z",
     "iopub.status.idle": "2025-08-04T15:50:12.407449Z",
     "shell.execute_reply": "2025-08-04T15:50:12.406682Z",
     "shell.execute_reply.started": "2025-08-04T15:50:12.052226Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_category_distribution(train_df, test_df, top_n=10):\n",
    "    # Get category counts and calculate percentages\n",
    "    train_total = len(train_df)\n",
    "    test_total = len(test_df)\n",
    "    train_pct = (train_df['labels'].value_counts() / train_total) * 100\n",
    "    test_pct = (test_df['labels'].value_counts() / test_total) * 100\n",
    "\n",
    "    # Combine percentages\n",
    "    combined_pct = pd.DataFrame({\n",
    "        'Train': train_pct,\n",
    "        'Test': test_pct\n",
    "    }).fillna(0)\n",
    "\n",
    "    # Sort by total percentage and get top N categories\n",
    "    combined_pct['Total'] = combined_pct['Train'] + combined_pct['Test']\n",
    "    top_categories = combined_pct.nlargest(top_n, 'Total')\n",
    "\n",
    "    # Create plot\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    bar_width = 0.35\n",
    "    index = range(len(top_categories))\n",
    "\n",
    "    # Plot bars\n",
    "    train_bars = plt.bar(index, top_categories['Train'], bar_width, label='Train', alpha=0.8)\n",
    "    test_bars = plt.bar([i + bar_width for i in index], top_categories['Test'], bar_width, label='Test', alpha=0.8)\n",
    "\n",
    "    plt.xlabel('Intents')\n",
    "    plt.ylabel('Percentage')\n",
    "    plt.title(f'Top {top_n} Category Distribution (%) in Train and Test Sets')\n",
    "    plt.xticks([i + bar_width/2 for i in index], top_categories.index, rotation=45, ha='right')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Usage\n",
    "plot_category_distribution(train_df, test_df, top_n=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a179a76-a6f9-49a0-9ffd-7ddbc61b0b2b",
   "metadata": {},
   "source": [
    "## 3.6 Plot token counts in train and test datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8a2f45-47b7-4ef5-9f07-ff9cd99daee4",
   "metadata": {},
   "source": [
    "Below, we will look at the number of tokens in our train and test data. This helps us understand the `max_seq_length` expected during training and inference. From the plot below, we see that the largest user prompt in both train and test sets had 36 tokens. This is far below the 8,192 token context length that ModernBERT can handle. If we do not specify the `max_model_length` parameter to our tokenizer, it will assume the worst-case scenario (8192) and will simply use a padding token to fill the remaining space. So even though the input sequence is at most 36 tokens, the tokenizer will pass a vector of size 8192 to the LLM (mostly filled with PAD tokens). This will consume excessive memory during training and inference.\n",
    "\n",
    "To avoid excessive memory use, we will simply set our max context length `max_model_length` to 64. While this is 2x the expected tokens (to be on the safe side), it's still significantly lower than 8192. See section 2.2 where we actually set this hyperparameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7efefac9-417b-4696-8f43-3b09408fb852",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-04T15:51:32.255887Z",
     "iopub.status.busy": "2025-08-04T15:51:32.255519Z",
     "iopub.status.idle": "2025-08-04T15:51:41.077811Z",
     "shell.execute_reply": "2025-08-04T15:51:41.076899Z",
     "shell.execute_reply.started": "2025-08-04T15:51:32.255865Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_id = \"answerdotai/ModernBERT-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "def get_token_lengths(dataset):\n",
    "    lengths = []\n",
    "    for example in dataset['text']:\n",
    "        tokens = tokenizer.encode(example)\n",
    "        lengths.append(len(tokens))\n",
    "    return lengths\n",
    "\n",
    "pd.Series(get_token_lengths(train_df)).plot.hist(label=\"train\")\n",
    "pd.Series(get_token_lengths(test_df)).plot.hist(label=\"test\")\n",
    "plt.legend()\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbbe7c6-0261-4c36-80dc-f329be1ad27e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-04T11:53:03.369987Z",
     "iopub.status.busy": "2025-08-04T11:53:03.368119Z",
     "iopub.status.idle": "2025-08-04T11:53:03.374688Z",
     "shell.execute_reply": "2025-08-04T11:53:03.373194Z",
     "shell.execute_reply.started": "2025-08-04T11:53:03.369899Z"
    }
   },
   "source": [
    "## 3.5 Save dataset to s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0af55394-498e-47dd-9baf-0f72ee7ea293",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-04T15:52:49.866980Z",
     "iopub.status.busy": "2025-08-04T15:52:49.865130Z",
     "iopub.status.idle": "2025-08-04T15:52:50.493888Z",
     "shell.execute_reply": "2025-08-04T15:52:50.492874Z",
     "shell.execute_reply.started": "2025-08-04T15:52:49.866938Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0c739e85dd84112b456f721520abd08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/25326 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6439aa87d57c4425b8e2f5b0a866496d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/6332 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-2-207567795090/datasets/train s3://sagemaker-us-east-2-207567795090/datasets/test\n"
     ]
    }
   ],
   "source": [
    "# Create full S3 paths\n",
    "s3_path_train = f\"s3://{default_bucket}/datasets/train\"\n",
    "s3_path_test = f\"s3://{default_bucket}/datasets/test\"\n",
    "\n",
    "# Save dataset\n",
    "filtered_dataset['train'].save_to_disk(s3_path_train)\n",
    "filtered_dataset['test'].save_to_disk(s3_path_test)\n",
    "\n",
    "print(s3_path_train, s3_path_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38d31af-b60e-4ca1-9fb8-621b9066b9ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f29ec839-26a6-432d-bff4-2670286c9b8f",
   "metadata": {},
   "source": [
    "# 2. Finetune the Model using train dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561588e9-fcb5-4124-8f35-1a1449f13389",
   "metadata": {},
   "source": [
    "# 2.1 Create the training script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e0be3385-0791-4dca-8042-297ed57c722b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-04T16:59:32.740659Z",
     "iopub.status.busy": "2025-08-04T16:59:32.740350Z",
     "iopub.status.idle": "2025-08-04T16:59:32.751822Z",
     "shell.execute_reply": "2025-08-04T16:59:32.750908Z",
     "shell.execute_reply.started": "2025-08-04T16:59:32.740630Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[38;5;28;01mimport\u001b[39;00m sys\n",
       "\u001b[38;5;28;01mimport\u001b[39;00m os\n",
       "\u001b[38;5;28;01mimport\u001b[39;00m random\n",
       "\u001b[38;5;28;01mimport\u001b[39;00m warnings\n",
       "\u001b[38;5;28;01mimport\u001b[39;00m argparse\n",
       "\u001b[38;5;28;01mfrom\u001b[39;00m random \u001b[38;5;28;01mimport\u001b[39;00m randrange\n",
       "\u001b[38;5;28;01mimport\u001b[39;00m os\n",
       "\u001b[38;5;28;01mimport\u001b[39;00m warnings\n",
       "\u001b[38;5;28;01mimport\u001b[39;00m random\n",
       "\u001b[38;5;28;01mimport\u001b[39;00m torch\n",
       "\u001b[38;5;28;01mimport\u001b[39;00m logging\n",
       "\n",
       "\n",
       "\u001b[38;5;28;01mimport\u001b[39;00m numpy \u001b[38;5;28;01mas\u001b[39;00m np\n",
       "\u001b[38;5;28;01mfrom\u001b[39;00m sklearn.metrics \u001b[38;5;28;01mimport\u001b[39;00m f1_score\n",
       "\u001b[38;5;28;01mfrom\u001b[39;00m datasets \u001b[38;5;28;01mimport\u001b[39;00m load_from_disk, Dataset\n",
       "\u001b[38;5;28;01mfrom\u001b[39;00m transformers \u001b[38;5;28;01mimport\u001b[39;00m (\n",
       "    AutoTokenizer, \n",
       "    AutoModelForSequenceClassification, \n",
       "    AutoConfig,\n",
       "    Trainer, \n",
       "    TrainingArguments,\n",
       "    EarlyStoppingCallback,\n",
       "    set_seed\n",
       ")\n",
       "\n",
       "os.environ[\u001b[33m\"TOKENIZERS_PARALLELISM\"\u001b[39m] = \u001b[33m\"false\"\u001b[39m\n",
       "\n",
       "\u001b[38;5;66;03m# Set up logging\u001b[39;00m\n",
       "logger = logging.getLogger(__name__)\n",
       "\n",
       "logging.basicConfig(\n",
       "    level=logging.getLevelName(\u001b[33m\"INFO\"\u001b[39m),\n",
       "    handlers=[logging.StreamHandler(sys.stdout)],\n",
       "    format=\u001b[33m\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\"\u001b[39m,\n",
       ")\n",
       "\n",
       "\u001b[38;5;66;03m# Filter out the specific PyTorch warning about scalar tensors\u001b[39;00m\n",
       "warnings.filterwarnings(\u001b[33m'ignore'\u001b[39m, message=\u001b[33m'Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.'\u001b[39m)\n",
       "\n",
       "\n",
       "\u001b[38;5;28;01mdef\u001b[39;00m set_random_seed(seed=\u001b[32m42\u001b[39m):\n",
       "    \u001b[33m\"\"\"Set random seed for reproducibility.\"\"\"\u001b[39m\n",
       "    random.seed(seed)\n",
       "    np.random.seed(seed)\n",
       "    torch.manual_seed(seed)\n",
       "    torch.cuda.manual_seed_all(seed)\n",
       "    set_seed(seed)  \u001b[38;5;66;03m# transformers library seed\u001b[39;00m\n",
       "\n",
       "    \u001b[38;5;66;03m# Make PyTorch deterministic\u001b[39;00m\n",
       "    torch.backends.cudnn.deterministic = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
       "    torch.backends.cudnn.benchmark = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
       "\n",
       "\n",
       "\u001b[38;5;28;01mdef\u001b[39;00m setup_tokenizer(model_id, model_max_length):\n",
       "    \u001b[33m\"\"\"Initialize and configure the tokenizer.\"\"\"\u001b[39m\n",
       "    tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
       "    tokenizer.model_max_length = model_max_length  \u001b[38;5;66;03m# set max_length for prompts\u001b[39;00m\n",
       "    \u001b[38;5;28;01mreturn\u001b[39;00m tokenizer\n",
       "\n",
       "\u001b[38;5;28;01mdef\u001b[39;00m tokenize_dataset(dataset, tokenizer):\n",
       "    \u001b[33m\"\"\"Tokenize the dataset using the provided tokenizer.\"\"\"\u001b[39m\n",
       "    \u001b[38;5;28;01mdef\u001b[39;00m tokenize_batch(batch):\n",
       "        \u001b[38;5;28;01mreturn\u001b[39;00m tokenizer(batch[\u001b[33m'text'\u001b[39m], padding=\u001b[33m'max_length'\u001b[39m, truncation=\u001b[38;5;28;01mTrue\u001b[39;00m, return_tensors=\u001b[33m\"pt\"\u001b[39m)\n",
       "    \n",
       "    \u001b[38;5;28;01mreturn\u001b[39;00m dataset.map(tokenize_batch, batched=\u001b[38;5;28;01mTrue\u001b[39;00m, remove_columns=[\u001b[33m\"text\"\u001b[39m])\n",
       "\n",
       "\u001b[38;5;28;01mdef\u001b[39;00m setup_model(model_id, num_labels, label2id, id2label, dropout_rate=\u001b[32m0.2\u001b[39m, device=\u001b[33m\"cuda\"\u001b[39m):\n",
       "    \u001b[33m\"\"\"Initialize and configure the model with dropout and other optimizations.\"\"\"\u001b[39m    \n",
       "    \u001b[38;5;66;03m#Get model config first\u001b[39;00m\n",
       "    config = AutoConfig.from_pretrained(\n",
       "        model_id,\n",
       "        num_labels=num_labels,\n",
       "        label2id=label2id,\n",
       "        id2label=id2label,\n",
       "        attention_dropout=dropout_rate,          \u001b[38;5;66;03m# 20% attention dropout\u001b[39;00m\n",
       "        embedding_dropout=dropout_rate,          \u001b[38;5;66;03m# 20% embedding dropout\u001b[39;00m\n",
       "        mlp_dropout=dropout_rate,               \u001b[38;5;66;03m# 20% MLP dropout\u001b[39;00m\n",
       "        classifier_dropout=dropout_rate,\n",
       "        \u001b[38;5;66;03m# problem_type=\"single_label_classification\"\u001b[39;00m\n",
       "    )\n",
       "    \n",
       "    \u001b[38;5;66;03m# Check if Flash Attention is available\u001b[39;00m\n",
       "    \u001b[38;5;28;01mtry\u001b[39;00m:\n",
       "        \u001b[38;5;28;01mfrom\u001b[39;00m flash_attn \u001b[38;5;28;01mimport\u001b[39;00m __version__ \u001b[38;5;28;01mas\u001b[39;00m flash_attn_version\n",
       "        logger.info(f\"Flash Attention version {flash_attn_version} is installed\")\n",
       "        use_flash_attention = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
       "    \u001b[38;5;28;01mexcept\u001b[39;00m ImportError:\n",
       "        logger.error(\u001b[33m\"Flash Attention is not installed. Using standard attention.\"\u001b[39m)\n",
       "        use_flash_attention = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
       "    \n",
       "    \u001b[38;5;66;03m# Load model with config    \u001b[39;00m\n",
       "    \u001b[38;5;66;03m# Download the model from huggingface.co/models\u001b[39;00m\n",
       "    model = AutoModelForSequenceClassification.from_pretrained(\n",
       "        model_id,\n",
       "        config=config,\n",
       "        attn_implementation=\u001b[33m\"flash_attention_2\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m use_flash_attention \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"eager\"\u001b[39m,\n",
       "    )\n",
       "        \n",
       "    \u001b[38;5;66;03m# Enable gradient checkpointing for memory efficiency\u001b[39;00m\n",
       "    model.gradient_checkpointing_enable()\n",
       "    logger.info(\u001b[33m\"Enabled gradient checkpointing for memory efficiency\"\u001b[39m)\n",
       "\n",
       "    model = model.to(device)\n",
       "    \n",
       "    \u001b[38;5;66;03m# Print model parameters\u001b[39;00m\n",
       "    total_params = sum(p.numel() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;28;01min\u001b[39;00m model.parameters())\n",
       "    trainable_params = sum(p.numel() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;28;01min\u001b[39;00m model.parameters() \u001b[38;5;28;01mif\u001b[39;00m p.requires_grad)\n",
       "    logger.info(f\"Model has {total_params/\u001b[32m1e6\u001b[39m:.1f}M parameters ({trainable_params/\u001b[32m1e6\u001b[39m:.1f}M trainable)\")\n",
       "    \n",
       "    \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
       "\n",
       "\u001b[38;5;66;03m# Metric helper method\u001b[39;00m\n",
       "\u001b[38;5;28;01mdef\u001b[39;00m compute_metrics(eval_pred):\n",
       "    predictions, labels = eval_pred\n",
       "    predictions = np.argmax(predictions, axis=\u001b[32m1\u001b[39m)\n",
       "    score = f1_score(\n",
       "            labels, predictions, labels=labels, pos_label=\u001b[32m1\u001b[39m, average=\u001b[33m\"weighted\"\u001b[39m\n",
       "        )\n",
       "    \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[33m\"f1\"\u001b[39m: float(score) \u001b[38;5;28;01mif\u001b[39;00m score == \u001b[32m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m score}\n",
       "\n",
       "\n",
       "\u001b[38;5;28;01mdef\u001b[39;00m get_training_args(args):\n",
       "    \u001b[33m\"\"\"Configure training arguments with stronger regularization.\"\"\"\u001b[39m\n",
       "    \u001b[38;5;28;01mreturn\u001b[39;00m TrainingArguments(\n",
       "        output_dir=args.model_dir,\n",
       "        per_device_train_batch_size=args.train_batch_size,\n",
       "        per_device_eval_batch_size=args.eval_batch_size,\n",
       "        learning_rate=float(args.learning_rate),\n",
       "        num_train_epochs=args.epochs,\n",
       "        bf16=\u001b[38;5;28;01mTrue\u001b[39;00m,\n",
       "        optim=\u001b[33m\"adamw_torch_fused\"\u001b[39m,\n",
       "        logging_strategy=\u001b[33m\"steps\"\u001b[39m,\n",
       "        logging_steps=\u001b[32m50\u001b[39m,\n",
       "        eval_strategy=\u001b[33m\"epoch\"\u001b[39m,\n",
       "        logging_dir=f\"{args.output_data_dir}/logs\",\n",
       "        save_strategy=\u001b[33m\"epoch\"\u001b[39m,\n",
       "        save_total_limit=\u001b[32m2\u001b[39m,\n",
       "        load_best_model_at_end=\u001b[38;5;28;01mTrue\u001b[39;00m,\n",
       "        metric_for_best_model=\u001b[33m\"f1\"\u001b[39m,\n",
       "        report_to=\u001b[33m\"tensorboard\"\u001b[39m,\n",
       "        weight_decay=args.weight_decay,\n",
       "        warmup_steps=args.warmup_steps,\n",
       "        gradient_accumulation_steps=args.gradient_accumulation_steps\n",
       "    )\n",
       "\n",
       "\n",
       "\u001b[38;5;28;01mif\u001b[39;00m __name__ == \u001b[33m\"__main__\"\u001b[39m:\n",
       "\n",
       "    parser = argparse.ArgumentParser()\n",
       "\n",
       "    \u001b[38;5;66;03m# hyperparameters sent by the client are passed as command-line arguments to the script.\u001b[39;00m\n",
       "    parser.add_argument(\u001b[33m\"--epochs\"\u001b[39m, type=int, default=\u001b[32m3\u001b[39m)\n",
       "    parser.add_argument(\u001b[33m\"--train_batch_size\"\u001b[39m, type=int, default=\u001b[32m32\u001b[39m)\n",
       "    parser.add_argument(\u001b[33m\"--eval_batch_size\"\u001b[39m, type=int, default=\u001b[32m64\u001b[39m)\n",
       "    parser.add_argument(\u001b[33m\"--warmup_steps\"\u001b[39m, type=int, default=\u001b[32m500\u001b[39m)\n",
       "    parser.add_argument(\u001b[33m\"--model_name\"\u001b[39m, type=str)\n",
       "    parser.add_argument(\u001b[33m\"--model_max_length\"\u001b[39m, type=int, default=\u001b[32m512\u001b[39m)\n",
       "    parser.add_argument(\u001b[33m\"--learning_rate\"\u001b[39m, type=str, default=\u001b[32m5e-5\u001b[39m)\n",
       "    parser.add_argument(\u001b[33m\"--dropout_rate\"\u001b[39m, type=float, default=\u001b[32m0.3\u001b[39m)\n",
       "    parser.add_argument(\u001b[33m\"--weight_decay\"\u001b[39m, type=float, default=\u001b[32m0.0\u001b[39m)\n",
       "    parser.add_argument(\u001b[33m\"--gradient_accumulation_steps\"\u001b[39m, type=int, default=\u001b[32m0\u001b[39m)\n",
       "\n",
       "    \u001b[38;5;66;03m# Data, model, and output directories\u001b[39;00m\n",
       "    parser.add_argument(\u001b[33m\"--output_data_dir\"\u001b[39m, type=str, default=os.environ[\u001b[33m\"SM_OUTPUT_DATA_DIR\"\u001b[39m])\n",
       "    parser.add_argument(\u001b[33m\"--model_dir\"\u001b[39m, type=str, default=os.environ[\u001b[33m\"SM_MODEL_DIR\"\u001b[39m])\n",
       "    parser.add_argument(\u001b[33m\"--n_gpus\"\u001b[39m, type=str, default=os.environ[\u001b[33m\"SM_NUM_GPUS\"\u001b[39m])\n",
       "    parser.add_argument(\u001b[33m\"--training_dir\"\u001b[39m, type=str, default=os.environ[\u001b[33m\"SM_CHANNEL_TRAIN\"\u001b[39m])\n",
       "    parser.add_argument(\u001b[33m\"--test_dir\"\u001b[39m, type=str, default=os.environ[\u001b[33m\"SM_CHANNEL_TEST\"\u001b[39m])\n",
       "\n",
       "    args, _ = parser.parse_known_args()\n",
       "\n",
       "    device = torch.device(\u001b[33m\"cuda\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch.cuda.is_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"cpu\"\u001b[39m)\n",
       "    logger.info(\u001b[33m\"Device detected: %s\"\u001b[39m, device)\n",
       "\n",
       "    \u001b[38;5;66;03m# Set random seed for reproducibility\u001b[39;00m\n",
       "    set_random_seed(\u001b[32m42\u001b[39m)\n",
       "\n",
       "    \u001b[38;5;66;03m# load datasets\u001b[39;00m\n",
       "    train_dataset = load_from_disk(args.training_dir)\n",
       "    test_dataset = load_from_disk(args.test_dir)\n",
       "\n",
       "    logger.info(f\" loaded train_dataset length is: {len(train_dataset)}\")\n",
       "    logger.info(f\" loaded test_dataset length is: {len(test_dataset)}\")\n",
       "\n",
       "    \u001b[38;5;66;03m# Setup tokenizer and tokenize datasets\u001b[39;00m\n",
       "    tokenizer = setup_tokenizer(args.model_name, args.model_max_length)\n",
       "    tokenized_train_dataset = tokenize_dataset(train_dataset, tokenizer)\n",
       "    tokenized_eval_dataset = tokenize_dataset(test_dataset, tokenizer)\n",
       "\n",
       "    \u001b[38;5;66;03m# Setup label mappings\u001b[39;00m\n",
       "    unique_labels = list(set(tokenized_train_dataset[\u001b[33m'labels'\u001b[39m]))\n",
       "    num_labels = len(unique_labels)\n",
       "    label2id = {label: i \u001b[38;5;28;01mfor\u001b[39;00m i, label \u001b[38;5;28;01min\u001b[39;00m enumerate(unique_labels)}\n",
       "    id2label = {i: label \u001b[38;5;28;01mfor\u001b[39;00m i, label \u001b[38;5;28;01min\u001b[39;00m enumerate(unique_labels)}\n",
       "\n",
       "    train_dataset = Dataset.from_dict({\n",
       "        \u001b[33m'input_ids'\u001b[39m: tokenized_train_dataset[\u001b[33m'input_ids'\u001b[39m],\n",
       "        \u001b[33m'attention_mask'\u001b[39m: tokenized_train_dataset[\u001b[33m'attention_mask'\u001b[39m],\n",
       "        \u001b[33m'labels'\u001b[39m: [label2id[label] \u001b[38;5;28;01mfor\u001b[39;00m label \u001b[38;5;28;01min\u001b[39;00m tokenized_train_dataset[\u001b[33m'labels'\u001b[39m]]\n",
       "    })\n",
       "\n",
       "    test_dataset = Dataset.from_dict({\n",
       "        \u001b[33m'input_ids'\u001b[39m: tokenized_eval_dataset[\u001b[33m'input_ids'\u001b[39m],\n",
       "        \u001b[33m'attention_mask'\u001b[39m: tokenized_eval_dataset[\u001b[33m'attention_mask'\u001b[39m],\n",
       "        \u001b[33m'labels'\u001b[39m: [label2id[label] \u001b[38;5;28;01mfor\u001b[39;00m label \u001b[38;5;28;01min\u001b[39;00m tokenized_eval_dataset[\u001b[33m'labels'\u001b[39m]]\n",
       "    })\n",
       "\n",
       "    \u001b[38;5;66;03m# Setup model with dropout\u001b[39;00m\n",
       "    model = setup_model(\n",
       "        args.model_name,\n",
       "        num_labels=num_labels,\n",
       "        label2id=label2id,\n",
       "        id2label=id2label,\n",
       "        dropout_rate=args.dropout_rate,\n",
       "        device=device\n",
       "    )\n",
       "\n",
       "    training_args = get_training_args(args)\n",
       "\n",
       "    \u001b[38;5;66;03m# Create a Trainer instance\u001b[39;00m\n",
       "    trainer = Trainer(\n",
       "        model=model,\n",
       "        args=training_args,\n",
       "        train_dataset=train_dataset,\n",
       "        eval_dataset=test_dataset,\n",
       "        compute_metrics=compute_metrics,\n",
       "        callbacks=[EarlyStoppingCallback(\n",
       "            early_stopping_patience=\u001b[32m5\u001b[39m,\n",
       "            early_stopping_threshold=\u001b[32m0.005\u001b[39m\n",
       "        )]\n",
       "    )\n",
       "\n",
       "    \u001b[38;5;66;03m# Train the model\u001b[39;00m\n",
       "    logger.info(\u001b[33m\"\\nStarting training...\"\u001b[39m)\n",
       "    trainer.train()\n",
       "    logger.info(\u001b[33m\"Training completed!\"\u001b[39m)\n",
       "\n",
       "    \u001b[38;5;66;03m# evaluate model\u001b[39;00m\n",
       "    eval_result = trainer.evaluate(eval_dataset=tokenized_eval_dataset)\n",
       "\n",
       "    \u001b[38;5;66;03m# writes eval result to file which can be accessed later in s3 ouput\u001b[39;00m\n",
       "    \u001b[38;5;28;01mwith\u001b[39;00m open(os.path.join(args.output_data_dir, \u001b[33m\"eval_results.txt\"\u001b[39m), \u001b[33m\"w\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m writer:\n",
       "        print(f\"***** Eval results *****\")\n",
       "        \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;28;01min\u001b[39;00m sorted(eval_result.items()):\n",
       "            writer.write(f\"{key} = {value}\\n\")\n",
       "\n",
       "    \u001b[38;5;66;03m# Save the model\u001b[39;00m\n",
       "    trainer.save_model(args.model_dir)\n",
       "    tokenizer.save_pretrained(args.model_dir)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%pycat assets/train.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15dc5a55-e251-4654-ba0a-a8841ae087ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-04T15:54:07.336876Z",
     "iopub.status.busy": "2025-08-04T15:54:07.336047Z",
     "iopub.status.idle": "2025-08-04T15:54:07.340703Z",
     "shell.execute_reply": "2025-08-04T15:54:07.339663Z",
     "shell.execute_reply.started": "2025-08-04T15:54:07.336845Z"
    }
   },
   "source": [
    "## 2.2 Define the training hyperpramaters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "db6809be-0978-4e87-a91a-c6a9fae11e89",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-04T16:01:05.101154Z",
     "iopub.status.busy": "2025-08-04T16:01:05.100852Z",
     "iopub.status.idle": "2025-08-04T16:01:05.105836Z",
     "shell.execute_reply": "2025-08-04T16:01:05.104729Z",
     "shell.execute_reply.started": "2025-08-04T16:01:05.101133Z"
    }
   },
   "outputs": [],
   "source": [
    "# hyperparameters which are passed to the training job\n",
    "hyperparameters={\n",
    "    'model_name': 'answerdotai/ModernBERT-base',\n",
    "    'model_max_length': 64, #max sequence length in tokens\n",
    "    'epochs': 2,\n",
    "    'train_batch_size': 32,\n",
    "    'eval_batch_size': 16,\n",
    "    'warmup_steps': 500,\n",
    "    'learning_rate': 5e-5,\n",
    "    'dropout_rate': 0.3,\n",
    "    'weight_decay': 0.2,\n",
    "    'gradient_accumulation_steps': 2\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120df482-c5ab-4588-b969-d36839282714",
   "metadata": {},
   "source": [
    "## 2.3 Create sage Maker Estimator and fit it on the train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1f6e0901-9281-4275-818b-d69d267721c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-04T16:03:25.912683Z",
     "iopub.status.busy": "2025-08-04T16:03:25.912398Z",
     "iopub.status.idle": "2025-08-04T16:03:25.950228Z",
     "shell.execute_reply": "2025-08-04T16:03:25.949144Z",
     "shell.execute_reply.started": "2025-08-04T16:03:25.912661Z"
    }
   },
   "outputs": [],
   "source": [
    "from sagemaker.estimator import Estimator\n",
    "\n",
    "# Define your image URI (example for PyTorch)\n",
    "image_uri = \"763104351884.dkr.ecr.us-east-2.amazonaws.com/pytorch-training:2.7.1-gpu-py312-cu128-ubuntu22.04-sagemaker\"\n",
    "\n",
    "# Set up the estimator\n",
    "estimator = Estimator(\n",
    "    entry_point='train.py',\n",
    "    source_dir='./assets',\n",
    "    requirements_file='requirements.txt',  # Use this instead of dependencies\n",
    "    image_uri=image_uri,\n",
    "    role=get_execution_role(),\n",
    "    instance_count=1,\n",
    "    instance_type='ml.g5.xlarge',  # or your preferred instance type\n",
    "    input_mode='File',\n",
    "    output_path=f's3://{default_bucket}/training-output',\n",
    "    base_job_name='Modernbert-training',\n",
    "    keep_alive_period_in_seconds=1800,  # 30 minutes\n",
    "    disable_profiler=True,\n",
    "    debugger_hook_config=False,\n",
    "    max_run=86400,  # 24 hours max run time\n",
    "    sagemaker_session=sess,\n",
    "    # Hyperparameters\n",
    "    hyperparameters=hyperparameters,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "15e003ea-29c5-491b-96bb-7fd89b388433",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-04T16:24:04.237059Z",
     "iopub.status.busy": "2025-08-04T16:24:04.236693Z",
     "iopub.status.idle": "2025-08-04T16:37:59.182733Z",
     "shell.execute_reply": "2025-08-04T16:37:59.181842Z",
     "shell.execute_reply.started": "2025-08-04T16:24:04.237035Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.telemetry.telemetry_logging:SageMaker Python SDK will collect telemetry to help us better understand our user's needs, diagnose issues, and deliver additional features.\n",
      "To opt out of telemetry, please disable via TelemetryOptOut parameter in SDK defaults config. For more information, refer to https://sagemaker.readthedocs.io/en/stable/overview.html#configuring-and-using-defaults-with-the-sagemaker-python-sdk.\n",
      "INFO:sagemaker:Creating training-job with name: Modernbert-training-2025-08-04-16-24-04-240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-04 16:24:06 Starting - Starting the training job...\n",
      "2025-08-04 16:24:19 Starting - Preparing the instances for training...\n",
      "2025-08-04 16:25:06 Downloading - Downloading the training image.................................\n",
      "2025-08-04 16:30:24 Training - Training image download completed. Training in progress..\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34mSkipping CUDA compat setup as package not found\u001b[0m\n",
      "\u001b[34m2025-08-04 16:30:41,001 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2025-08-04 16:30:41,020 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2025-08-04 16:30:41,029 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2025-08-04 16:30:41,032 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2025-08-04 16:30:42,619 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy in /usr/local/lib/python3.12/site-packages (from -r requirements.txt (line 1)) (1.26.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pandas in /usr/local/lib/python3.12/site-packages (from -r requirements.txt (line 2)) (2.3.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scikit-learn in /usr/local/lib/python3.12/site-packages (from -r requirements.txt (line 3)) (1.7.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: matplotlib in /usr/local/lib/python3.12/site-packages (from -r requirements.txt (line 4)) (3.10.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tqdm in /usr/local/lib/python3.12/site-packages (from -r requirements.txt (line 5)) (4.67.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torch>=2.6.0 in /usr/local/lib/python3.12/site-packages (from -r requirements.txt (line 6)) (2.7.1+cu128)\u001b[0m\n",
      "\u001b[34mCollecting transformers (from -r requirements.txt (line 7))\u001b[0m\n",
      "\u001b[34mDownloading transformers-4.54.1-py3-none-any.whl.metadata (41 kB)\u001b[0m\n",
      "\u001b[34mCollecting datasets (from -r requirements.txt (line 8))\u001b[0m\n",
      "\u001b[34mDownloading datasets-4.0.0-py3-none-any.whl.metadata (19 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: boto3 in /usr/local/lib/python3.12/site-packages (from -r requirements.txt (line 9)) (1.39.7)\u001b[0m\n",
      "\u001b[34mCollecting sentence-transformers (from -r requirements.txt (line 10))\u001b[0m\n",
      "\u001b[34mDownloading sentence_transformers-5.0.0-py3-none-any.whl.metadata (16 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: huggingface-hub in /usr/local/lib/python3.12/site-packages (from -r requirements.txt (line 11)) (0.33.4)\u001b[0m\n",
      "\u001b[34mCollecting nltk (from -r requirements.txt (line 12))\u001b[0m\n",
      "\u001b[34mDownloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\u001b[0m\n",
      "\u001b[34mCollecting python-dotenv (from -r requirements.txt (line 13))\u001b[0m\n",
      "\u001b[34mDownloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\u001b[0m\n",
      "\u001b[34mCollecting pytest (from -r requirements.txt (line 14))\u001b[0m\n",
      "\u001b[34mDownloading pytest-8.4.1-py3-none-any.whl.metadata (7.7 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: accelerate in /usr/local/lib/python3.12/site-packages (from -r requirements.txt (line 15)) (1.9.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: s3fs in /usr/local/lib/python3.12/site-packages (from -r requirements.txt (line 16)) (0.4.2)\u001b[0m\n",
      "\u001b[34mCollecting setuptools<71.0.0 (from -r requirements.txt (line 17))\u001b[0m\n",
      "\u001b[34mDownloading setuptools-70.3.0-py3-none-any.whl.metadata (5.8 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/site-packages (from pandas->-r requirements.txt (line 2)) (2.9.0.post0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/site-packages (from pandas->-r requirements.txt (line 2)) (2025.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/site-packages (from pandas->-r requirements.txt (line 2)) (2025.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scipy>=1.8.0 in /usr/local/lib/python3.12/site-packages (from scikit-learn->-r requirements.txt (line 3)) (1.16.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/site-packages (from scikit-learn->-r requirements.txt (line 3)) (1.5.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/site-packages (from scikit-learn->-r requirements.txt (line 3)) (3.6.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/site-packages (from matplotlib->-r requirements.txt (line 4)) (1.3.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/site-packages (from matplotlib->-r requirements.txt (line 4)) (0.12.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/site-packages (from matplotlib->-r requirements.txt (line 4)) (4.59.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/site-packages (from matplotlib->-r requirements.txt (line 4)) (1.4.8)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/site-packages (from matplotlib->-r requirements.txt (line 4)) (24.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/site-packages (from matplotlib->-r requirements.txt (line 4)) (11.3.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/site-packages (from matplotlib->-r requirements.txt (line 4)) (3.2.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: filelock in /usr/local/lib/python3.12/site-packages (from torch>=2.6.0->-r requirements.txt (line 6)) (3.13.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/site-packages (from torch>=2.6.0->-r requirements.txt (line 6)) (4.14.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/site-packages (from torch>=2.6.0->-r requirements.txt (line 6)) (1.13.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: networkx in /usr/local/lib/python3.12/site-packages (from torch>=2.6.0->-r requirements.txt (line 6)) (3.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jinja2 in /usr/local/lib/python3.12/site-packages (from torch>=2.6.0->-r requirements.txt (line 6)) (3.1.6)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: fsspec in /usr/local/lib/python3.12/site-packages (from torch>=2.6.0->-r requirements.txt (line 6)) (2025.7.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.61 in /usr/local/lib/python3.12/site-packages (from torch>=2.6.0->-r requirements.txt (line 6)) (12.8.61)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: nvidia-cuda-runtime-cu12==12.8.57 in /usr/local/lib/python3.12/site-packages (from torch>=2.6.0->-r requirements.txt (line 6)) (12.8.57)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: nvidia-cuda-cupti-cu12==12.8.57 in /usr/local/lib/python3.12/site-packages (from torch>=2.6.0->-r requirements.txt (line 6)) (12.8.57)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: nvidia-cudnn-cu12==9.7.1.26 in /usr/local/lib/python3.12/site-packages (from torch>=2.6.0->-r requirements.txt (line 6)) (9.7.1.26)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: nvidia-cublas-cu12==12.8.3.14 in /usr/local/lib/python3.12/site-packages (from torch>=2.6.0->-r requirements.txt (line 6)) (12.8.3.14)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: nvidia-cufft-cu12==11.3.3.41 in /usr/local/lib/python3.12/site-packages (from torch>=2.6.0->-r requirements.txt (line 6)) (11.3.3.41)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: nvidia-curand-cu12==10.3.9.55 in /usr/local/lib/python3.12/site-packages (from torch>=2.6.0->-r requirements.txt (line 6)) (10.3.9.55)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: nvidia-cusolver-cu12==11.7.2.55 in /usr/local/lib/python3.12/site-packages (from torch>=2.6.0->-r requirements.txt (line 6)) (11.7.2.55)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: nvidia-cusparse-cu12==12.5.7.53 in /usr/local/lib/python3.12/site-packages (from torch>=2.6.0->-r requirements.txt (line 6)) (12.5.7.53)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /usr/local/lib/python3.12/site-packages (from torch>=2.6.0->-r requirements.txt (line 6)) (0.6.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: nvidia-nccl-cu12==2.26.2 in /usr/local/lib/python3.12/site-packages (from torch>=2.6.0->-r requirements.txt (line 6)) (2.26.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: nvidia-nvtx-cu12==12.8.55 in /usr/local/lib/python3.12/site-packages (from torch>=2.6.0->-r requirements.txt (line 6)) (12.8.55)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: nvidia-nvjitlink-cu12==12.8.61 in /usr/local/lib/python3.12/site-packages (from torch>=2.6.0->-r requirements.txt (line 6)) (12.8.61)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: nvidia-cufile-cu12==1.13.0.11 in /usr/local/lib/python3.12/site-packages (from torch>=2.6.0->-r requirements.txt (line 6)) (1.13.0.11)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: triton==3.3.1 in /usr/local/lib/python3.12/site-packages (from torch>=2.6.0->-r requirements.txt (line 6)) (3.3.1)\u001b[0m\n",
      "\u001b[34mCollecting huggingface-hub (from -r requirements.txt (line 11))\u001b[0m\n",
      "\u001b[34mDownloading huggingface_hub-0.34.3-py3-none-any.whl.metadata (14 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/site-packages (from transformers->-r requirements.txt (line 7)) (6.0.2)\u001b[0m\n",
      "\u001b[34mCollecting regex!=2019.12.17 (from transformers->-r requirements.txt (line 7))\u001b[0m\n",
      "\u001b[34mDownloading regex-2025.7.34-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests in /usr/local/lib/python3.12/site-packages (from transformers->-r requirements.txt (line 7)) (2.32.4)\u001b[0m\n",
      "\u001b[34mCollecting tokenizers<0.22,>=0.21 (from transformers->-r requirements.txt (line 7))\u001b[0m\n",
      "\u001b[34mDownloading tokenizers-0.21.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/site-packages (from transformers->-r requirements.txt (line 7)) (0.5.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/site-packages (from huggingface-hub->-r requirements.txt (line 11)) (1.1.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/site-packages (from datasets->-r requirements.txt (line 8)) (20.0.0)\u001b[0m\n",
      "\u001b[34mCollecting dill<0.3.9,>=0.3.0 (from datasets->-r requirements.txt (line 8))\u001b[0m\n",
      "\u001b[34mDownloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\u001b[0m\n",
      "\u001b[34mCollecting xxhash (from datasets->-r requirements.txt (line 8))\u001b[0m\n",
      "\u001b[34mDownloading xxhash-3.5.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\u001b[0m\n",
      "\u001b[34mCollecting multiprocess<0.70.17 (from datasets->-r requirements.txt (line 8))\u001b[0m\n",
      "\u001b[34mDownloading multiprocess-0.70.16-py312-none-any.whl.metadata (7.2 kB)\u001b[0m\n",
      "\u001b[34mCollecting fsspec (from torch>=2.6.0->-r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mDownloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\u001b[0m\n",
      "\u001b[34mCollecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r requirements.txt (line 8))\u001b[0m\n",
      "\u001b[34mDownloading aiohttp-3.12.15-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: botocore<1.40.0,>=1.39.7 in /usr/local/lib/python3.12/site-packages (from boto3->-r requirements.txt (line 9)) (1.39.7)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.12/site-packages (from boto3->-r requirements.txt (line 9)) (1.0.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: s3transfer<0.14.0,>=0.13.0 in /usr/local/lib/python3.12/site-packages (from boto3->-r requirements.txt (line 9)) (0.13.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.12/site-packages (from botocore<1.40.0,>=1.39.7->boto3->-r requirements.txt (line 9)) (2.5.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->-r requirements.txt (line 2)) (1.17.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: click in /usr/local/lib/python3.12/site-packages (from nltk->-r requirements.txt (line 12)) (8.2.1)\u001b[0m\n",
      "\u001b[34mCollecting iniconfig>=1 (from pytest->-r requirements.txt (line 14))\u001b[0m\n",
      "\u001b[34mDownloading iniconfig-2.1.0-py3-none-any.whl.metadata (2.7 kB)\u001b[0m\n",
      "\u001b[34mCollecting pluggy<2,>=1.5 (from pytest->-r requirements.txt (line 14))\u001b[0m\n",
      "\u001b[34mDownloading pluggy-1.6.0-py3-none-any.whl.metadata (4.8 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pygments>=2.7.2 in /usr/local/lib/python3.12/site-packages (from pytest->-r requirements.txt (line 14)) (2.19.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: psutil in /usr/local/lib/python3.12/site-packages (from accelerate->-r requirements.txt (line 15)) (7.0.0)\u001b[0m\n",
      "\u001b[34mCollecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r requirements.txt (line 8))\u001b[0m\n",
      "\u001b[34mDownloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\u001b[0m\n",
      "\u001b[34mCollecting aiosignal>=1.4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r requirements.txt (line 8))\u001b[0m\n",
      "\u001b[34mDownloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r requirements.txt (line 8)) (25.3.0)\u001b[0m\n",
      "\u001b[34mCollecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r requirements.txt (line 8))\u001b[0m\n",
      "\u001b[34mDownloading frozenlist-1.7.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\u001b[0m\n",
      "\u001b[34mCollecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r requirements.txt (line 8))\u001b[0m\n",
      "\u001b[34mDownloading multidict-6.6.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.3 kB)\u001b[0m\n",
      "\u001b[34mCollecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r requirements.txt (line 8))\u001b[0m\n",
      "\u001b[34mDownloading propcache-0.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\u001b[0m\n",
      "\u001b[34mCollecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r requirements.txt (line 8))\u001b[0m\n",
      "\u001b[34mDownloading yarl-1.20.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (73 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna>=2.0 in /usr/local/lib/python3.12/site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r requirements.txt (line 8)) (3.10)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/site-packages (from requests->transformers->-r requirements.txt (line 7)) (3.4.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/site-packages (from requests->transformers->-r requirements.txt (line 7)) (2025.7.14)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=2.6.0->-r requirements.txt (line 6)) (1.3.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/site-packages (from jinja2->torch>=2.6.0->-r requirements.txt (line 6)) (3.0.2)\u001b[0m\n",
      "\u001b[34mDownloading setuptools-70.3.0-py3-none-any.whl (931 kB)\u001b[0m\n",
      "\u001b[34m 931.1/931.1 kB 30.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading transformers-4.54.1-py3-none-any.whl (11.2 MB)\u001b[0m\n",
      "\u001b[34m 11.2/11.2 MB 145.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading huggingface_hub-0.34.3-py3-none-any.whl (558 kB)\u001b[0m\n",
      "\u001b[34m 558.8/558.8 kB 62.8 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading tokenizers-0.21.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\u001b[0m\n",
      "\u001b[34m 3.1/3.1 MB 159.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading datasets-4.0.0-py3-none-any.whl (494 kB)\u001b[0m\n",
      "\u001b[34mDownloading dill-0.3.8-py3-none-any.whl (116 kB)\u001b[0m\n",
      "\u001b[34mDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\u001b[0m\n",
      "\u001b[34mDownloading multiprocess-0.70.16-py312-none-any.whl (146 kB)\u001b[0m\n",
      "\u001b[34mDownloading sentence_transformers-5.0.0-py3-none-any.whl (470 kB)\u001b[0m\n",
      "\u001b[34mDownloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\u001b[0m\n",
      "\u001b[34m 1.5/1.5 MB 131.8 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\u001b[0m\n",
      "\u001b[34mDownloading pytest-8.4.1-py3-none-any.whl (365 kB)\u001b[0m\n",
      "\u001b[34mDownloading pluggy-1.6.0-py3-none-any.whl (20 kB)\u001b[0m\n",
      "\u001b[34mDownloading aiohttp-3.12.15-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\u001b[0m\n",
      "\u001b[34m 1.7/1.7 MB 116.8 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading multidict-6.6.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (256 kB)\u001b[0m\n",
      "\u001b[34mDownloading yarl-1.20.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (355 kB)\u001b[0m\n",
      "\u001b[34mDownloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\u001b[0m\n",
      "\u001b[34mDownloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\u001b[0m\n",
      "\u001b[34mDownloading frozenlist-1.7.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (241 kB)\u001b[0m\n",
      "\u001b[34mDownloading iniconfig-2.1.0-py3-none-any.whl (6.0 kB)\u001b[0m\n",
      "\u001b[34mDownloading propcache-0.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (224 kB)\u001b[0m\n",
      "\u001b[34mDownloading regex-2025.7.34-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (801 kB)\u001b[0m\n",
      "\u001b[34m 801.9/801.9 kB 58.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading xxhash-3.5.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\u001b[0m\n",
      "\u001b[34mInstalling collected packages: xxhash, setuptools, regex, python-dotenv, propcache, pluggy, multidict, iniconfig, fsspec, frozenlist, dill, aiohappyeyeballs, yarl, pytest, nltk, multiprocess, huggingface-hub, aiosignal, tokenizers, aiohttp, transformers, sentence-transformers, datasets\u001b[0m\n",
      "\u001b[34mAttempting uninstall: setuptools\u001b[0m\n",
      "\u001b[34mFound existing installation: setuptools 80.9.0\u001b[0m\n",
      "\u001b[34mUninstalling setuptools-80.9.0:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled setuptools-80.9.0\u001b[0m\n",
      "\u001b[34mAttempting uninstall: fsspec\u001b[0m\n",
      "\u001b[34mFound existing installation: fsspec 2025.7.0\u001b[0m\n",
      "\u001b[34mUninstalling fsspec-2025.7.0:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled fsspec-2025.7.0\u001b[0m\n",
      "\u001b[34mAttempting uninstall: dill\u001b[0m\n",
      "\u001b[34mFound existing installation: dill 0.4.0\u001b[0m\n",
      "\u001b[34mUninstalling dill-0.4.0:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled dill-0.4.0\u001b[0m\n",
      "\u001b[34mAttempting uninstall: multiprocess\u001b[0m\n",
      "\u001b[34mFound existing installation: multiprocess 0.70.18\u001b[0m\n",
      "\u001b[34mUninstalling multiprocess-0.70.18:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled multiprocess-0.70.18\u001b[0m\n",
      "\u001b[34mAttempting uninstall: huggingface-hub\u001b[0m\n",
      "\u001b[34mFound existing installation: huggingface-hub 0.33.4\u001b[0m\n",
      "\u001b[34mUninstalling huggingface-hub-0.33.4:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled huggingface-hub-0.33.4\u001b[0m\n",
      "\u001b[34mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\u001b[0m\n",
      "\u001b[34mpathos 0.3.4 requires dill>=0.4.0, but you have dill 0.3.8 which is incompatible.\u001b[0m\n",
      "\u001b[34mpathos 0.3.4 requires multiprocess>=0.70.18, but you have multiprocess 0.70.16 which is incompatible.\u001b[0m\n",
      "\u001b[34mSuccessfully installed aiohappyeyeballs-2.6.1 aiohttp-3.12.15 aiosignal-1.4.0 datasets-4.0.0 dill-0.3.8 frozenlist-1.7.0 fsspec-2025.3.0 huggingface-hub-0.34.3 iniconfig-2.1.0 multidict-6.6.3 multiprocess-0.70.16 nltk-3.9.1 pluggy-1.6.0 propcache-0.3.2 pytest-8.4.1 python-dotenv-1.1.1 regex-2025.7.34 sentence-transformers-5.0.0 setuptools-70.3.0 tokenizers-0.21.4 transformers-4.54.1 xxhash-3.5.0 yarl-1.20.1\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\n",
      "\u001b[34m[notice] A new release of pip is available: 25.1.1 -> 25.2\u001b[0m\n",
      "\u001b[34m[notice] To update, run: pip install --upgrade pip\u001b[0m\n",
      "\u001b[34m2025-08-04 16:30:57,076 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2025-08-04 16:30:57,076 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2025-08-04 16:30:57,114 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2025-08-04 16:30:57,143 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2025-08-04 16:30:57,178 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2025-08-04 16:30:57,189 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"test\": \"/opt/ml/input/data/test\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.g5.xlarge\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"dropout_rate\": 0.3,\n",
      "        \"epochs\": 3,\n",
      "        \"eval_batch_size\": 16,\n",
      "        \"gradient_accumulation_steps\": 2,\n",
      "        \"learning_rate\": 5e-05,\n",
      "        \"model_max_length\": 64,\n",
      "        \"model_name\": \"answerdotai/ModernBERT-base\",\n",
      "        \"train_batch_size\": 32,\n",
      "        \"warmup_steps\": 500,\n",
      "        \"weight_decay\": 0.2\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"test\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.g5.xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": false,\n",
      "    \"is_smddprun_installed\": false,\n",
      "    \"job_name\": \"Modernbert-training-2025-08-04-16-24-04-240\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-2-207567795090/Modernbert-training-2025-08-04-16-24-04-240/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 1,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.g5.xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.g5.xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\",\n",
      "        \"topology\": null\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"dropout_rate\":0.3,\"epochs\":3,\"eval_batch_size\":16,\"gradient_accumulation_steps\":2,\"learning_rate\":5e-05,\"model_max_length\":64,\"model_name\":\"answerdotai/ModernBERT-base\",\"train_batch_size\":32,\"warmup_steps\":500,\"weight_decay\":0.2}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g5.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.xlarge\"}],\"network_interface_name\":\"eth0\",\"topology\":null}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"test\",\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_TYPE=ml.g5.xlarge\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.xlarge\"}}\u001b[0m\n",
      "\u001b[34mSM_DISTRIBUTION_INSTANCE_GROUPS=[]\u001b[0m\n",
      "\u001b[34mSM_IS_HETERO=false\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_NUM_NEURONS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-2-207567795090/Modernbert-training-2025-08-04-16-24-04-240/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.g5.xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"dropout_rate\":0.3,\"epochs\":3,\"eval_batch_size\":16,\"gradient_accumulation_steps\":2,\"learning_rate\":5e-05,\"model_max_length\":64,\"model_name\":\"answerdotai/ModernBERT-base\",\"train_batch_size\":32,\"warmup_steps\":500,\"weight_decay\":0.2},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":false,\"is_smddprun_installed\":false,\"job_name\":\"Modernbert-training-2025-08-04-16-24-04-240\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-2-207567795090/Modernbert-training-2025-08-04-16-24-04-240/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":1,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g5.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.xlarge\"}],\"network_interface_name\":\"eth0\",\"topology\":null},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--dropout_rate\",\"0.3\",\"--epochs\",\"3\",\"--eval_batch_size\",\"16\",\"--gradient_accumulation_steps\",\"2\",\"--learning_rate\",\"5e-05\",\"--model_max_length\",\"64\",\"--model_name\",\"answerdotai/ModernBERT-base\",\"--train_batch_size\",\"32\",\"--warmup_steps\",\"500\",\"--weight_decay\",\"0.2\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TEST=/opt/ml/input/data/test\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_DROPOUT_RATE=0.3\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=3\u001b[0m\n",
      "\u001b[34mSM_HP_EVAL_BATCH_SIZE=16\u001b[0m\n",
      "\u001b[34mSM_HP_GRADIENT_ACCUMULATION_STEPS=2\u001b[0m\n",
      "\u001b[34mSM_HP_LEARNING_RATE=5e-05\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL_MAX_LENGTH=64\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL_NAME=answerdotai/ModernBERT-base\u001b[0m\n",
      "\u001b[34mSM_HP_TRAIN_BATCH_SIZE=32\u001b[0m\n",
      "\u001b[34mSM_HP_WARMUP_STEPS=500\u001b[0m\n",
      "\u001b[34mSM_HP_WEIGHT_DECAY=0.2\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/local/lib/python312.zip:/usr/local/lib/python3.12:/usr/local/lib/python3.12/lib-dynload:/usr/local/lib/python3.12/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/usr/local/bin/python train.py --dropout_rate 0.3 --epochs 3 --eval_batch_size 16 --gradient_accumulation_steps 2 --learning_rate 5e-05 --model_max_length 64 --model_name answerdotai/ModernBERT-base --train_batch_size 32 --warmup_steps 500 --weight_decay 0.2\u001b[0m\n",
      "\u001b[34m2025-08-04 16:30:57,190 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker Debugger as it is not installed.\u001b[0m\n",
      "\u001b[34m2025-08-04 16:30:57,190 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker TF as Tensorflow is not installed.\u001b[0m\n",
      "\u001b[34m2025-08-04 16:31:01,963 - __main__ - INFO - Device detected: cuda\u001b[0m\n",
      "\u001b[34m2025-08-04 16:31:01,971 - __main__ - INFO -  loaded train_dataset length is: 25326\u001b[0m\n",
      "\u001b[34m2025-08-04 16:31:01,971 - __main__ - INFO -  loaded test_dataset length is: 6332\u001b[0m\n",
      "\u001b[34mMap:   0%|          | 0/25326 [00:00<?, ? examples/s]\u001b[0m\n",
      "\u001b[34mMap:   8%|         | 2000/25326 [00:00<00:01, 13292.02 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  16%|        | 4000/25326 [00:00<00:01, 13997.88 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  24%|       | 6000/25326 [00:00<00:01, 14311.84 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  32%|      | 8000/25326 [00:00<00:01, 14356.75 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  39%|      | 10000/25326 [00:00<00:01, 14415.54 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  47%|     | 12000/25326 [00:00<00:00, 14448.26 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  55%|    | 14000/25326 [00:01<00:01, 11032.37 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  63%|   | 16000/25326 [00:01<00:00, 11994.05 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  71%|   | 18000/25326 [00:01<00:00, 12586.46 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  79%|  | 20000/25326 [00:01<00:00, 13144.42 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  87%| | 22000/25326 [00:01<00:00, 13577.50 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  95%|| 24000/25326 [00:01<00:00, 13878.78 examples/s]\u001b[0m\n",
      "\u001b[34mMap: 100%|| 25326/25326 [00:01<00:00, 13373.29 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   0%|          | 0/6332 [00:00<?, ? examples/s]\u001b[0m\n",
      "\u001b[34mMap:  32%|      | 2000/6332 [00:00<00:00, 13627.14 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  63%|   | 4000/6332 [00:00<00:00, 14169.71 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  95%|| 6000/6332 [00:00<00:00, 14375.37 examples/s]\u001b[0m\n",
      "\u001b[34mMap: 100%|| 6332/6332 [00:00<00:00, 14188.42 examples/s]\u001b[0m\n",
      "\u001b[34m2025-08-04 16:31:43,949 - __main__ - INFO - Flash Attention version 2.7.4.post1 is installed\u001b[0m\n",
      "\u001b[34mFlash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in ModernBertForSequenceClassification is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained(\"openai/whisper-tiny\", attn_implementation=\"flash_attention_2\", torch_dtype=torch.float16)`\u001b[0m\n",
      "\u001b[34mFlash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in ModernBertForSequenceClassification is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained(\"openai/whisper-tiny\", attn_implementation=\"flash_attention_2\", torch_dtype=torch.float16)`\u001b[0m\n",
      "\u001b[34mFlash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in ModernBertModel is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained(\"openai/whisper-tiny\", attn_implementation=\"flash_attention_2\", torch_dtype=torch.float16)`\u001b[0m\n",
      "\u001b[34mFlash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in ModernBertModel is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained(\"openai/whisper-tiny\", attn_implementation=\"flash_attention_2\", torch_dtype=torch.float16)`\u001b[0m\n",
      "\u001b[34mSome weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']\u001b[0m\n",
      "\u001b[34mYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001b[0m\n",
      "\u001b[34mSome weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']\u001b[0m\n",
      "\u001b[34mYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001b[0m\n",
      "\u001b[34m2025-08-04 16:31:46,862 - __main__ - INFO - Enabled gradient checkpointing for memory efficiency\u001b[0m\n",
      "\u001b[34m2025-08-04 16:31:47,572 - __main__ - INFO - Model has 149.6M parameters (149.6M trainable)\u001b[0m\n",
      "\u001b[34m2025-08-04 16:31:47,720 - __main__ - INFO - \u001b[0m\n",
      "\u001b[34mStarting training...\u001b[0m\n",
      "\u001b[34m0%|          | 0/1188 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m0%|          | 1/1188 [00:09<3:03:29,  9.27s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 2/1188 [00:09<1:17:26,  3.92s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 3/1188 [00:09<43:30,  2.20s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 4/1188 [00:09<27:35,  1.40s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 5/1188 [00:09<18:48,  1.05it/s]\u001b[0m\n",
      "\u001b[34m1%|          | 6/1188 [00:10<13:30,  1.46it/s]\u001b[0m\n",
      "\u001b[34m1%|          | 7/1188 [00:10<10:08,  1.94it/s]\u001b[0m\n",
      "\u001b[34m1%|          | 8/1188 [00:10<07:57,  2.47it/s]\u001b[0m\n",
      "\u001b[34m1%|          | 9/1188 [00:10<06:28,  3.04it/s]\u001b[0m\n",
      "\u001b[34m1%|          | 10/1188 [00:10<05:30,  3.57it/s]\u001b[0m\n",
      "\u001b[34m1%|          | 11/1188 [00:10<04:48,  4.07it/s]\u001b[0m\n",
      "\u001b[34m1%|          | 12/1188 [00:11<04:20,  4.52it/s]\u001b[0m\n",
      "\u001b[34m1%|          | 13/1188 [00:11<04:00,  4.88it/s]\u001b[0m\n",
      "\u001b[34m1%|          | 14/1188 [00:11<03:48,  5.15it/s]\u001b[0m\n",
      "\u001b[34m1%|         | 15/1188 [00:11<05:03,  3.86it/s]\u001b[0m\n",
      "\u001b[34m1%|         | 16/1188 [00:12<05:53,  3.31it/s]\u001b[0m\n",
      "\u001b[34m1%|         | 17/1188 [00:12<05:06,  3.82it/s]\u001b[0m\n",
      "\u001b[34m2%|         | 18/1188 [00:12<04:33,  4.28it/s]\u001b[0m\n",
      "\u001b[34m2%|         | 19/1188 [00:12<04:08,  4.70it/s]\u001b[0m\n",
      "\u001b[34m2%|         | 20/1188 [00:12<03:51,  5.04it/s]\u001b[0m\n",
      "\u001b[34m2%|         | 21/1188 [00:13<03:41,  5.28it/s]\u001b[0m\n",
      "\u001b[34m2%|         | 22/1188 [00:13<03:32,  5.50it/s]\u001b[0m\n",
      "\u001b[34m2%|         | 23/1188 [00:13<03:25,  5.66it/s]\u001b[0m\n",
      "\u001b[34m2%|         | 24/1188 [00:13<03:32,  5.47it/s]\u001b[0m\n",
      "\u001b[34m2%|         | 25/1188 [00:13<03:26,  5.64it/s]\u001b[0m\n",
      "\u001b[34m2%|         | 26/1188 [00:13<03:21,  5.77it/s]\u001b[0m\n",
      "\u001b[34m2%|         | 27/1188 [00:14<03:17,  5.88it/s]\u001b[0m\n",
      "\u001b[34m2%|         | 28/1188 [00:14<03:15,  5.94it/s]\u001b[0m\n",
      "\u001b[34m2%|         | 29/1188 [00:14<03:13,  6.00it/s]\u001b[0m\n",
      "\u001b[34m3%|         | 30/1188 [00:14<03:12,  6.02it/s]\u001b[0m\n",
      "\u001b[34m3%|         | 31/1188 [00:14<03:11,  6.04it/s]\u001b[0m\n",
      "\u001b[34m3%|         | 32/1188 [00:14<03:10,  6.06it/s]\u001b[0m\n",
      "\u001b[34m3%|         | 33/1188 [00:15<03:10,  6.07it/s]\u001b[0m\n",
      "\u001b[34m3%|         | 34/1188 [00:15<03:11,  6.02it/s]\u001b[0m\n",
      "\u001b[34m3%|         | 35/1188 [00:15<03:11,  6.03it/s]\u001b[0m\n",
      "\u001b[34m3%|         | 36/1188 [00:15<03:11,  6.02it/s]\u001b[0m\n",
      "\u001b[34m3%|         | 37/1188 [00:15<03:12,  5.98it/s]\u001b[0m\n",
      "\u001b[34m3%|         | 38/1188 [00:15<03:11,  6.02it/s]\u001b[0m\n",
      "\u001b[34m3%|         | 39/1188 [00:16<03:10,  6.03it/s]\u001b[0m\n",
      "\u001b[34m3%|         | 40/1188 [00:16<03:09,  6.05it/s]\u001b[0m\n",
      "\u001b[34m3%|         | 41/1188 [00:16<03:08,  6.08it/s]\u001b[0m\n",
      "\u001b[34m4%|         | 42/1188 [00:16<03:09,  6.05it/s]\u001b[0m\n",
      "\u001b[34m4%|         | 43/1188 [00:16<03:09,  6.05it/s]\u001b[0m\n",
      "\u001b[34m4%|         | 44/1188 [00:16<03:09,  6.05it/s]\u001b[0m\n",
      "\u001b[34m4%|         | 45/1188 [00:17<03:09,  6.04it/s]\u001b[0m\n",
      "\u001b[34m4%|         | 46/1188 [00:17<03:10,  6.01it/s]\u001b[0m\n",
      "\u001b[34m4%|         | 47/1188 [00:17<03:09,  6.02it/s]\u001b[0m\n",
      "\u001b[34m4%|         | 48/1188 [00:17<03:08,  6.04it/s]\u001b[0m\n",
      "\u001b[34m4%|         | 49/1188 [00:17<03:07,  6.08it/s]\u001b[0m\n",
      "\u001b[34m4%|         | 50/1188 [00:17<03:07,  6.08it/s]\u001b[0m\n",
      "\u001b[34m{'loss': 5.2318, 'grad_norm': 304.22796630859375, 'learning_rate': 4.9000000000000005e-06, 'epoch': 0.13}\u001b[0m\n",
      "\u001b[34m4%|         | 50/1188 [00:17<03:07,  6.08it/s]\u001b[0m\n",
      "\u001b[34m4%|         | 51/1188 [00:18<03:10,  5.98it/s]\u001b[0m\n",
      "\u001b[34m4%|         | 52/1188 [00:18<03:09,  5.99it/s]\u001b[0m\n",
      "\u001b[34m4%|         | 53/1188 [00:18<03:08,  6.01it/s]\u001b[0m\n",
      "\u001b[34m5%|         | 54/1188 [00:18<03:08,  6.01it/s]\u001b[0m\n",
      "\u001b[34m5%|         | 55/1188 [00:18<03:08,  6.00it/s]\u001b[0m\n",
      "\u001b[34m5%|         | 56/1188 [00:18<03:08,  6.01it/s]\u001b[0m\n",
      "\u001b[34m5%|         | 57/1188 [00:19<03:08,  6.01it/s]\u001b[0m\n",
      "\u001b[34m5%|         | 58/1188 [00:19<03:08,  6.00it/s]\u001b[0m\n",
      "\u001b[34m5%|         | 59/1188 [00:19<03:07,  6.02it/s]\u001b[0m\n",
      "\u001b[34m5%|         | 60/1188 [00:19<03:07,  6.01it/s]\u001b[0m\n",
      "\u001b[34m5%|         | 61/1188 [00:19<03:07,  6.02it/s]\u001b[0m\n",
      "\u001b[34m5%|         | 62/1188 [00:19<03:07,  6.02it/s]\u001b[0m\n",
      "\u001b[34m5%|         | 63/1188 [00:20<03:07,  6.01it/s]\u001b[0m\n",
      "\u001b[34m5%|         | 64/1188 [00:20<03:07,  6.00it/s]\u001b[0m\n",
      "\u001b[34m5%|         | 65/1188 [00:20<03:06,  6.03it/s]\u001b[0m\n",
      "\u001b[34m6%|         | 66/1188 [00:20<03:06,  6.02it/s]\u001b[0m\n",
      "\u001b[34m6%|         | 67/1188 [00:20<03:07,  5.99it/s]\u001b[0m\n",
      "\u001b[34m6%|         | 68/1188 [00:20<03:06,  6.01it/s]\u001b[0m\n",
      "\u001b[34m6%|         | 69/1188 [00:21<03:05,  6.03it/s]\u001b[0m\n",
      "\u001b[34m6%|         | 70/1188 [00:21<03:05,  6.03it/s]\u001b[0m\n",
      "\u001b[34m6%|         | 71/1188 [00:21<03:03,  6.09it/s]\u001b[0m\n",
      "\u001b[34m6%|         | 72/1188 [00:21<03:04,  6.05it/s]\u001b[0m\n",
      "\u001b[34m6%|         | 73/1188 [00:21<03:04,  6.05it/s]\u001b[0m\n",
      "\u001b[34m6%|         | 74/1188 [00:21<03:03,  6.07it/s]\u001b[0m\n",
      "\u001b[34m6%|         | 75/1188 [00:22<03:03,  6.08it/s]\u001b[0m\n",
      "\u001b[34m6%|         | 76/1188 [00:22<03:03,  6.06it/s]\u001b[0m\n",
      "\u001b[34m6%|         | 77/1188 [00:22<03:02,  6.09it/s]\u001b[0m\n",
      "\u001b[34m7%|         | 78/1188 [00:22<03:03,  6.06it/s]\u001b[0m\n",
      "\u001b[34m7%|         | 79/1188 [00:22<03:01,  6.09it/s]\u001b[0m\n",
      "\u001b[34m7%|         | 80/1188 [00:22<03:01,  6.11it/s]\u001b[0m\n",
      "\u001b[34m7%|         | 81/1188 [00:23<03:01,  6.08it/s]\u001b[0m\n",
      "\u001b[34m7%|         | 82/1188 [00:23<03:01,  6.10it/s]\u001b[0m\n",
      "\u001b[34m7%|         | 83/1188 [00:23<03:00,  6.11it/s]\u001b[0m\n",
      "\u001b[34m7%|         | 84/1188 [00:23<03:02,  6.05it/s]\u001b[0m\n",
      "\u001b[34m7%|         | 85/1188 [00:23<03:01,  6.07it/s]\u001b[0m\n",
      "\u001b[34m7%|         | 86/1188 [00:23<03:01,  6.08it/s]\u001b[0m\n",
      "\u001b[34m7%|         | 87/1188 [00:24<03:01,  6.07it/s]\u001b[0m\n",
      "\u001b[34m7%|         | 88/1188 [00:24<03:00,  6.08it/s]\u001b[0m\n",
      "\u001b[34m7%|         | 89/1188 [00:24<03:00,  6.09it/s]\u001b[0m\n",
      "\u001b[34m8%|         | 90/1188 [00:24<03:00,  6.08it/s]\u001b[0m\n",
      "\u001b[34m8%|         | 91/1188 [00:24<03:01,  6.05it/s]\u001b[0m\n",
      "\u001b[34m8%|         | 92/1188 [00:24<03:01,  6.05it/s]\u001b[0m\n",
      "\u001b[34m8%|         | 93/1188 [00:25<03:00,  6.06it/s]\u001b[0m\n",
      "\u001b[34m8%|         | 94/1188 [00:25<03:00,  6.07it/s]\u001b[0m\n",
      "\u001b[34m8%|         | 95/1188 [00:25<03:00,  6.04it/s]\u001b[0m\n",
      "\u001b[34m8%|         | 96/1188 [00:25<03:00,  6.05it/s]\u001b[0m\n",
      "\u001b[34m8%|         | 97/1188 [00:25<03:00,  6.04it/s]\u001b[0m\n",
      "\u001b[34m8%|         | 98/1188 [00:25<03:01,  6.02it/s]\u001b[0m\n",
      "\u001b[34m8%|         | 99/1188 [00:26<03:00,  6.04it/s]\u001b[0m\n",
      "\u001b[34m8%|         | 100/1188 [00:26<03:00,  6.04it/s]\u001b[0m\n",
      "\u001b[34m{'loss': 4.2604, 'grad_norm': 152.40869140625, 'learning_rate': 9.900000000000002e-06, 'epoch': 0.25}\u001b[0m\n",
      "\u001b[34m8%|         | 100/1188 [00:26<03:00,  6.04it/s]\u001b[0m\n",
      "\u001b[34m9%|         | 101/1188 [00:26<03:00,  6.04it/s]\u001b[0m\n",
      "\u001b[34m9%|         | 102/1188 [00:26<02:59,  6.04it/s]\u001b[0m\n",
      "\u001b[34m9%|         | 103/1188 [00:26<02:59,  6.03it/s]\u001b[0m\n",
      "\u001b[34m9%|         | 104/1188 [00:26<02:59,  6.04it/s]\u001b[0m\n",
      "\u001b[34m9%|         | 105/1188 [00:27<02:59,  6.04it/s]\u001b[0m\n",
      "\u001b[34m9%|         | 106/1188 [00:27<02:59,  6.04it/s]\u001b[0m\n",
      "\u001b[34m9%|         | 107/1188 [00:27<02:58,  6.04it/s]\u001b[0m\n",
      "\u001b[34m9%|         | 108/1188 [00:27<02:58,  6.06it/s]\u001b[0m\n",
      "\u001b[34m9%|         | 109/1188 [00:27<02:58,  6.05it/s]\u001b[0m\n",
      "\u001b[34m9%|         | 110/1188 [00:27<02:58,  6.04it/s]\u001b[0m\n",
      "\u001b[34m9%|         | 111/1188 [00:27<02:57,  6.07it/s]\u001b[0m\n",
      "\u001b[34m9%|         | 112/1188 [00:28<02:57,  6.05it/s]\u001b[0m\n",
      "\u001b[34m10%|         | 113/1188 [00:28<02:57,  6.06it/s]\u001b[0m\n",
      "\u001b[34m10%|         | 114/1188 [00:28<02:56,  6.07it/s]\u001b[0m\n",
      "\u001b[34m10%|         | 115/1188 [00:28<02:57,  6.03it/s]\u001b[0m\n",
      "\u001b[34m10%|         | 116/1188 [00:28<02:57,  6.04it/s]\u001b[0m\n",
      "\u001b[34m10%|         | 117/1188 [00:28<02:57,  6.05it/s]\u001b[0m\n",
      "\u001b[34m10%|         | 118/1188 [00:29<02:56,  6.06it/s]\u001b[0m\n",
      "\u001b[34m10%|         | 119/1188 [00:29<02:56,  6.07it/s]\u001b[0m\n",
      "\u001b[34m10%|         | 120/1188 [00:29<02:56,  6.07it/s]\u001b[0m\n",
      "\u001b[34m10%|         | 121/1188 [00:29<02:55,  6.06it/s]\u001b[0m\n",
      "\u001b[34m10%|         | 122/1188 [00:29<02:55,  6.07it/s]\u001b[0m\n",
      "\u001b[34m10%|         | 123/1188 [00:29<02:55,  6.08it/s]\u001b[0m\n",
      "\u001b[34m10%|         | 124/1188 [00:30<02:55,  6.07it/s]\u001b[0m\n",
      "\u001b[34m11%|         | 125/1188 [00:30<02:56,  6.04it/s]\u001b[0m\n",
      "\u001b[34m11%|         | 126/1188 [00:30<02:55,  6.05it/s]\u001b[0m\n",
      "\u001b[34m11%|         | 127/1188 [00:30<02:55,  6.05it/s]\u001b[0m\n",
      "\u001b[34m11%|         | 128/1188 [00:30<02:56,  6.02it/s]\u001b[0m\n",
      "\u001b[34m11%|         | 129/1188 [00:30<02:55,  6.03it/s]\u001b[0m\n",
      "\u001b[34m11%|         | 130/1188 [00:31<02:55,  6.03it/s]\u001b[0m\n",
      "\u001b[34m11%|         | 131/1188 [00:31<02:55,  6.04it/s]\u001b[0m\n",
      "\u001b[34m11%|         | 132/1188 [00:31<02:54,  6.07it/s]\u001b[0m\n",
      "\u001b[34m11%|         | 133/1188 [00:31<02:53,  6.08it/s]\u001b[0m\n",
      "\u001b[34m11%|        | 134/1188 [00:31<02:53,  6.06it/s]\u001b[0m\n",
      "\u001b[34m11%|        | 135/1188 [00:31<02:53,  6.08it/s]\u001b[0m\n",
      "\u001b[34m11%|        | 136/1188 [00:32<02:53,  6.07it/s]\u001b[0m\n",
      "\u001b[34m12%|        | 137/1188 [00:32<02:53,  6.06it/s]\u001b[0m\n",
      "\u001b[34m12%|        | 138/1188 [00:32<02:52,  6.08it/s]\u001b[0m\n",
      "\u001b[34m12%|        | 139/1188 [00:32<02:52,  6.08it/s]\u001b[0m\n",
      "\u001b[34m12%|        | 140/1188 [00:32<02:52,  6.07it/s]\u001b[0m\n",
      "\u001b[34m12%|        | 141/1188 [00:32<02:52,  6.08it/s]\u001b[0m\n",
      "\u001b[34m12%|        | 142/1188 [00:33<02:52,  6.06it/s]\u001b[0m\n",
      "\u001b[34m12%|        | 143/1188 [00:33<02:52,  6.06it/s]\u001b[0m\n",
      "\u001b[34m12%|        | 144/1188 [00:33<02:52,  6.04it/s]\u001b[0m\n",
      "\u001b[34m12%|        | 145/1188 [00:33<02:51,  6.07it/s]\u001b[0m\n",
      "\u001b[34m12%|        | 146/1188 [00:33<02:52,  6.05it/s]\u001b[0m\n",
      "\u001b[34m12%|        | 147/1188 [00:33<02:51,  6.08it/s]\u001b[0m\n",
      "\u001b[34m12%|        | 148/1188 [00:34<02:50,  6.09it/s]\u001b[0m\n",
      "\u001b[34m13%|        | 149/1188 [00:34<02:50,  6.10it/s]\u001b[0m\n",
      "\u001b[34m13%|        | 150/1188 [00:34<02:49,  6.12it/s]\u001b[0m\n",
      "\u001b[34m{'loss': 3.9166, 'grad_norm': 137.96926879882812, 'learning_rate': 1.49e-05, 'epoch': 0.38}\u001b[0m\n",
      "\u001b[34m13%|        | 150/1188 [00:34<02:49,  6.12it/s]\u001b[0m\n",
      "\u001b[34m13%|        | 151/1188 [00:34<02:49,  6.12it/s]\u001b[0m\n",
      "\u001b[34m13%|        | 152/1188 [00:34<02:50,  6.09it/s]\u001b[0m\n",
      "\u001b[34m13%|        | 153/1188 [00:34<02:49,  6.12it/s]\u001b[0m\n",
      "\u001b[34m13%|        | 154/1188 [00:35<02:49,  6.11it/s]\u001b[0m\n",
      "\u001b[34m13%|        | 155/1188 [00:35<02:50,  6.08it/s]\u001b[0m\n",
      "\u001b[34m13%|        | 156/1188 [00:35<02:50,  6.06it/s]\u001b[0m\n",
      "\u001b[34m13%|        | 157/1188 [00:35<02:49,  6.08it/s]\u001b[0m\n",
      "\u001b[34m13%|        | 158/1188 [00:35<02:51,  5.99it/s]\u001b[0m\n",
      "\u001b[34m13%|        | 159/1188 [00:35<02:50,  6.02it/s]\u001b[0m\n",
      "\u001b[34m13%|        | 160/1188 [00:36<02:50,  6.03it/s]\u001b[0m\n",
      "\u001b[34m14%|        | 161/1188 [00:36<02:50,  6.01it/s]\u001b[0m\n",
      "\u001b[34m14%|        | 162/1188 [00:36<02:49,  6.05it/s]\u001b[0m\n",
      "\u001b[34m14%|        | 163/1188 [00:36<02:49,  6.06it/s]\u001b[0m\n",
      "\u001b[34m14%|        | 164/1188 [00:36<02:49,  6.02it/s]\u001b[0m\n",
      "\u001b[34m14%|        | 165/1188 [00:36<02:49,  6.02it/s]\u001b[0m\n",
      "\u001b[34m14%|        | 166/1188 [00:37<02:49,  6.01it/s]\u001b[0m\n",
      "\u001b[34m14%|        | 167/1188 [00:37<02:49,  6.02it/s]\u001b[0m\n",
      "\u001b[34m14%|        | 168/1188 [00:37<02:49,  6.03it/s]\u001b[0m\n",
      "\u001b[34m14%|        | 169/1188 [00:37<02:48,  6.04it/s]\u001b[0m\n",
      "\u001b[34m14%|        | 170/1188 [00:37<02:49,  6.00it/s]\u001b[0m\n",
      "\u001b[34m14%|        | 171/1188 [00:37<02:49,  6.00it/s]\u001b[0m\n",
      "\u001b[34m14%|        | 172/1188 [00:38<02:49,  6.01it/s]\u001b[0m\n",
      "\u001b[34m15%|        | 173/1188 [00:38<02:48,  6.01it/s]\u001b[0m\n",
      "\u001b[34m15%|        | 174/1188 [00:38<02:48,  6.00it/s]\u001b[0m\n",
      "\u001b[34m15%|        | 175/1188 [00:38<02:48,  6.02it/s]\u001b[0m\n",
      "\u001b[34m15%|        | 176/1188 [00:38<02:48,  5.99it/s]\u001b[0m\n",
      "\u001b[34m15%|        | 177/1188 [00:38<02:48,  6.01it/s]\u001b[0m\n",
      "\u001b[34m15%|        | 178/1188 [00:39<02:47,  6.03it/s]\u001b[0m\n",
      "\u001b[34m15%|        | 179/1188 [00:39<02:47,  6.03it/s]\u001b[0m\n",
      "\u001b[34m15%|        | 180/1188 [00:39<02:46,  6.07it/s]\u001b[0m\n",
      "\u001b[34m15%|        | 181/1188 [00:39<02:45,  6.09it/s]\u001b[0m\n",
      "\u001b[34m15%|        | 182/1188 [00:39<02:45,  6.08it/s]\u001b[0m\n",
      "\u001b[34m15%|        | 183/1188 [00:39<02:45,  6.08it/s]\u001b[0m\n",
      "\u001b[34m15%|        | 184/1188 [00:40<02:45,  6.07it/s]\u001b[0m\n",
      "\u001b[34m16%|        | 185/1188 [00:40<02:45,  6.07it/s]\u001b[0m\n",
      "\u001b[34m16%|        | 186/1188 [00:40<02:45,  6.05it/s]\u001b[0m\n",
      "\u001b[34m16%|        | 187/1188 [00:40<02:45,  6.06it/s]\u001b[0m\n",
      "\u001b[34m16%|        | 188/1188 [00:40<02:46,  5.99it/s]\u001b[0m\n",
      "\u001b[34m16%|        | 189/1188 [00:40<02:46,  6.00it/s]\u001b[0m\n",
      "\u001b[34m16%|        | 190/1188 [00:41<02:45,  6.01it/s]\u001b[0m\n",
      "\u001b[34m16%|        | 191/1188 [00:41<02:45,  6.02it/s]\u001b[0m\n",
      "\u001b[34m16%|        | 192/1188 [00:41<02:45,  6.03it/s]\u001b[0m\n",
      "\u001b[34m16%|        | 193/1188 [00:41<02:44,  6.04it/s]\u001b[0m\n",
      "\u001b[34m16%|        | 194/1188 [00:41<02:44,  6.05it/s]\u001b[0m\n",
      "\u001b[34m16%|        | 195/1188 [00:41<02:44,  6.04it/s]\u001b[0m\n",
      "\u001b[34m16%|        | 196/1188 [00:42<02:43,  6.07it/s]\u001b[0m\n",
      "\u001b[34m17%|        | 197/1188 [00:42<02:43,  6.05it/s]\u001b[0m\n",
      "\u001b[34m17%|        | 198/1188 [00:42<02:43,  6.07it/s]\u001b[0m\n",
      "\u001b[34m17%|        | 199/1188 [00:42<02:43,  6.06it/s]\u001b[0m\n",
      "\u001b[34m17%|        | 200/1188 [00:42<02:41,  6.10it/s]\u001b[0m\n",
      "\u001b[34m{'loss': 3.7751, 'grad_norm': 156.15478515625, 'learning_rate': 1.9900000000000003e-05, 'epoch': 0.51}\u001b[0m\n",
      "\u001b[34m17%|        | 200/1188 [00:42<02:41,  6.10it/s]\u001b[0m\n",
      "\u001b[34m17%|        | 201/1188 [00:42<02:42,  6.08it/s]\u001b[0m\n",
      "\u001b[34m17%|        | 202/1188 [00:43<02:41,  6.11it/s]\u001b[0m\n",
      "\u001b[34m17%|        | 203/1188 [00:43<02:41,  6.09it/s]\u001b[0m\n",
      "\u001b[34m17%|        | 204/1188 [00:43<02:41,  6.08it/s]\u001b[0m\n",
      "\u001b[34m17%|        | 205/1188 [00:43<02:42,  6.05it/s]\u001b[0m\n",
      "\u001b[34m17%|        | 206/1188 [00:43<02:43,  6.01it/s]\u001b[0m\n",
      "\u001b[34m17%|        | 207/1188 [00:43<02:43,  6.01it/s]\u001b[0m\n",
      "\u001b[34m18%|        | 208/1188 [00:44<02:42,  6.03it/s]\u001b[0m\n",
      "\u001b[34m18%|        | 209/1188 [00:44<02:42,  6.03it/s]\u001b[0m\n",
      "\u001b[34m18%|        | 210/1188 [00:44<02:41,  6.06it/s]\u001b[0m\n",
      "\u001b[34m18%|        | 211/1188 [00:44<02:40,  6.07it/s]\u001b[0m\n",
      "\u001b[34m18%|        | 212/1188 [00:44<02:40,  6.08it/s]\u001b[0m\n",
      "\u001b[34m18%|        | 213/1188 [00:44<02:41,  6.04it/s]\u001b[0m\n",
      "\u001b[34m18%|        | 214/1188 [00:45<02:40,  6.06it/s]\u001b[0m\n",
      "\u001b[34m18%|        | 215/1188 [00:45<02:39,  6.09it/s]\u001b[0m\n",
      "\u001b[34m18%|        | 216/1188 [00:45<02:40,  6.07it/s]\u001b[0m\n",
      "\u001b[34m18%|        | 217/1188 [00:45<02:39,  6.08it/s]\u001b[0m\n",
      "\u001b[34m18%|        | 218/1188 [00:45<02:38,  6.11it/s]\u001b[0m\n",
      "\u001b[34m18%|        | 219/1188 [00:45<02:41,  6.01it/s]\u001b[0m\n",
      "\u001b[34m19%|        | 220/1188 [00:45<02:40,  6.04it/s]\u001b[0m\n",
      "\u001b[34m19%|        | 221/1188 [00:46<02:40,  6.04it/s]\u001b[0m\n",
      "\u001b[34m19%|        | 222/1188 [00:46<02:39,  6.04it/s]\u001b[0m\n",
      "\u001b[34m19%|        | 223/1188 [00:46<02:39,  6.05it/s]\u001b[0m\n",
      "\u001b[34m19%|        | 224/1188 [00:46<02:39,  6.06it/s]\u001b[0m\n",
      "\u001b[34m19%|        | 225/1188 [00:46<02:39,  6.04it/s]\u001b[0m\n",
      "\u001b[34m19%|        | 226/1188 [00:46<02:39,  6.02it/s]\u001b[0m\n",
      "\u001b[34m19%|        | 227/1188 [00:47<02:40,  6.00it/s]\u001b[0m\n",
      "\u001b[34m19%|        | 228/1188 [00:47<02:39,  6.01it/s]\u001b[0m\n",
      "\u001b[34m19%|        | 229/1188 [00:47<02:38,  6.04it/s]\u001b[0m\n",
      "\u001b[34m19%|        | 230/1188 [00:47<02:38,  6.04it/s]\u001b[0m\n",
      "\u001b[34m19%|        | 231/1188 [00:47<02:38,  6.03it/s]\u001b[0m\n",
      "\u001b[34m20%|        | 232/1188 [00:47<02:37,  6.08it/s]\u001b[0m\n",
      "\u001b[34m20%|        | 233/1188 [00:48<02:37,  6.07it/s]\u001b[0m\n",
      "\u001b[34m20%|        | 234/1188 [00:48<02:37,  6.08it/s]\u001b[0m\n",
      "\u001b[34m20%|        | 235/1188 [00:48<02:36,  6.07it/s]\u001b[0m\n",
      "\u001b[34m20%|        | 236/1188 [00:48<02:36,  6.08it/s]\u001b[0m\n",
      "\u001b[34m20%|        | 237/1188 [00:48<02:36,  6.07it/s]\u001b[0m\n",
      "\u001b[34m20%|        | 238/1188 [00:48<02:36,  6.05it/s]\u001b[0m\n",
      "\u001b[34m20%|        | 239/1188 [00:49<02:37,  6.03it/s]\u001b[0m\n",
      "\u001b[34m20%|        | 240/1188 [00:49<02:37,  6.03it/s]\u001b[0m\n",
      "\u001b[34m20%|        | 241/1188 [00:49<02:36,  6.06it/s]\u001b[0m\n",
      "\u001b[34m20%|        | 242/1188 [00:49<02:35,  6.08it/s]\u001b[0m\n",
      "\u001b[34m20%|        | 243/1188 [00:49<02:36,  6.04it/s]\u001b[0m\n",
      "\u001b[34m21%|        | 244/1188 [00:49<02:36,  6.04it/s]\u001b[0m\n",
      "\u001b[34m21%|        | 245/1188 [00:50<02:35,  6.06it/s]\u001b[0m\n",
      "\u001b[34m21%|        | 246/1188 [00:50<02:35,  6.06it/s]\u001b[0m\n",
      "\u001b[34m21%|        | 247/1188 [00:50<02:35,  6.05it/s]\u001b[0m\n",
      "\u001b[34m21%|        | 248/1188 [00:50<02:35,  6.06it/s]\u001b[0m\n",
      "\u001b[34m21%|        | 249/1188 [00:50<02:37,  5.97it/s]\u001b[0m\n",
      "\u001b[34m21%|        | 250/1188 [00:50<02:36,  5.98it/s]\u001b[0m\n",
      "\u001b[34m{'loss': 3.6919, 'grad_norm': 75.73487091064453, 'learning_rate': 2.4900000000000002e-05, 'epoch': 0.63}\u001b[0m\n",
      "\u001b[34m21%|        | 250/1188 [00:50<02:36,  5.98it/s]\u001b[0m\n",
      "\u001b[34m21%|        | 251/1188 [00:51<02:36,  5.99it/s]\u001b[0m\n",
      "\u001b[34m21%|        | 252/1188 [00:51<02:35,  6.02it/s]\u001b[0m\n",
      "\u001b[34m21%|       | 253/1188 [00:51<02:35,  6.03it/s]\u001b[0m\n",
      "\u001b[34m21%|       | 254/1188 [00:51<02:34,  6.03it/s]\u001b[0m\n",
      "\u001b[34m21%|       | 255/1188 [00:51<02:34,  6.03it/s]\u001b[0m\n",
      "\u001b[34m22%|       | 256/1188 [00:51<02:34,  6.03it/s]\u001b[0m\n",
      "\u001b[34m22%|       | 257/1188 [00:52<02:33,  6.05it/s]\u001b[0m\n",
      "\u001b[34m22%|       | 258/1188 [00:52<02:33,  6.06it/s]\u001b[0m\n",
      "\u001b[34m22%|       | 259/1188 [00:52<02:32,  6.10it/s]\u001b[0m\n",
      "\u001b[34m22%|       | 260/1188 [00:52<02:34,  6.00it/s]\u001b[0m\n",
      "\u001b[34m22%|       | 261/1188 [00:52<02:34,  6.01it/s]\u001b[0m\n",
      "\u001b[34m22%|       | 262/1188 [00:52<02:34,  6.00it/s]\u001b[0m\n",
      "\u001b[34m22%|       | 263/1188 [00:53<02:33,  6.02it/s]\u001b[0m\n",
      "\u001b[34m22%|       | 264/1188 [00:53<02:33,  6.04it/s]\u001b[0m\n",
      "\u001b[34m22%|       | 265/1188 [00:53<02:32,  6.04it/s]\u001b[0m\n",
      "\u001b[34m22%|       | 266/1188 [00:53<02:32,  6.04it/s]\u001b[0m\n",
      "\u001b[34m22%|       | 267/1188 [00:53<02:32,  6.04it/s]\u001b[0m\n",
      "\u001b[34m23%|       | 268/1188 [00:53<02:32,  6.03it/s]\u001b[0m\n",
      "\u001b[34m23%|       | 269/1188 [00:54<02:32,  6.03it/s]\u001b[0m\n",
      "\u001b[34m23%|       | 270/1188 [00:54<02:32,  6.04it/s]\u001b[0m\n",
      "\u001b[34m23%|       | 271/1188 [00:54<02:31,  6.05it/s]\u001b[0m\n",
      "\u001b[34m23%|       | 272/1188 [00:54<02:31,  6.06it/s]\u001b[0m\n",
      "\u001b[34m23%|       | 273/1188 [00:54<02:30,  6.07it/s]\u001b[0m\n",
      "\u001b[34m23%|       | 274/1188 [00:54<02:30,  6.06it/s]\u001b[0m\n",
      "\u001b[34m23%|       | 275/1188 [00:55<02:30,  6.06it/s]\u001b[0m\n",
      "\u001b[34m23%|       | 276/1188 [00:55<02:30,  6.06it/s]\u001b[0m\n",
      "\u001b[34m23%|       | 277/1188 [00:55<02:31,  6.02it/s]\u001b[0m\n",
      "\u001b[34m23%|       | 278/1188 [00:55<02:30,  6.03it/s]\u001b[0m\n",
      "\u001b[34m23%|       | 279/1188 [00:55<02:32,  5.97it/s]\u001b[0m\n",
      "\u001b[34m24%|       | 280/1188 [00:55<02:32,  5.95it/s]\u001b[0m\n",
      "\u001b[34m24%|       | 281/1188 [00:56<02:31,  5.98it/s]\u001b[0m\n",
      "\u001b[34m24%|       | 282/1188 [00:56<02:31,  6.00it/s]\u001b[0m\n",
      "\u001b[34m24%|       | 283/1188 [00:56<02:29,  6.04it/s]\u001b[0m\n",
      "\u001b[34m24%|       | 284/1188 [00:56<02:29,  6.05it/s]\u001b[0m\n",
      "\u001b[34m24%|       | 285/1188 [00:56<02:28,  6.06it/s]\u001b[0m\n",
      "\u001b[34m24%|       | 286/1188 [00:56<02:29,  6.04it/s]\u001b[0m\n",
      "\u001b[34m24%|       | 287/1188 [00:57<02:28,  6.07it/s]\u001b[0m\n",
      "\u001b[34m24%|       | 288/1188 [00:57<02:28,  6.05it/s]\u001b[0m\n",
      "\u001b[34m24%|       | 289/1188 [00:57<02:28,  6.07it/s]\u001b[0m\n",
      "\u001b[34m24%|       | 290/1188 [00:57<02:27,  6.09it/s]\u001b[0m\n",
      "\u001b[34m24%|       | 291/1188 [00:57<02:27,  6.09it/s]\u001b[0m\n",
      "\u001b[34m25%|       | 292/1188 [00:57<02:27,  6.07it/s]\u001b[0m\n",
      "\u001b[34m25%|       | 293/1188 [00:58<02:27,  6.07it/s]\u001b[0m\n",
      "\u001b[34m25%|       | 294/1188 [00:58<02:27,  6.08it/s]\u001b[0m\n",
      "\u001b[34m25%|       | 295/1188 [00:58<02:27,  6.07it/s]\u001b[0m\n",
      "\u001b[34m25%|       | 296/1188 [00:58<02:26,  6.09it/s]\u001b[0m\n",
      "\u001b[34m25%|       | 297/1188 [00:58<02:26,  6.10it/s]\u001b[0m\n",
      "\u001b[34m25%|       | 298/1188 [00:58<02:26,  6.08it/s]\u001b[0m\n",
      "\u001b[34m25%|       | 299/1188 [00:59<02:26,  6.06it/s]\u001b[0m\n",
      "\u001b[34m25%|       | 300/1188 [00:59<02:26,  6.05it/s]\u001b[0m\n",
      "\u001b[34m{'loss': 3.6085, 'grad_norm': 54.11947250366211, 'learning_rate': 2.9900000000000002e-05, 'epoch': 0.76}\u001b[0m\n",
      "\u001b[34m25%|       | 300/1188 [00:59<02:26,  6.05it/s]\u001b[0m\n",
      "\u001b[34m25%|       | 301/1188 [00:59<02:27,  6.03it/s]\u001b[0m\n",
      "\u001b[34m25%|       | 302/1188 [00:59<02:26,  6.05it/s]\u001b[0m\n",
      "\u001b[34m26%|       | 303/1188 [00:59<02:25,  6.07it/s]\u001b[0m\n",
      "\u001b[34m26%|       | 304/1188 [00:59<02:25,  6.07it/s]\u001b[0m\n",
      "\u001b[34m26%|       | 305/1188 [01:00<02:25,  6.06it/s]\u001b[0m\n",
      "\u001b[34m26%|       | 306/1188 [01:00<02:24,  6.09it/s]\u001b[0m\n",
      "\u001b[34m26%|       | 307/1188 [01:00<02:24,  6.11it/s]\u001b[0m\n",
      "\u001b[34m26%|       | 308/1188 [01:00<02:23,  6.12it/s]\u001b[0m\n",
      "\u001b[34m26%|       | 309/1188 [01:00<02:25,  6.06it/s]\u001b[0m\n",
      "\u001b[34m26%|       | 310/1188 [01:00<02:25,  6.03it/s]\u001b[0m\n",
      "\u001b[34m26%|       | 311/1188 [01:01<02:24,  6.06it/s]\u001b[0m\n",
      "\u001b[34m26%|       | 312/1188 [01:01<02:24,  6.07it/s]\u001b[0m\n",
      "\u001b[34m26%|       | 313/1188 [01:01<02:24,  6.07it/s]\u001b[0m\n",
      "\u001b[34m26%|       | 314/1188 [01:01<02:23,  6.08it/s]\u001b[0m\n",
      "\u001b[34m27%|       | 315/1188 [01:01<02:23,  6.10it/s]\u001b[0m\n",
      "\u001b[34m27%|       | 316/1188 [01:01<02:23,  6.09it/s]\u001b[0m\n",
      "\u001b[34m27%|       | 317/1188 [01:02<02:23,  6.07it/s]\u001b[0m\n",
      "\u001b[34m27%|       | 318/1188 [01:02<02:23,  6.06it/s]\u001b[0m\n",
      "\u001b[34m27%|       | 319/1188 [01:02<02:22,  6.08it/s]\u001b[0m\n",
      "\u001b[34m27%|       | 320/1188 [01:02<02:22,  6.08it/s]\u001b[0m\n",
      "\u001b[34m27%|       | 321/1188 [01:02<02:22,  6.10it/s]\u001b[0m\n",
      "\u001b[34m27%|       | 322/1188 [01:02<02:22,  6.09it/s]\u001b[0m\n",
      "\u001b[34m27%|       | 323/1188 [01:03<02:22,  6.07it/s]\u001b[0m\n",
      "\u001b[34m27%|       | 324/1188 [01:03<02:22,  6.06it/s]\u001b[0m\n",
      "\u001b[34m27%|       | 325/1188 [01:03<02:21,  6.08it/s]\u001b[0m\n",
      "\u001b[34m27%|       | 326/1188 [01:03<02:21,  6.09it/s]\u001b[0m\n",
      "\u001b[34m28%|       | 327/1188 [01:03<02:21,  6.09it/s]\u001b[0m\n",
      "\u001b[34m28%|       | 328/1188 [01:03<02:21,  6.09it/s]\u001b[0m\n",
      "\u001b[34m28%|       | 329/1188 [01:04<02:21,  6.07it/s]\u001b[0m\n",
      "\u001b[34m28%|       | 330/1188 [01:04<02:21,  6.05it/s]\u001b[0m\n",
      "\u001b[34m28%|       | 331/1188 [01:04<02:21,  6.06it/s]\u001b[0m\n",
      "\u001b[34m28%|       | 332/1188 [01:04<02:20,  6.08it/s]\u001b[0m\n",
      "\u001b[34m28%|       | 333/1188 [01:04<02:21,  6.05it/s]\u001b[0m\n",
      "\u001b[34m28%|       | 334/1188 [01:04<02:20,  6.07it/s]\u001b[0m\n",
      "\u001b[34m28%|       | 335/1188 [01:05<02:21,  6.02it/s]\u001b[0m\n",
      "\u001b[34m28%|       | 336/1188 [01:05<02:20,  6.07it/s]\u001b[0m\n",
      "\u001b[34m28%|       | 337/1188 [01:05<02:19,  6.09it/s]\u001b[0m\n",
      "\u001b[34m28%|       | 338/1188 [01:05<02:19,  6.10it/s]\u001b[0m\n",
      "\u001b[34m29%|       | 339/1188 [01:05<02:19,  6.10it/s]\u001b[0m\n",
      "\u001b[34m29%|       | 340/1188 [01:05<02:20,  6.04it/s]\u001b[0m\n",
      "\u001b[34m29%|       | 341/1188 [01:05<02:20,  6.01it/s]\u001b[0m\n",
      "\u001b[34m29%|       | 342/1188 [01:06<02:20,  6.03it/s]\u001b[0m\n",
      "\u001b[34m29%|       | 343/1188 [01:06<02:19,  6.05it/s]\u001b[0m\n",
      "\u001b[34m29%|       | 344/1188 [01:06<02:19,  6.05it/s]\u001b[0m\n",
      "\u001b[34m29%|       | 345/1188 [01:06<02:18,  6.07it/s]\u001b[0m\n",
      "\u001b[34m29%|       | 346/1188 [01:06<02:18,  6.07it/s]\u001b[0m\n",
      "\u001b[34m29%|       | 347/1188 [01:06<02:18,  6.06it/s]\u001b[0m\n",
      "\u001b[34m29%|       | 348/1188 [01:07<02:18,  6.06it/s]\u001b[0m\n",
      "\u001b[34m29%|       | 349/1188 [01:07<02:18,  6.06it/s]\u001b[0m\n",
      "\u001b[34m29%|       | 350/1188 [01:07<02:18,  6.07it/s]\u001b[0m\n",
      "\u001b[34m{'loss': 3.5073, 'grad_norm': 372.0257263183594, 'learning_rate': 3.49e-05, 'epoch': 0.88}\u001b[0m\n",
      "\u001b[34m29%|       | 350/1188 [01:07<02:18,  6.07it/s]\u001b[0m\n",
      "\u001b[34m30%|       | 351/1188 [01:07<02:17,  6.07it/s]\u001b[0m\n",
      "\u001b[34m30%|       | 352/1188 [01:07<02:17,  6.06it/s]\u001b[0m\n",
      "\u001b[34m30%|       | 353/1188 [01:07<02:17,  6.06it/s]\u001b[0m\n",
      "\u001b[34m30%|       | 354/1188 [01:08<02:17,  6.06it/s]\u001b[0m\n",
      "\u001b[34m30%|       | 355/1188 [01:08<02:17,  6.05it/s]\u001b[0m\n",
      "\u001b[34m30%|       | 356/1188 [01:08<02:17,  6.04it/s]\u001b[0m\n",
      "\u001b[34m30%|       | 357/1188 [01:08<02:17,  6.06it/s]\u001b[0m\n",
      "\u001b[34m30%|       | 358/1188 [01:08<02:16,  6.06it/s]\u001b[0m\n",
      "\u001b[34m30%|       | 359/1188 [01:08<02:16,  6.06it/s]\u001b[0m\n",
      "\u001b[34m30%|       | 360/1188 [01:09<02:16,  6.06it/s]\u001b[0m\n",
      "\u001b[34m30%|       | 361/1188 [01:09<02:16,  6.04it/s]\u001b[0m\n",
      "\u001b[34m30%|       | 362/1188 [01:09<02:16,  6.04it/s]\u001b[0m\n",
      "\u001b[34m31%|       | 363/1188 [01:09<02:16,  6.06it/s]\u001b[0m\n",
      "\u001b[34m31%|       | 364/1188 [01:09<02:16,  6.06it/s]\u001b[0m\n",
      "\u001b[34m31%|       | 365/1188 [01:09<02:15,  6.08it/s]\u001b[0m\n",
      "\u001b[34m31%|       | 366/1188 [01:10<02:15,  6.06it/s]\u001b[0m\n",
      "\u001b[34m31%|       | 367/1188 [01:10<02:15,  6.07it/s]\u001b[0m\n",
      "\u001b[34m31%|       | 368/1188 [01:10<02:15,  6.04it/s]\u001b[0m\n",
      "\u001b[34m31%|       | 369/1188 [01:10<02:15,  6.05it/s]\u001b[0m\n",
      "\u001b[34m31%|       | 370/1188 [01:10<02:16,  6.00it/s]\u001b[0m\n",
      "\u001b[34m31%|       | 371/1188 [01:10<02:15,  6.01it/s]\u001b[0m\n",
      "\u001b[34m31%|      | 372/1188 [01:11<02:15,  6.01it/s]\u001b[0m\n",
      "\u001b[34m31%|      | 373/1188 [01:11<02:15,  6.00it/s]\u001b[0m\n",
      "\u001b[34m31%|      | 374/1188 [01:11<02:15,  6.00it/s]\u001b[0m\n",
      "\u001b[34m32%|      | 375/1188 [01:11<02:15,  6.02it/s]\u001b[0m\n",
      "\u001b[34m32%|      | 376/1188 [01:11<02:14,  6.04it/s]\u001b[0m\n",
      "\u001b[34m32%|      | 377/1188 [01:11<02:14,  6.04it/s]\u001b[0m\n",
      "\u001b[34m32%|      | 378/1188 [01:12<02:14,  6.04it/s]\u001b[0m\n",
      "\u001b[34m32%|      | 379/1188 [01:12<02:13,  6.05it/s]\u001b[0m\n",
      "\u001b[34m32%|      | 380/1188 [01:12<02:13,  6.07it/s]\u001b[0m\n",
      "\u001b[34m32%|      | 381/1188 [01:12<02:12,  6.10it/s]\u001b[0m\n",
      "\u001b[34m32%|      | 382/1188 [01:12<02:12,  6.10it/s]\u001b[0m\n",
      "\u001b[34m32%|      | 383/1188 [01:12<02:11,  6.10it/s]\u001b[0m\n",
      "\u001b[34m32%|      | 384/1188 [01:13<02:12,  6.09it/s]\u001b[0m\n",
      "\u001b[34m32%|      | 385/1188 [01:13<02:11,  6.09it/s]\u001b[0m\n",
      "\u001b[34m32%|      | 386/1188 [01:13<02:11,  6.10it/s]\u001b[0m\n",
      "\u001b[34m33%|      | 387/1188 [01:13<02:12,  6.03it/s]\u001b[0m\n",
      "\u001b[34m33%|      | 388/1188 [01:13<02:16,  5.86it/s]\u001b[0m\n",
      "\u001b[34m33%|      | 389/1188 [01:13<02:15,  5.91it/s]\u001b[0m\n",
      "\u001b[34m33%|      | 390/1188 [01:14<02:14,  5.93it/s]\u001b[0m\n",
      "\u001b[34m33%|      | 391/1188 [01:14<02:14,  5.94it/s]\u001b[0m\n",
      "\u001b[34m33%|      | 392/1188 [01:14<02:13,  5.96it/s]\u001b[0m\n",
      "\u001b[34m33%|      | 393/1188 [01:14<02:12,  5.98it/s]\u001b[0m\n",
      "\u001b[34m33%|      | 394/1188 [01:14<02:12,  6.00it/s]\u001b[0m\n",
      "\u001b[34m33%|      | 395/1188 [01:14<02:12,  6.00it/s]\u001b[0m\n",
      "\u001b[34m33%|      | 396/1188 [01:15<02:11,  6.00it/s]\u001b[0m\n",
      "\u001b[34m0%|          | 0/396 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m2%|         | 6/396 [00:00<00:06, 59.29it/s]#033[A\u001b[0m\n",
      "\u001b[34m3%|         | 12/396 [00:00<00:07, 54.05it/s]#033[A\u001b[0m\n",
      "\u001b[34m5%|         | 18/396 [00:00<00:07, 52.84it/s]#033[A\u001b[0m\n",
      "\u001b[34m6%|         | 24/396 [00:00<00:07, 52.06it/s]#033[A\u001b[0m\n",
      "\u001b[34m8%|         | 30/396 [00:00<00:07, 51.58it/s]#033[A\u001b[0m\n",
      "\u001b[34m9%|         | 36/396 [00:00<00:07, 51.36it/s]#033[A\u001b[0m\n",
      "\u001b[34m11%|         | 42/396 [00:00<00:06, 51.21it/s]#033[A\u001b[0m\n",
      "\u001b[34m12%|        | 48/396 [00:00<00:06, 51.17it/s]#033[A\u001b[0m\n",
      "\u001b[34m14%|        | 54/396 [00:01<00:06, 51.12it/s]#033[A\u001b[0m\n",
      "\u001b[34m15%|        | 60/396 [00:01<00:06, 50.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m17%|        | 66/396 [00:01<00:06, 50.88it/s]#033[A\u001b[0m\n",
      "\u001b[34m18%|        | 72/396 [00:01<00:06, 50.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m20%|        | 78/396 [00:01<00:06, 50.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m21%|        | 84/396 [00:01<00:06, 50.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m23%|       | 90/396 [00:01<00:06, 50.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m24%|       | 96/396 [00:01<00:05, 50.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m26%|       | 102/396 [00:01<00:05, 51.14it/s]#033[A\u001b[0m\n",
      "\u001b[34m27%|       | 108/396 [00:02<00:05, 51.03it/s]#033[A\u001b[0m\n",
      "\u001b[34m29%|       | 114/396 [00:02<00:05, 51.03it/s]#033[A\u001b[0m\n",
      "\u001b[34m30%|       | 120/396 [00:02<00:05, 51.11it/s]#033[A\u001b[0m\n",
      "\u001b[34m32%|      | 126/396 [00:02<00:05, 51.27it/s]#033[A\u001b[0m\n",
      "\u001b[34m33%|      | 132/396 [00:02<00:05, 51.45it/s]#033[A\u001b[0m\n",
      "\u001b[34m35%|      | 138/396 [00:02<00:05, 51.39it/s]#033[A\u001b[0m\n",
      "\u001b[34m36%|      | 144/396 [00:02<00:04, 51.13it/s]#033[A\u001b[0m\n",
      "\u001b[34m38%|      | 150/396 [00:02<00:04, 51.20it/s]#033[A\u001b[0m\n",
      "\u001b[34m39%|      | 156/396 [00:03<00:04, 51.16it/s]#033[A\u001b[0m\n",
      "\u001b[34m41%|      | 162/396 [00:03<00:04, 51.06it/s]#033[A\u001b[0m\n",
      "\u001b[34m42%|     | 168/396 [00:03<00:04, 51.16it/s]#033[A\u001b[0m\n",
      "\u001b[34m44%|     | 174/396 [00:03<00:04, 51.57it/s]#033[A\u001b[0m\n",
      "\u001b[34m45%|     | 180/396 [00:03<00:04, 51.71it/s]#033[A\u001b[0m\n",
      "\u001b[34m47%|     | 186/396 [00:03<00:04, 51.49it/s]#033[A\u001b[0m\n",
      "\u001b[34m48%|     | 192/396 [00:03<00:04, 50.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m50%|     | 198/396 [00:03<00:03, 50.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m52%|    | 204/396 [00:03<00:03, 50.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m53%|    | 210/396 [00:04<00:03, 50.89it/s]#033[A\u001b[0m\n",
      "\u001b[34m55%|    | 216/396 [00:04<00:03, 50.86it/s]#033[A\u001b[0m\n",
      "\u001b[34m56%|    | 222/396 [00:04<00:03, 51.04it/s]#033[A\u001b[0m\n",
      "\u001b[34m58%|    | 228/396 [00:04<00:03, 51.03it/s]#033[A\u001b[0m\n",
      "\u001b[34m59%|    | 234/396 [00:04<00:03, 51.48it/s]#033[A\u001b[0m\n",
      "\u001b[34m61%|    | 240/396 [00:04<00:03, 51.31it/s]#033[A\u001b[0m\n",
      "\u001b[34m62%|   | 246/396 [00:04<00:02, 51.34it/s]#033[A\u001b[0m\n",
      "\u001b[34m64%|   | 252/396 [00:04<00:02, 51.35it/s]#033[A\u001b[0m\n",
      "\u001b[34m65%|   | 258/396 [00:05<00:02, 51.31it/s]#033[A\u001b[0m\n",
      "\u001b[34m67%|   | 264/396 [00:05<00:02, 51.07it/s]#033[A\u001b[0m\n",
      "\u001b[34m68%|   | 270/396 [00:05<00:02, 50.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m70%|   | 276/396 [00:05<00:02, 50.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m71%|   | 282/396 [00:05<00:02, 51.14it/s]#033[A\u001b[0m\n",
      "\u001b[34m73%|  | 288/396 [00:05<00:02, 51.17it/s]#033[A\u001b[0m\n",
      "\u001b[34m74%|  | 294/396 [00:05<00:01, 51.17it/s]#033[A\u001b[0m\n",
      "\u001b[34m76%|  | 300/396 [00:05<00:01, 51.34it/s]#033[A\u001b[0m\n",
      "\u001b[34m77%|  | 306/396 [00:05<00:01, 51.43it/s]#033[A\u001b[0m\n",
      "\u001b[34m79%|  | 312/396 [00:06<00:01, 51.38it/s]#033[A\u001b[0m\n",
      "\u001b[34m80%|  | 318/396 [00:06<00:01, 51.11it/s]#033[A\u001b[0m\n",
      "\u001b[34m82%| | 324/396 [00:06<00:01, 51.22it/s]#033[A\u001b[0m\n",
      "\u001b[34m83%| | 330/396 [00:06<00:01, 51.40it/s]#033[A\u001b[0m\n",
      "\u001b[34m85%| | 336/396 [00:06<00:01, 51.46it/s]#033[A\u001b[0m\n",
      "\u001b[34m86%| | 342/396 [00:06<00:01, 51.23it/s]#033[A\u001b[0m\n",
      "\u001b[34m88%| | 348/396 [00:06<00:00, 51.17it/s]#033[A\u001b[0m\n",
      "\u001b[34m89%| | 354/396 [00:06<00:00, 51.36it/s]#033[A\u001b[0m\n",
      "\u001b[34m91%| | 360/396 [00:07<00:00, 51.44it/s]#033[A\u001b[0m\n",
      "\u001b[34m92%|| 366/396 [00:07<00:00, 51.35it/s]#033[A\u001b[0m\n",
      "\u001b[34m94%|| 372/396 [00:07<00:00, 51.09it/s]#033[A\u001b[0m\n",
      "\u001b[34m95%|| 378/396 [00:07<00:00, 51.11it/s]#033[A\u001b[0m\n",
      "\u001b[34m97%|| 384/396 [00:07<00:00, 51.25it/s]#033[A\u001b[0m\n",
      "\u001b[34m98%|| 390/396 [00:07<00:00, 39.32it/s]#033[A\u001b[0m\n",
      "\u001b[34m100%|| 396/396 [00:07<00:00, 42.28it/s]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m{'eval_loss': 1.4843401908874512, 'eval_f1': 0.4105688455063857, 'eval_runtime': 9.7212, 'eval_samples_per_second': 651.362, 'eval_steps_per_second': 40.736, 'epoch': 1.0}\u001b[0m\n",
      "\u001b[34m33%|      | 396/1188 [01:24<02:11,  6.00it/s]\u001b[0m\n",
      "\u001b[34m100%|| 396/396 [00:07<00:00, 42.28it/s]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m33%|      | 397/1188 [01:28<53:04,  4.03s/it]\u001b[0m\n",
      "\u001b[34m34%|      | 398/1188 [01:28<37:46,  2.87s/it]\u001b[0m\n",
      "\u001b[34m34%|      | 399/1188 [01:28<27:05,  2.06s/it]\u001b[0m\n",
      "\u001b[34m34%|      | 400/1188 [01:28<19:35,  1.49s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 3.2381, 'grad_norm': 71.17800903320312, 'learning_rate': 3.99e-05, 'epoch': 1.01}\u001b[0m\n",
      "\u001b[34m34%|      | 400/1188 [01:28<19:35,  1.49s/it]\u001b[0m\n",
      "\u001b[34m34%|      | 401/1188 [01:28<14:21,  1.09s/it]\u001b[0m\n",
      "\u001b[34m34%|      | 402/1188 [01:28<10:41,  1.23it/s]\u001b[0m\n",
      "\u001b[34m34%|      | 403/1188 [01:29<08:07,  1.61it/s]\u001b[0m\n",
      "\u001b[34m34%|      | 404/1188 [01:29<06:20,  2.06it/s]\u001b[0m\n",
      "\u001b[34m34%|      | 405/1188 [01:29<05:04,  2.57it/s]\u001b[0m\n",
      "\u001b[34m34%|      | 406/1188 [01:29<04:12,  3.10it/s]\u001b[0m\n",
      "\u001b[34m34%|      | 407/1188 [01:29<03:35,  3.63it/s]\u001b[0m\n",
      "\u001b[34m34%|      | 408/1188 [01:29<03:09,  4.11it/s]\u001b[0m\n",
      "\u001b[34m34%|      | 409/1188 [01:30<02:51,  4.54it/s]\u001b[0m\n",
      "\u001b[34m35%|      | 410/1188 [01:30<02:39,  4.89it/s]\u001b[0m\n",
      "\u001b[34m35%|      | 411/1188 [01:30<02:29,  5.19it/s]\u001b[0m\n",
      "\u001b[34m35%|      | 412/1188 [01:30<02:23,  5.41it/s]\u001b[0m\n",
      "\u001b[34m35%|      | 413/1188 [01:30<02:20,  5.53it/s]\u001b[0m\n",
      "\u001b[34m35%|      | 414/1188 [01:30<02:16,  5.66it/s]\u001b[0m\n",
      "\u001b[34m35%|      | 415/1188 [01:31<02:14,  5.77it/s]\u001b[0m\n",
      "\u001b[34m35%|      | 416/1188 [01:31<02:12,  5.84it/s]\u001b[0m\n",
      "\u001b[34m35%|      | 417/1188 [01:31<02:10,  5.89it/s]\u001b[0m\n",
      "\u001b[34m35%|      | 418/1188 [01:31<02:09,  5.92it/s]\u001b[0m\n",
      "\u001b[34m35%|      | 419/1188 [01:31<02:09,  5.96it/s]\u001b[0m\n",
      "\u001b[34m35%|      | 420/1188 [01:31<02:08,  5.99it/s]\u001b[0m\n",
      "\u001b[34m35%|      | 421/1188 [01:32<02:35,  4.92it/s]\u001b[0m\n",
      "\u001b[34m36%|      | 422/1188 [01:32<02:27,  5.21it/s]\u001b[0m\n",
      "\u001b[34m36%|      | 423/1188 [01:32<02:20,  5.45it/s]\u001b[0m\n",
      "\u001b[34m36%|      | 424/1188 [01:32<02:16,  5.60it/s]\u001b[0m\n",
      "\u001b[34m36%|      | 425/1188 [01:32<02:12,  5.74it/s]\u001b[0m\n",
      "\u001b[34m36%|      | 426/1188 [01:33<02:11,  5.81it/s]\u001b[0m\n",
      "\u001b[34m36%|      | 427/1188 [01:33<02:09,  5.86it/s]\u001b[0m\n",
      "\u001b[34m36%|      | 428/1188 [01:33<02:08,  5.91it/s]\u001b[0m\n",
      "\u001b[34m36%|      | 429/1188 [01:33<02:10,  5.83it/s]\u001b[0m\n",
      "\u001b[34m36%|      | 430/1188 [01:33<02:10,  5.81it/s]\u001b[0m\n",
      "\u001b[34m36%|      | 431/1188 [01:33<02:08,  5.87it/s]\u001b[0m\n",
      "\u001b[34m36%|      | 432/1188 [01:34<02:08,  5.90it/s]\u001b[0m\n",
      "\u001b[34m36%|      | 433/1188 [01:34<02:08,  5.89it/s]\u001b[0m\n",
      "\u001b[34m37%|      | 434/1188 [01:34<02:07,  5.90it/s]\u001b[0m\n",
      "\u001b[34m37%|      | 435/1188 [01:34<02:07,  5.92it/s]\u001b[0m\n",
      "\u001b[34m37%|      | 436/1188 [01:34<02:07,  5.92it/s]\u001b[0m\n",
      "\u001b[34m37%|      | 437/1188 [01:34<02:07,  5.91it/s]\u001b[0m\n",
      "\u001b[34m37%|      | 438/1188 [01:35<02:06,  5.93it/s]\u001b[0m\n",
      "\u001b[34m37%|      | 439/1188 [01:35<02:07,  5.90it/s]\u001b[0m\n",
      "\u001b[34m37%|      | 440/1188 [01:35<02:06,  5.92it/s]\u001b[0m\n",
      "\u001b[34m37%|      | 441/1188 [01:35<02:06,  5.92it/s]\u001b[0m\n",
      "\u001b[34m37%|      | 442/1188 [01:35<02:06,  5.88it/s]\u001b[0m\n",
      "\u001b[34m37%|      | 443/1188 [01:35<02:06,  5.90it/s]\u001b[0m\n",
      "\u001b[34m37%|      | 444/1188 [01:36<02:05,  5.91it/s]\u001b[0m\n",
      "\u001b[34m37%|      | 445/1188 [01:36<02:05,  5.91it/s]\u001b[0m\n",
      "\u001b[34m38%|      | 446/1188 [01:36<02:05,  5.94it/s]\u001b[0m\n",
      "\u001b[34m38%|      | 447/1188 [01:36<02:04,  5.94it/s]\u001b[0m\n",
      "\u001b[34m38%|      | 448/1188 [01:36<02:04,  5.94it/s]\u001b[0m\n",
      "\u001b[34m38%|      | 449/1188 [01:36<02:04,  5.94it/s]\u001b[0m\n",
      "\u001b[34m38%|      | 450/1188 [01:37<02:04,  5.94it/s]\u001b[0m\n",
      "\u001b[34m{'loss': 2.8034, 'grad_norm': 72.46173858642578, 'learning_rate': 4.49e-05, 'epoch': 1.14}\u001b[0m\n",
      "\u001b[34m38%|      | 450/1188 [01:37<02:04,  5.94it/s]\u001b[0m\n",
      "\u001b[34m38%|      | 451/1188 [01:37<02:04,  5.91it/s]\u001b[0m\n",
      "\u001b[34m38%|      | 452/1188 [01:37<02:03,  5.94it/s]\u001b[0m\n",
      "\u001b[34m38%|      | 453/1188 [01:37<02:03,  5.95it/s]\u001b[0m\n",
      "\u001b[34m38%|      | 454/1188 [01:37<02:03,  5.95it/s]\u001b[0m\n",
      "\u001b[34m38%|      | 455/1188 [01:37<02:02,  5.97it/s]\u001b[0m\n",
      "\u001b[34m38%|      | 456/1188 [01:38<02:02,  5.97it/s]\u001b[0m\n",
      "\u001b[34m38%|      | 457/1188 [01:38<02:02,  5.96it/s]\u001b[0m\n",
      "\u001b[34m39%|      | 458/1188 [01:38<02:02,  5.97it/s]\u001b[0m\n",
      "\u001b[34m39%|      | 459/1188 [01:38<02:02,  5.97it/s]\u001b[0m\n",
      "\u001b[34m39%|      | 460/1188 [01:38<02:01,  5.97it/s]\u001b[0m\n",
      "\u001b[34m39%|      | 461/1188 [01:38<02:01,  5.99it/s]\u001b[0m\n",
      "\u001b[34m39%|      | 462/1188 [01:39<02:01,  5.99it/s]\u001b[0m\n",
      "\u001b[34m39%|      | 463/1188 [01:39<02:01,  5.98it/s]\u001b[0m\n",
      "\u001b[34m39%|      | 464/1188 [01:39<02:00,  6.00it/s]\u001b[0m\n",
      "\u001b[34m39%|      | 465/1188 [01:39<02:00,  6.01it/s]\u001b[0m\n",
      "\u001b[34m39%|      | 466/1188 [01:39<02:00,  6.01it/s]\u001b[0m\n",
      "\u001b[34m39%|      | 467/1188 [01:39<01:59,  6.03it/s]\u001b[0m\n",
      "\u001b[34m39%|      | 468/1188 [01:40<01:59,  6.03it/s]\u001b[0m\n",
      "\u001b[34m39%|      | 469/1188 [01:40<01:59,  6.01it/s]\u001b[0m\n",
      "\u001b[34m40%|      | 470/1188 [01:40<01:58,  6.04it/s]\u001b[0m\n",
      "\u001b[34m40%|      | 471/1188 [01:40<01:58,  6.03it/s]\u001b[0m\n",
      "\u001b[34m40%|      | 472/1188 [01:40<01:59,  5.97it/s]\u001b[0m\n",
      "\u001b[34m40%|      | 473/1188 [01:40<01:59,  5.97it/s]\u001b[0m\n",
      "\u001b[34m40%|      | 474/1188 [01:41<01:59,  5.98it/s]\u001b[0m\n",
      "\u001b[34m40%|      | 475/1188 [01:41<01:59,  5.95it/s]\u001b[0m\n",
      "\u001b[34m40%|      | 476/1188 [01:41<01:59,  5.97it/s]\u001b[0m\n",
      "\u001b[34m40%|      | 477/1188 [01:41<01:58,  6.00it/s]\u001b[0m\n",
      "\u001b[34m40%|      | 478/1188 [01:41<01:57,  6.02it/s]\u001b[0m\n",
      "\u001b[34m40%|      | 479/1188 [01:41<01:57,  6.06it/s]\u001b[0m\n",
      "\u001b[34m40%|      | 480/1188 [01:42<01:57,  6.05it/s]\u001b[0m\n",
      "\u001b[34m40%|      | 481/1188 [01:42<01:57,  6.02it/s]\u001b[0m\n",
      "\u001b[34m41%|      | 482/1188 [01:42<01:56,  6.04it/s]\u001b[0m\n",
      "\u001b[34m41%|      | 483/1188 [01:42<01:56,  6.05it/s]\u001b[0m\n",
      "\u001b[34m41%|      | 484/1188 [01:42<01:56,  6.04it/s]\u001b[0m\n",
      "\u001b[34m41%|      | 485/1188 [01:42<01:56,  6.06it/s]\u001b[0m\n",
      "\u001b[34m41%|      | 486/1188 [01:43<01:56,  6.05it/s]\u001b[0m\n",
      "\u001b[34m41%|      | 487/1188 [01:43<01:55,  6.06it/s]\u001b[0m\n",
      "\u001b[34m41%|      | 488/1188 [01:43<01:56,  6.02it/s]\u001b[0m\n",
      "\u001b[34m41%|      | 489/1188 [01:43<01:55,  6.03it/s]\u001b[0m\n",
      "\u001b[34m41%|      | 490/1188 [01:43<01:55,  6.03it/s]\u001b[0m\n",
      "\u001b[34m41%|     | 491/1188 [01:43<01:55,  6.06it/s]\u001b[0m\n",
      "\u001b[34m41%|     | 492/1188 [01:44<01:55,  6.05it/s]\u001b[0m\n",
      "\u001b[34m41%|     | 493/1188 [01:44<01:54,  6.07it/s]\u001b[0m\n",
      "\u001b[34m42%|     | 494/1188 [01:44<01:54,  6.07it/s]\u001b[0m\n",
      "\u001b[34m42%|     | 495/1188 [01:44<01:54,  6.07it/s]\u001b[0m\n",
      "\u001b[34m42%|     | 496/1188 [01:44<01:54,  6.07it/s]\u001b[0m\n",
      "\u001b[34m42%|     | 497/1188 [01:44<01:54,  6.06it/s]\u001b[0m\n",
      "\u001b[34m42%|     | 498/1188 [01:45<01:54,  6.05it/s]\u001b[0m\n",
      "\u001b[34m42%|     | 499/1188 [01:45<01:53,  6.06it/s]\u001b[0m\n",
      "\u001b[34m42%|     | 500/1188 [01:45<01:53,  6.04it/s]\u001b[0m\n",
      "\u001b[34m{'loss': 2.1096, 'grad_norm': 66.21639251708984, 'learning_rate': 4.99e-05, 'epoch': 1.26}\u001b[0m\n",
      "\u001b[34m42%|     | 500/1188 [01:45<01:53,  6.04it/s]\u001b[0m\n",
      "\u001b[34m42%|     | 501/1188 [01:45<01:53,  6.03it/s]\u001b[0m\n",
      "\u001b[34m42%|     | 502/1188 [01:45<01:54,  5.98it/s]\u001b[0m\n",
      "\u001b[34m42%|     | 503/1188 [01:45<01:53,  6.01it/s]\u001b[0m\n",
      "\u001b[34m42%|     | 504/1188 [01:46<01:53,  6.00it/s]\u001b[0m\n",
      "\u001b[34m43%|     | 505/1188 [01:46<01:53,  6.01it/s]\u001b[0m\n",
      "\u001b[34m43%|     | 506/1188 [01:46<01:53,  6.00it/s]\u001b[0m\n",
      "\u001b[34m43%|     | 507/1188 [01:46<01:53,  6.00it/s]\u001b[0m\n",
      "\u001b[34m43%|     | 508/1188 [01:46<01:52,  6.02it/s]\u001b[0m\n",
      "\u001b[34m43%|     | 509/1188 [01:46<01:52,  6.03it/s]\u001b[0m\n",
      "\u001b[34m43%|     | 510/1188 [01:47<01:52,  6.04it/s]\u001b[0m\n",
      "\u001b[34m43%|     | 511/1188 [01:47<01:52,  6.04it/s]\u001b[0m\n",
      "\u001b[34m43%|     | 512/1188 [01:47<01:51,  6.04it/s]\u001b[0m\n",
      "\u001b[34m43%|     | 513/1188 [01:47<01:51,  6.06it/s]\u001b[0m\n",
      "\u001b[34m43%|     | 514/1188 [01:47<01:51,  6.05it/s]\u001b[0m\n",
      "\u001b[34m43%|     | 515/1188 [01:47<01:51,  6.06it/s]\u001b[0m\n",
      "\u001b[34m43%|     | 516/1188 [01:48<01:51,  6.05it/s]\u001b[0m\n",
      "\u001b[34m44%|     | 517/1188 [01:48<01:50,  6.05it/s]\u001b[0m\n",
      "\u001b[34m44%|     | 518/1188 [01:48<01:51,  6.02it/s]\u001b[0m\n",
      "\u001b[34m44%|     | 519/1188 [01:48<01:51,  6.02it/s]\u001b[0m\n",
      "\u001b[34m44%|     | 520/1188 [01:48<01:51,  6.02it/s]\u001b[0m\n",
      "\u001b[34m44%|     | 521/1188 [01:48<01:51,  6.00it/s]\u001b[0m\n",
      "\u001b[34m44%|     | 522/1188 [01:49<01:50,  6.03it/s]\u001b[0m\n",
      "\u001b[34m44%|     | 523/1188 [01:49<01:50,  6.04it/s]\u001b[0m\n",
      "\u001b[34m44%|     | 524/1188 [01:49<01:50,  6.03it/s]\u001b[0m\n",
      "\u001b[34m44%|     | 525/1188 [01:49<01:49,  6.07it/s]\u001b[0m\n",
      "\u001b[34m44%|     | 526/1188 [01:49<01:49,  6.07it/s]\u001b[0m\n",
      "\u001b[34m44%|     | 527/1188 [01:49<01:48,  6.09it/s]\u001b[0m\n",
      "\u001b[34m44%|     | 528/1188 [01:50<01:48,  6.10it/s]\u001b[0m\n",
      "\u001b[34m45%|     | 529/1188 [01:50<01:48,  6.08it/s]\u001b[0m\n",
      "\u001b[34m45%|     | 530/1188 [01:50<01:48,  6.07it/s]\u001b[0m\n",
      "\u001b[34m45%|     | 531/1188 [01:50<01:48,  6.06it/s]\u001b[0m\n",
      "\u001b[34m45%|     | 532/1188 [01:50<01:50,  5.96it/s]\u001b[0m\n",
      "\u001b[34m45%|     | 533/1188 [01:50<01:49,  5.99it/s]\u001b[0m\n",
      "\u001b[34m45%|     | 534/1188 [01:51<01:49,  6.00it/s]\u001b[0m\n",
      "\u001b[34m45%|     | 535/1188 [01:51<01:48,  6.00it/s]\u001b[0m\n",
      "\u001b[34m45%|     | 536/1188 [01:51<01:48,  6.02it/s]\u001b[0m\n",
      "\u001b[34m45%|     | 537/1188 [01:51<01:48,  6.01it/s]\u001b[0m\n",
      "\u001b[34m45%|     | 538/1188 [01:51<01:47,  6.02it/s]\u001b[0m\n",
      "\u001b[34m45%|     | 539/1188 [01:51<01:47,  6.03it/s]\u001b[0m\n",
      "\u001b[34m45%|     | 540/1188 [01:52<01:47,  6.05it/s]\u001b[0m\n",
      "\u001b[34m46%|     | 541/1188 [01:52<01:47,  6.04it/s]\u001b[0m\n",
      "\u001b[34m46%|     | 542/1188 [01:52<01:47,  6.03it/s]\u001b[0m\n",
      "\u001b[34m46%|     | 543/1188 [01:52<01:47,  6.02it/s]\u001b[0m\n",
      "\u001b[34m46%|     | 544/1188 [01:52<01:48,  5.93it/s]\u001b[0m\n",
      "\u001b[34m46%|     | 545/1188 [01:52<01:47,  5.96it/s]\u001b[0m\n",
      "\u001b[34m46%|     | 546/1188 [01:53<01:47,  5.98it/s]\u001b[0m\n",
      "\u001b[34m46%|     | 547/1188 [01:53<01:46,  6.01it/s]\u001b[0m\n",
      "\u001b[34m46%|     | 548/1188 [01:53<01:46,  6.00it/s]\u001b[0m\n",
      "\u001b[34m46%|     | 549/1188 [01:53<01:45,  6.03it/s]\u001b[0m\n",
      "\u001b[34m46%|     | 550/1188 [01:53<01:46,  6.01it/s]\u001b[0m\n",
      "\u001b[34m{'loss': 1.2966, 'grad_norm': 40.67218017578125, 'learning_rate': 4.64389534883721e-05, 'epoch': 1.39}\u001b[0m\n",
      "\u001b[34m46%|     | 550/1188 [01:53<01:46,  6.01it/s]\u001b[0m\n",
      "\u001b[34m46%|     | 551/1188 [01:53<01:45,  6.03it/s]\u001b[0m\n",
      "\u001b[34m46%|     | 552/1188 [01:54<01:45,  6.05it/s]\u001b[0m\n",
      "\u001b[34m47%|     | 553/1188 [01:54<01:45,  6.04it/s]\u001b[0m\n",
      "\u001b[34m47%|     | 554/1188 [01:54<01:44,  6.04it/s]\u001b[0m\n",
      "\u001b[34m47%|     | 555/1188 [01:54<01:44,  6.04it/s]\u001b[0m\n",
      "\u001b[34m47%|     | 556/1188 [01:54<01:44,  6.04it/s]\u001b[0m\n",
      "\u001b[34m47%|     | 557/1188 [01:54<01:44,  6.04it/s]\u001b[0m\n",
      "\u001b[34m47%|     | 558/1188 [01:55<01:44,  6.05it/s]\u001b[0m\n",
      "\u001b[34m47%|     | 559/1188 [01:55<01:44,  6.04it/s]\u001b[0m\n",
      "\u001b[34m47%|     | 560/1188 [01:55<01:44,  6.03it/s]\u001b[0m\n",
      "\u001b[34m47%|     | 561/1188 [01:55<01:43,  6.05it/s]\u001b[0m\n",
      "\u001b[34m47%|     | 562/1188 [01:55<01:44,  6.00it/s]\u001b[0m\n",
      "\u001b[34m47%|     | 563/1188 [01:55<01:43,  6.03it/s]\u001b[0m\n",
      "\u001b[34m47%|     | 564/1188 [01:56<01:43,  6.03it/s]\u001b[0m\n",
      "\u001b[34m48%|     | 565/1188 [01:56<01:42,  6.06it/s]\u001b[0m\n",
      "\u001b[34m48%|     | 566/1188 [01:56<01:42,  6.07it/s]\u001b[0m\n",
      "\u001b[34m48%|     | 567/1188 [01:56<01:42,  6.05it/s]\u001b[0m\n",
      "\u001b[34m48%|     | 568/1188 [01:56<01:42,  6.05it/s]\u001b[0m\n",
      "\u001b[34m48%|     | 569/1188 [01:56<01:42,  6.04it/s]\u001b[0m\n",
      "\u001b[34m48%|     | 570/1188 [01:57<01:42,  6.04it/s]\u001b[0m\n",
      "\u001b[34m48%|     | 571/1188 [01:57<01:41,  6.05it/s]\u001b[0m\n",
      "\u001b[34m48%|     | 572/1188 [01:57<01:41,  6.06it/s]\u001b[0m\n",
      "\u001b[34m48%|     | 573/1188 [01:57<01:41,  6.05it/s]\u001b[0m\n",
      "\u001b[34m48%|     | 574/1188 [01:57<01:41,  6.06it/s]\u001b[0m\n",
      "\u001b[34m48%|     | 575/1188 [01:57<01:40,  6.07it/s]\u001b[0m\n",
      "\u001b[34m48%|     | 576/1188 [01:58<01:40,  6.08it/s]\u001b[0m\n",
      "\u001b[34m49%|     | 577/1188 [01:58<01:40,  6.09it/s]\u001b[0m\n",
      "\u001b[34m49%|     | 578/1188 [01:58<01:39,  6.11it/s]\u001b[0m\n",
      "\u001b[34m49%|     | 579/1188 [01:58<01:40,  6.07it/s]\u001b[0m\n",
      "\u001b[34m49%|     | 580/1188 [01:58<01:40,  6.05it/s]\u001b[0m\n",
      "\u001b[34m49%|     | 581/1188 [01:58<01:40,  6.05it/s]\u001b[0m\n",
      "\u001b[34m49%|     | 582/1188 [01:59<01:40,  6.04it/s]\u001b[0m\n",
      "\u001b[34m49%|     | 583/1188 [01:59<01:40,  6.03it/s]\u001b[0m\n",
      "\u001b[34m49%|     | 584/1188 [01:59<01:39,  6.04it/s]\u001b[0m\n",
      "\u001b[34m49%|     | 585/1188 [01:59<01:40,  6.02it/s]\u001b[0m\n",
      "\u001b[34m49%|     | 586/1188 [01:59<01:39,  6.03it/s]\u001b[0m\n",
      "\u001b[34m49%|     | 587/1188 [01:59<01:39,  6.04it/s]\u001b[0m\n",
      "\u001b[34m49%|     | 588/1188 [02:00<01:39,  6.03it/s]\u001b[0m\n",
      "\u001b[34m50%|     | 589/1188 [02:00<01:39,  6.04it/s]\u001b[0m\n",
      "\u001b[34m50%|     | 590/1188 [02:00<01:39,  6.03it/s]\u001b[0m\n",
      "\u001b[34m50%|     | 591/1188 [02:00<01:39,  6.02it/s]\u001b[0m\n",
      "\u001b[34m50%|     | 592/1188 [02:00<01:39,  5.97it/s]\u001b[0m\n",
      "\u001b[34m50%|     | 593/1188 [02:00<01:39,  5.97it/s]\u001b[0m\n",
      "\u001b[34m50%|     | 594/1188 [02:01<01:39,  5.99it/s]\u001b[0m\n",
      "\u001b[34m50%|     | 595/1188 [02:01<01:38,  6.02it/s]\u001b[0m\n",
      "\u001b[34m50%|     | 596/1188 [02:01<01:38,  6.03it/s]\u001b[0m\n",
      "\u001b[34m50%|     | 597/1188 [02:01<01:38,  6.01it/s]\u001b[0m\n",
      "\u001b[34m50%|     | 598/1188 [02:01<01:38,  6.02it/s]\u001b[0m\n",
      "\u001b[34m50%|     | 599/1188 [02:01<01:37,  6.02it/s]\u001b[0m\n",
      "\u001b[34m51%|     | 600/1188 [02:02<01:37,  6.04it/s]\u001b[0m\n",
      "\u001b[34m{'loss': 0.8124, 'grad_norm': 30.28183937072754, 'learning_rate': 4.2805232558139535e-05, 'epoch': 1.52}\u001b[0m\n",
      "\u001b[34m51%|     | 600/1188 [02:02<01:37,  6.04it/s]\u001b[0m\n",
      "\u001b[34m51%|     | 601/1188 [02:02<01:37,  6.03it/s]\u001b[0m\n",
      "\u001b[34m51%|     | 602/1188 [02:02<01:37,  6.03it/s]\u001b[0m\n",
      "\u001b[34m51%|     | 603/1188 [02:02<01:37,  6.01it/s]\u001b[0m\n",
      "\u001b[34m51%|     | 604/1188 [02:02<01:36,  6.03it/s]\u001b[0m\n",
      "\u001b[34m51%|     | 605/1188 [02:02<01:36,  6.03it/s]\u001b[0m\n",
      "\u001b[34m51%|     | 606/1188 [02:03<01:36,  6.06it/s]\u001b[0m\n",
      "\u001b[34m51%|     | 607/1188 [02:03<01:36,  6.05it/s]\u001b[0m\n",
      "\u001b[34m51%|     | 608/1188 [02:03<01:35,  6.06it/s]\u001b[0m\n",
      "\u001b[34m51%|    | 609/1188 [02:03<01:36,  6.03it/s]\u001b[0m\n",
      "\u001b[34m51%|    | 610/1188 [02:03<01:35,  6.03it/s]\u001b[0m\n",
      "\u001b[34m51%|    | 611/1188 [02:03<01:36,  6.01it/s]\u001b[0m\n",
      "\u001b[34m52%|    | 612/1188 [02:04<01:35,  6.03it/s]\u001b[0m\n",
      "\u001b[34m52%|    | 613/1188 [02:04<01:35,  6.01it/s]\u001b[0m\n",
      "\u001b[34m52%|    | 614/1188 [02:04<01:35,  6.03it/s]\u001b[0m\n",
      "\u001b[34m52%|    | 615/1188 [02:04<01:35,  5.99it/s]\u001b[0m\n",
      "\u001b[34m52%|    | 616/1188 [02:04<01:35,  6.01it/s]\u001b[0m\n",
      "\u001b[34m52%|    | 617/1188 [02:04<01:34,  6.01it/s]\u001b[0m\n",
      "\u001b[34m52%|    | 618/1188 [02:05<01:34,  6.01it/s]\u001b[0m\n",
      "\u001b[34m52%|    | 619/1188 [02:05<01:34,  6.03it/s]\u001b[0m\n",
      "\u001b[34m52%|    | 620/1188 [02:05<01:34,  6.03it/s]\u001b[0m\n",
      "\u001b[34m52%|    | 621/1188 [02:05<01:33,  6.03it/s]\u001b[0m\n",
      "\u001b[34m52%|    | 622/1188 [02:05<01:34,  6.01it/s]\u001b[0m\n",
      "\u001b[34m52%|    | 623/1188 [02:05<01:34,  5.97it/s]\u001b[0m\n",
      "\u001b[34m53%|    | 624/1188 [02:06<01:33,  6.00it/s]\u001b[0m\n",
      "\u001b[34m53%|    | 625/1188 [02:06<01:33,  6.01it/s]\u001b[0m\n",
      "\u001b[34m53%|    | 626/1188 [02:06<01:33,  6.02it/s]\u001b[0m\n",
      "\u001b[34m53%|    | 627/1188 [02:06<01:33,  6.01it/s]\u001b[0m\n",
      "\u001b[34m53%|    | 628/1188 [02:06<01:33,  6.00it/s]\u001b[0m\n",
      "\u001b[34m53%|    | 629/1188 [02:06<01:33,  6.01it/s]\u001b[0m\n",
      "\u001b[34m53%|    | 630/1188 [02:07<01:32,  6.02it/s]\u001b[0m\n",
      "\u001b[34m53%|    | 631/1188 [02:07<01:32,  6.03it/s]\u001b[0m\n",
      "\u001b[34m53%|    | 632/1188 [02:07<01:32,  6.02it/s]\u001b[0m\n",
      "\u001b[34m53%|    | 633/1188 [02:07<01:31,  6.03it/s]\u001b[0m\n",
      "\u001b[34m53%|    | 634/1188 [02:07<01:32,  6.02it/s]\u001b[0m\n",
      "\u001b[34m53%|    | 635/1188 [02:07<01:31,  6.02it/s]\u001b[0m\n",
      "\u001b[34m54%|    | 636/1188 [02:08<01:31,  6.03it/s]\u001b[0m\n",
      "\u001b[34m54%|    | 637/1188 [02:08<01:31,  6.03it/s]\u001b[0m\n",
      "\u001b[34m54%|    | 638/1188 [02:08<01:31,  6.04it/s]\u001b[0m\n",
      "\u001b[34m54%|    | 639/1188 [02:08<01:31,  6.03it/s]\u001b[0m\n",
      "\u001b[34m54%|    | 640/1188 [02:08<01:31,  6.01it/s]\u001b[0m\n",
      "\u001b[34m54%|    | 641/1188 [02:08<01:30,  6.02it/s]\u001b[0m\n",
      "\u001b[34m54%|    | 642/1188 [02:09<01:30,  6.03it/s]\u001b[0m\n",
      "\u001b[34m54%|    | 643/1188 [02:09<01:30,  6.03it/s]\u001b[0m\n",
      "\u001b[34m54%|    | 644/1188 [02:09<01:30,  6.03it/s]\u001b[0m\n",
      "\u001b[34m54%|    | 645/1188 [02:09<01:30,  6.02it/s]\u001b[0m\n",
      "\u001b[34m54%|    | 646/1188 [02:09<01:30,  6.00it/s]\u001b[0m\n",
      "\u001b[34m54%|    | 647/1188 [02:09<01:30,  6.00it/s]\u001b[0m\n",
      "\u001b[34m55%|    | 648/1188 [02:10<01:29,  6.04it/s]\u001b[0m\n",
      "\u001b[34m55%|    | 649/1188 [02:10<01:28,  6.06it/s]\u001b[0m\n",
      "\u001b[34m55%|    | 650/1188 [02:10<01:29,  6.04it/s]\u001b[0m\n",
      "\u001b[34m{'loss': 0.4798, 'grad_norm': 14.025958061218262, 'learning_rate': 3.917151162790697e-05, 'epoch': 1.64}\u001b[0m\n",
      "\u001b[34m55%|    | 650/1188 [02:10<01:29,  6.04it/s]\u001b[0m\n",
      "\u001b[34m55%|    | 651/1188 [02:10<01:28,  6.04it/s]\u001b[0m\n",
      "\u001b[34m55%|    | 652/1188 [02:10<01:28,  6.03it/s]\u001b[0m\n",
      "\u001b[34m55%|    | 653/1188 [02:10<01:29,  5.97it/s]\u001b[0m\n",
      "\u001b[34m55%|    | 654/1188 [02:11<01:29,  6.00it/s]\u001b[0m\n",
      "\u001b[34m55%|    | 655/1188 [02:11<01:29,  5.97it/s]\u001b[0m\n",
      "\u001b[34m55%|    | 656/1188 [02:11<01:28,  6.02it/s]\u001b[0m\n",
      "\u001b[34m55%|    | 657/1188 [02:11<01:28,  6.01it/s]\u001b[0m\n",
      "\u001b[34m55%|    | 658/1188 [02:11<01:28,  6.01it/s]\u001b[0m\n",
      "\u001b[34m55%|    | 659/1188 [02:11<01:27,  6.01it/s]\u001b[0m\n",
      "\u001b[34m56%|    | 660/1188 [02:12<01:27,  6.04it/s]\u001b[0m\n",
      "\u001b[34m56%|    | 661/1188 [02:12<01:26,  6.07it/s]\u001b[0m\n",
      "\u001b[34m56%|    | 662/1188 [02:12<01:26,  6.07it/s]\u001b[0m\n",
      "\u001b[34m56%|    | 663/1188 [02:12<01:26,  6.09it/s]\u001b[0m\n",
      "\u001b[34m56%|    | 664/1188 [02:12<01:26,  6.07it/s]\u001b[0m\n",
      "\u001b[34m56%|    | 665/1188 [02:12<01:26,  6.06it/s]\u001b[0m\n",
      "\u001b[34m56%|    | 666/1188 [02:12<01:26,  6.06it/s]\u001b[0m\n",
      "\u001b[34m56%|    | 667/1188 [02:13<01:26,  6.05it/s]\u001b[0m\n",
      "\u001b[34m56%|    | 668/1188 [02:13<01:25,  6.05it/s]\u001b[0m\n",
      "\u001b[34m56%|    | 669/1188 [02:13<01:25,  6.04it/s]\u001b[0m\n",
      "\u001b[34m56%|    | 670/1188 [02:13<01:25,  6.03it/s]\u001b[0m\n",
      "\u001b[34m56%|    | 671/1188 [02:13<01:29,  5.79it/s]\u001b[0m\n",
      "\u001b[34m57%|    | 672/1188 [02:14<01:29,  5.78it/s]\u001b[0m\n",
      "\u001b[34m57%|    | 673/1188 [02:14<01:28,  5.85it/s]\u001b[0m\n",
      "\u001b[34m57%|    | 674/1188 [02:14<01:26,  5.93it/s]\u001b[0m\n",
      "\u001b[34m57%|    | 675/1188 [02:14<01:25,  5.97it/s]\u001b[0m\n",
      "\u001b[34m57%|    | 676/1188 [02:14<01:25,  5.97it/s]\u001b[0m\n",
      "\u001b[34m57%|    | 677/1188 [02:14<01:25,  6.00it/s]\u001b[0m\n",
      "\u001b[34m57%|    | 678/1188 [02:15<01:24,  6.02it/s]\u001b[0m\n",
      "\u001b[34m57%|    | 679/1188 [02:15<01:24,  6.02it/s]\u001b[0m\n",
      "\u001b[34m57%|    | 680/1188 [02:15<01:24,  6.04it/s]\u001b[0m\n",
      "\u001b[34m57%|    | 681/1188 [02:15<01:23,  6.04it/s]\u001b[0m\n",
      "\u001b[34m57%|    | 682/1188 [02:15<01:24,  6.01it/s]\u001b[0m\n",
      "\u001b[34m57%|    | 683/1188 [02:15<01:24,  5.95it/s]\u001b[0m\n",
      "\u001b[34m58%|    | 684/1188 [02:16<01:24,  5.97it/s]\u001b[0m\n",
      "\u001b[34m58%|    | 685/1188 [02:16<01:24,  5.99it/s]\u001b[0m\n",
      "\u001b[34m58%|    | 686/1188 [02:16<01:23,  6.03it/s]\u001b[0m\n",
      "\u001b[34m58%|    | 687/1188 [02:16<01:23,  6.03it/s]\u001b[0m\n",
      "\u001b[34m58%|    | 688/1188 [02:16<01:23,  6.01it/s]\u001b[0m\n",
      "\u001b[34m58%|    | 689/1188 [02:16<01:22,  6.02it/s]\u001b[0m\n",
      "\u001b[34m58%|    | 690/1188 [02:17<01:22,  6.03it/s]\u001b[0m\n",
      "\u001b[34m58%|    | 691/1188 [02:17<01:22,  6.05it/s]\u001b[0m\n",
      "\u001b[34m58%|    | 692/1188 [02:17<01:21,  6.07it/s]\u001b[0m\n",
      "\u001b[34m58%|    | 693/1188 [02:17<01:21,  6.09it/s]\u001b[0m\n",
      "\u001b[34m58%|    | 694/1188 [02:17<01:21,  6.08it/s]\u001b[0m\n",
      "\u001b[34m59%|    | 695/1188 [02:17<01:21,  6.05it/s]\u001b[0m\n",
      "\u001b[34m59%|    | 696/1188 [02:17<01:21,  6.06it/s]\u001b[0m\n",
      "\u001b[34m59%|    | 697/1188 [02:18<01:21,  6.05it/s]\u001b[0m\n",
      "\u001b[34m59%|    | 698/1188 [02:18<01:21,  6.05it/s]\u001b[0m\n",
      "\u001b[34m59%|    | 699/1188 [02:18<01:20,  6.05it/s]\u001b[0m\n",
      "\u001b[34m59%|    | 700/1188 [02:18<01:21,  6.01it/s]\u001b[0m\n",
      "\u001b[34m{'loss': 0.3553, 'grad_norm': 7.127463340759277, 'learning_rate': 3.5537790697674425e-05, 'epoch': 1.77}\u001b[0m\n",
      "\u001b[34m59%|    | 700/1188 [02:18<01:21,  6.01it/s]\u001b[0m\n",
      "\u001b[34m59%|    | 701/1188 [02:18<01:21,  5.99it/s]\u001b[0m\n",
      "\u001b[34m59%|    | 702/1188 [02:18<01:21,  6.00it/s]\u001b[0m\n",
      "\u001b[34m59%|    | 703/1188 [02:19<01:20,  6.00it/s]\u001b[0m\n",
      "\u001b[34m59%|    | 704/1188 [02:19<01:20,  6.01it/s]\u001b[0m\n",
      "\u001b[34m59%|    | 705/1188 [02:19<01:20,  6.03it/s]\u001b[0m\n",
      "\u001b[34m59%|    | 706/1188 [02:19<01:19,  6.03it/s]\u001b[0m\n",
      "\u001b[34m60%|    | 707/1188 [02:19<01:19,  6.01it/s]\u001b[0m\n",
      "\u001b[34m60%|    | 708/1188 [02:19<01:19,  6.05it/s]\u001b[0m\n",
      "\u001b[34m60%|    | 709/1188 [02:20<01:19,  6.06it/s]\u001b[0m\n",
      "\u001b[34m60%|    | 710/1188 [02:20<01:19,  6.05it/s]\u001b[0m\n",
      "\u001b[34m60%|    | 711/1188 [02:20<01:18,  6.07it/s]\u001b[0m\n",
      "\u001b[34m60%|    | 712/1188 [02:20<01:18,  6.09it/s]\u001b[0m\n",
      "\u001b[34m60%|    | 713/1188 [02:20<01:19,  5.97it/s]\u001b[0m\n",
      "\u001b[34m60%|    | 714/1188 [02:20<01:19,  5.98it/s]\u001b[0m\n",
      "\u001b[34m60%|    | 715/1188 [02:21<01:19,  5.97it/s]\u001b[0m\n",
      "\u001b[34m60%|    | 716/1188 [02:21<01:18,  5.98it/s]\u001b[0m\n",
      "\u001b[34m60%|    | 717/1188 [02:21<01:18,  6.01it/s]\u001b[0m\n",
      "\u001b[34m60%|    | 718/1188 [02:21<01:17,  6.04it/s]\u001b[0m\n",
      "\u001b[34m61%|    | 719/1188 [02:21<01:17,  6.01it/s]\u001b[0m\n",
      "\u001b[34m61%|    | 720/1188 [02:21<01:17,  6.03it/s]\u001b[0m\n",
      "\u001b[34m61%|    | 721/1188 [02:22<01:17,  6.04it/s]\u001b[0m\n",
      "\u001b[34m61%|    | 722/1188 [02:22<01:17,  6.04it/s]\u001b[0m\n",
      "\u001b[34m61%|    | 723/1188 [02:22<01:17,  6.03it/s]\u001b[0m\n",
      "\u001b[34m61%|    | 724/1188 [02:22<01:16,  6.05it/s]\u001b[0m\n",
      "\u001b[34m61%|    | 725/1188 [02:22<01:16,  6.05it/s]\u001b[0m\n",
      "\u001b[34m61%|    | 726/1188 [02:22<01:16,  6.06it/s]\u001b[0m\n",
      "\u001b[34m61%|    | 727/1188 [02:23<01:16,  6.05it/s]\u001b[0m\n",
      "\u001b[34m61%|   | 728/1188 [02:23<01:16,  6.05it/s]\u001b[0m\n",
      "\u001b[34m61%|   | 729/1188 [02:23<01:15,  6.07it/s]\u001b[0m\n",
      "\u001b[34m61%|   | 730/1188 [02:23<01:15,  6.05it/s]\u001b[0m\n",
      "\u001b[34m62%|   | 731/1188 [02:23<01:15,  6.03it/s]\u001b[0m\n",
      "\u001b[34m62%|   | 732/1188 [02:23<01:15,  6.05it/s]\u001b[0m\n",
      "\u001b[34m62%|   | 733/1188 [02:24<01:15,  6.05it/s]\u001b[0m\n",
      "\u001b[34m62%|   | 734/1188 [02:24<01:14,  6.06it/s]\u001b[0m\n",
      "\u001b[34m62%|   | 735/1188 [02:24<01:14,  6.08it/s]\u001b[0m\n",
      "\u001b[34m62%|   | 736/1188 [02:24<01:14,  6.08it/s]\u001b[0m\n",
      "\u001b[34m62%|   | 737/1188 [02:24<01:14,  6.05it/s]\u001b[0m\n",
      "\u001b[34m62%|   | 738/1188 [02:24<01:14,  6.03it/s]\u001b[0m\n",
      "\u001b[34m62%|   | 739/1188 [02:25<01:14,  6.05it/s]\u001b[0m\n",
      "\u001b[34m62%|   | 740/1188 [02:25<01:14,  6.05it/s]\u001b[0m\n",
      "\u001b[34m62%|   | 741/1188 [02:25<01:13,  6.08it/s]\u001b[0m\n",
      "\u001b[34m62%|   | 742/1188 [02:25<01:13,  6.07it/s]\u001b[0m\n",
      "\u001b[34m63%|   | 743/1188 [02:25<01:14,  6.00it/s]\u001b[0m\n",
      "\u001b[34m63%|   | 744/1188 [02:25<01:13,  6.02it/s]\u001b[0m\n",
      "\u001b[34m63%|   | 745/1188 [02:26<01:13,  6.02it/s]\u001b[0m\n",
      "\u001b[34m63%|   | 746/1188 [02:26<01:13,  6.02it/s]\u001b[0m\n",
      "\u001b[34m63%|   | 747/1188 [02:26<01:13,  6.04it/s]\u001b[0m\n",
      "\u001b[34m63%|   | 748/1188 [02:26<01:12,  6.05it/s]\u001b[0m\n",
      "\u001b[34m63%|   | 749/1188 [02:26<01:12,  6.04it/s]\u001b[0m\n",
      "\u001b[34m63%|   | 750/1188 [02:26<01:12,  6.00it/s]\u001b[0m\n",
      "\u001b[34m{'loss': 0.2626, 'grad_norm': 12.195269584655762, 'learning_rate': 3.190406976744186e-05, 'epoch': 1.89}\u001b[0m\n",
      "\u001b[34m63%|   | 750/1188 [02:26<01:12,  6.00it/s]\u001b[0m\n",
      "\u001b[34m63%|   | 751/1188 [02:27<01:13,  5.99it/s]\u001b[0m\n",
      "\u001b[34m63%|   | 752/1188 [02:27<01:12,  6.00it/s]\u001b[0m\n",
      "\u001b[34m63%|   | 753/1188 [02:27<01:12,  6.01it/s]\u001b[0m\n",
      "\u001b[34m63%|   | 754/1188 [02:27<01:11,  6.03it/s]\u001b[0m\n",
      "\u001b[34m64%|   | 755/1188 [02:27<01:12,  6.01it/s]\u001b[0m\n",
      "\u001b[34m64%|   | 756/1188 [02:27<01:11,  6.02it/s]\u001b[0m\n",
      "\u001b[34m64%|   | 757/1188 [02:28<01:11,  6.02it/s]\u001b[0m\n",
      "\u001b[34m64%|   | 758/1188 [02:28<01:11,  6.02it/s]\u001b[0m\n",
      "\u001b[34m64%|   | 759/1188 [02:28<01:11,  6.03it/s]\u001b[0m\n",
      "\u001b[34m64%|   | 760/1188 [02:28<01:11,  6.01it/s]\u001b[0m\n",
      "\u001b[34m64%|   | 761/1188 [02:28<01:11,  6.00it/s]\u001b[0m\n",
      "\u001b[34m64%|   | 762/1188 [02:28<01:10,  6.00it/s]\u001b[0m\n",
      "\u001b[34m64%|   | 763/1188 [02:29<01:10,  6.01it/s]\u001b[0m\n",
      "\u001b[34m64%|   | 764/1188 [02:29<01:10,  6.03it/s]\u001b[0m\n",
      "\u001b[34m64%|   | 765/1188 [02:29<01:10,  6.03it/s]\u001b[0m\n",
      "\u001b[34m64%|   | 766/1188 [02:29<01:10,  6.02it/s]\u001b[0m\n",
      "\u001b[34m65%|   | 767/1188 [02:29<01:10,  6.01it/s]\u001b[0m\n",
      "\u001b[34m65%|   | 768/1188 [02:29<01:10,  5.98it/s]\u001b[0m\n",
      "\u001b[34m65%|   | 769/1188 [02:30<01:09,  5.99it/s]\u001b[0m\n",
      "\u001b[34m65%|   | 770/1188 [02:30<01:09,  6.00it/s]\u001b[0m\n",
      "\u001b[34m65%|   | 771/1188 [02:30<01:09,  6.02it/s]\u001b[0m\n",
      "\u001b[34m65%|   | 772/1188 [02:30<01:08,  6.03it/s]\u001b[0m\n",
      "\u001b[34m65%|   | 773/1188 [02:30<01:09,  5.95it/s]\u001b[0m\n",
      "\u001b[34m65%|   | 774/1188 [02:30<01:09,  5.98it/s]\u001b[0m\n",
      "\u001b[34m65%|   | 775/1188 [02:31<01:09,  5.97it/s]\u001b[0m\n",
      "\u001b[34m65%|   | 776/1188 [02:31<01:08,  5.99it/s]\u001b[0m\n",
      "\u001b[34m65%|   | 777/1188 [02:31<01:08,  6.00it/s]\u001b[0m\n",
      "\u001b[34m65%|   | 778/1188 [02:31<01:08,  6.02it/s]\u001b[0m\n",
      "\u001b[34m66%|   | 779/1188 [02:31<01:07,  6.02it/s]\u001b[0m\n",
      "\u001b[34m66%|   | 780/1188 [02:31<01:07,  6.01it/s]\u001b[0m\n",
      "\u001b[34m66%|   | 781/1188 [02:32<01:07,  6.01it/s]\u001b[0m\n",
      "\u001b[34m66%|   | 782/1188 [02:32<01:07,  6.03it/s]\u001b[0m\n",
      "\u001b[34m66%|   | 783/1188 [02:32<01:07,  6.03it/s]\u001b[0m\n",
      "\u001b[34m66%|   | 784/1188 [02:32<01:06,  6.04it/s]\u001b[0m\n",
      "\u001b[34m66%|   | 785/1188 [02:32<01:06,  6.05it/s]\u001b[0m\n",
      "\u001b[34m66%|   | 786/1188 [02:32<01:06,  6.03it/s]\u001b[0m\n",
      "\u001b[34m66%|   | 787/1188 [02:33<01:06,  6.03it/s]\u001b[0m\n",
      "\u001b[34m66%|   | 788/1188 [02:33<01:06,  6.04it/s]\u001b[0m\n",
      "\u001b[34m66%|   | 789/1188 [02:33<01:05,  6.06it/s]\u001b[0m\n",
      "\u001b[34m66%|   | 790/1188 [02:33<01:05,  6.03it/s]\u001b[0m\n",
      "\u001b[34m67%|   | 791/1188 [02:33<01:05,  6.05it/s]\u001b[0m\n",
      "\u001b[34m67%|   | 792/1188 [02:33<01:05,  6.06it/s]\u001b[0m\n",
      "\u001b[34m0%|          | 0/396 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m2%|         | 7/396 [00:00<00:06, 58.86it/s]#033[A\u001b[0m\n",
      "\u001b[34m3%|         | 13/396 [00:00<00:07, 54.01it/s]#033[A\u001b[0m\n",
      "\u001b[34m5%|         | 19/396 [00:00<00:07, 52.81it/s]#033[A\u001b[0m\n",
      "\u001b[34m6%|         | 25/396 [00:00<00:07, 51.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m8%|         | 31/396 [00:00<00:07, 51.38it/s]#033[A\u001b[0m\n",
      "\u001b[34m9%|         | 37/396 [00:00<00:07, 51.21it/s]#033[A\u001b[0m\n",
      "\u001b[34m11%|         | 43/396 [00:00<00:06, 51.04it/s]#033[A\u001b[0m\n",
      "\u001b[34m12%|        | 49/396 [00:00<00:06, 50.57it/s]#033[A\u001b[0m\n",
      "\u001b[34m14%|        | 55/396 [00:01<00:06, 50.62it/s]#033[A\u001b[0m\n",
      "\u001b[34m15%|        | 61/396 [00:01<00:06, 50.66it/s]#033[A\u001b[0m\n",
      "\u001b[34m17%|        | 67/396 [00:01<00:06, 50.74it/s]#033[A\u001b[0m\n",
      "\u001b[34m18%|        | 73/396 [00:01<00:06, 50.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m20%|        | 79/396 [00:01<00:06, 50.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m21%|       | 85/396 [00:01<00:06, 51.01it/s]#033[A\u001b[0m\n",
      "\u001b[34m23%|       | 91/396 [00:01<00:06, 50.13it/s]#033[A\u001b[0m\n",
      "\u001b[34m24%|       | 97/396 [00:01<00:05, 49.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m26%|       | 103/396 [00:02<00:05, 50.20it/s]#033[A\u001b[0m\n",
      "\u001b[34m28%|       | 109/396 [00:02<00:05, 50.43it/s]#033[A\u001b[0m\n",
      "\u001b[34m29%|       | 115/396 [00:02<00:05, 50.47it/s]#033[A\u001b[0m\n",
      "\u001b[34m31%|       | 121/396 [00:02<00:05, 50.77it/s]#033[A\u001b[0m\n",
      "\u001b[34m32%|      | 127/396 [00:02<00:05, 51.03it/s]#033[A\u001b[0m\n",
      "\u001b[34m34%|      | 133/396 [00:02<00:05, 51.06it/s]#033[A\u001b[0m\n",
      "\u001b[34m35%|      | 139/396 [00:02<00:05, 51.04it/s]#033[A\u001b[0m\n",
      "\u001b[34m37%|      | 145/396 [00:02<00:04, 51.10it/s]#033[A\u001b[0m\n",
      "\u001b[34m38%|      | 151/396 [00:02<00:04, 50.72it/s]#033[A\u001b[0m\n",
      "\u001b[34m40%|      | 157/396 [00:03<00:04, 50.66it/s]#033[A\u001b[0m\n",
      "\u001b[34m41%|      | 163/396 [00:03<00:04, 50.86it/s]#033[A\u001b[0m\n",
      "\u001b[34m43%|     | 169/396 [00:03<00:04, 50.85it/s]#033[A\u001b[0m\n",
      "\u001b[34m44%|     | 175/396 [00:03<00:04, 51.30it/s]#033[A\u001b[0m\n",
      "\u001b[34m46%|     | 181/396 [00:03<00:04, 51.12it/s]#033[A\u001b[0m\n",
      "\u001b[34m47%|     | 187/396 [00:03<00:04, 51.27it/s]#033[A\u001b[0m\n",
      "\u001b[34m49%|     | 193/396 [00:03<00:03, 51.66it/s]#033[A\u001b[0m\n",
      "\u001b[34m50%|     | 199/396 [00:03<00:03, 51.37it/s]#033[A\u001b[0m\n",
      "\u001b[34m52%|    | 205/396 [00:04<00:03, 51.43it/s]#033[A\u001b[0m\n",
      "\u001b[34m53%|    | 211/396 [00:04<00:03, 50.86it/s]#033[A\u001b[0m\n",
      "\u001b[34m55%|    | 217/396 [00:04<00:03, 50.53it/s]#033[A\u001b[0m\n",
      "\u001b[34m56%|    | 223/396 [00:04<00:03, 50.55it/s]#033[A\u001b[0m\n",
      "\u001b[34m58%|    | 229/396 [00:04<00:03, 50.41it/s]#033[A\u001b[0m\n",
      "\u001b[34m59%|    | 235/396 [00:04<00:03, 50.25it/s]#033[A\u001b[0m\n",
      "\u001b[34m61%|    | 241/396 [00:04<00:03, 50.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m62%|   | 247/396 [00:04<00:02, 50.03it/s]#033[A\u001b[0m\n",
      "\u001b[34m64%|   | 253/396 [00:04<00:02, 49.65it/s]#033[A\u001b[0m\n",
      "\u001b[34m65%|   | 258/396 [00:05<00:02, 49.67it/s]#033[A\u001b[0m\n",
      "\u001b[34m67%|   | 264/396 [00:05<00:02, 50.14it/s]#033[A\u001b[0m\n",
      "\u001b[34m68%|   | 270/396 [00:05<00:02, 50.32it/s]#033[A\u001b[0m\n",
      "\u001b[34m70%|   | 276/396 [00:05<00:02, 50.45it/s]#033[A\u001b[0m\n",
      "\u001b[34m71%|   | 282/396 [00:05<00:02, 50.71it/s]#033[A\u001b[0m\n",
      "\u001b[34m73%|  | 288/396 [00:05<00:02, 50.81it/s]#033[A\u001b[0m\n",
      "\u001b[34m74%|  | 294/396 [00:05<00:02, 50.76it/s]#033[A\u001b[0m\n",
      "\u001b[34m76%|  | 300/396 [00:05<00:01, 50.61it/s]#033[A\u001b[0m\n",
      "\u001b[34m77%|  | 306/396 [00:06<00:01, 50.38it/s]#033[A\u001b[0m\n",
      "\u001b[34m79%|  | 312/396 [00:06<00:01, 50.45it/s]#033[A\u001b[0m\n",
      "\u001b[34m80%|  | 318/396 [00:06<00:01, 50.56it/s]#033[A\u001b[0m\n",
      "\u001b[34m82%| | 324/396 [00:06<00:01, 50.62it/s]#033[A\u001b[0m\n",
      "\u001b[34m83%| | 330/396 [00:06<00:01, 50.60it/s]#033[A\u001b[0m\n",
      "\u001b[34m85%| | 336/396 [00:06<00:01, 50.55it/s]#033[A\u001b[0m\n",
      "\u001b[34m86%| | 342/396 [00:06<00:01, 50.45it/s]#033[A\u001b[0m\n",
      "\u001b[34m88%| | 348/396 [00:06<00:00, 50.18it/s]#033[A\u001b[0m\n",
      "\u001b[34m89%| | 354/396 [00:06<00:00, 50.10it/s]#033[A\u001b[0m\n",
      "\u001b[34m91%| | 360/396 [00:07<00:00, 50.52it/s]#033[A\u001b[0m\n",
      "\u001b[34m92%|| 366/396 [00:07<00:00, 51.18it/s]#033[A\u001b[0m\n",
      "\u001b[34m94%|| 372/396 [00:07<00:00, 50.10it/s]#033[A\u001b[0m\n",
      "\u001b[34m95%|| 378/396 [00:07<00:00, 49.84it/s]#033[A\u001b[0m\n",
      "\u001b[34m97%|| 383/396 [00:07<00:00, 49.18it/s]#033[A\u001b[0m\n",
      "\u001b[34m98%|| 388/396 [00:07<00:00, 48.83it/s]#033[A\u001b[0m\n",
      "\u001b[34m99%|| 394/396 [00:07<00:00, 49.49it/s]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.039348334074020386, 'eval_f1': 0.9890430547785337, 'eval_runtime': 7.8532, 'eval_samples_per_second': 806.292, 'eval_steps_per_second': 50.425, 'epoch': 2.0}\u001b[0m\n",
      "\u001b[34m67%|   | 792/1188 [02:41<01:05,  6.06it/s]\u001b[0m\n",
      "\u001b[34m#015100%|| 396/396 [00:07<00:00, 49.49it/s]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m67%|   | 793/1188 [02:45<22:49,  3.47s/it]\u001b[0m\n",
      "\u001b[34m67%|   | 794/1188 [02:45<16:16,  2.48s/it]\u001b[0m\n",
      "\u001b[34m67%|   | 795/1188 [02:45<11:41,  1.79s/it]\u001b[0m\n",
      "\u001b[34m67%|   | 796/1188 [02:45<08:29,  1.30s/it]\u001b[0m\n",
      "\u001b[34m67%|   | 797/1188 [02:45<06:16,  1.04it/s]\u001b[0m\n",
      "\u001b[34m67%|   | 798/1188 [02:45<04:42,  1.38it/s]\u001b[0m\n",
      "\u001b[34m67%|   | 799/1188 [02:46<03:36,  1.80it/s]\u001b[0m\n",
      "\u001b[34m67%|   | 800/1188 [02:46<02:50,  2.28it/s]\u001b[0m\n",
      "\u001b[34m{'loss': 0.2282, 'grad_norm': 22.441360473632812, 'learning_rate': 2.8270348837209304e-05, 'epoch': 2.02}\u001b[0m\n",
      "\u001b[34m67%|   | 800/1188 [02:46<02:50,  2.28it/s]\u001b[0m\n",
      "\u001b[34m67%|   | 801/1188 [02:46<02:18,  2.80it/s]\u001b[0m\n",
      "\u001b[34m68%|   | 802/1188 [02:46<01:55,  3.34it/s]\u001b[0m\n",
      "\u001b[34m68%|   | 803/1188 [02:46<01:39,  3.87it/s]\u001b[0m\n",
      "\u001b[34m68%|   | 804/1188 [02:46<01:28,  4.32it/s]\u001b[0m\n",
      "\u001b[34m68%|   | 805/1188 [02:47<01:20,  4.74it/s]\u001b[0m\n",
      "\u001b[34m68%|   | 806/1188 [02:47<01:15,  5.09it/s]\u001b[0m\n",
      "\u001b[34m68%|   | 807/1188 [02:47<01:11,  5.36it/s]\u001b[0m\n",
      "\u001b[34m68%|   | 808/1188 [02:47<01:08,  5.55it/s]\u001b[0m\n",
      "\u001b[34m68%|   | 809/1188 [02:47<01:06,  5.72it/s]\u001b[0m\n",
      "\u001b[34m68%|   | 810/1188 [02:47<01:05,  5.80it/s]\u001b[0m\n",
      "\u001b[34m68%|   | 811/1188 [02:48<01:04,  5.85it/s]\u001b[0m\n",
      "\u001b[34m68%|   | 812/1188 [02:48<01:03,  5.89it/s]\u001b[0m\n",
      "\u001b[34m68%|   | 813/1188 [02:48<01:03,  5.95it/s]\u001b[0m\n",
      "\u001b[34m69%|   | 814/1188 [02:48<01:02,  6.00it/s]\u001b[0m\n",
      "\u001b[34m69%|   | 815/1188 [02:48<01:01,  6.03it/s]\u001b[0m\n",
      "\u001b[34m69%|   | 816/1188 [02:48<01:01,  6.01it/s]\u001b[0m\n",
      "\u001b[34m69%|   | 817/1188 [02:49<01:01,  5.99it/s]\u001b[0m\n",
      "\u001b[34m69%|   | 818/1188 [02:49<01:01,  5.98it/s]\u001b[0m\n",
      "\u001b[34m69%|   | 819/1188 [02:49<01:01,  6.03it/s]\u001b[0m\n",
      "\u001b[34m69%|   | 820/1188 [02:49<01:00,  6.05it/s]\u001b[0m\n",
      "\u001b[34m69%|   | 821/1188 [02:49<01:24,  4.36it/s]\u001b[0m\n",
      "\u001b[34m69%|   | 822/1188 [02:50<01:16,  4.76it/s]\u001b[0m\n",
      "\u001b[34m69%|   | 823/1188 [02:50<01:11,  5.09it/s]\u001b[0m\n",
      "\u001b[34m69%|   | 824/1188 [02:50<01:07,  5.36it/s]\u001b[0m\n",
      "\u001b[34m69%|   | 825/1188 [02:50<01:05,  5.57it/s]\u001b[0m\n",
      "\u001b[34m70%|   | 826/1188 [02:50<01:03,  5.67it/s]\u001b[0m\n",
      "\u001b[34m70%|   | 827/1188 [02:50<01:04,  5.57it/s]\u001b[0m\n",
      "\u001b[34m70%|   | 828/1188 [02:51<01:03,  5.66it/s]\u001b[0m\n",
      "\u001b[34m70%|   | 829/1188 [02:51<01:02,  5.72it/s]\u001b[0m\n",
      "\u001b[34m70%|   | 830/1188 [02:51<01:01,  5.78it/s]\u001b[0m\n",
      "\u001b[34m70%|   | 831/1188 [02:51<01:01,  5.83it/s]\u001b[0m\n",
      "\u001b[34m70%|   | 832/1188 [02:51<01:00,  5.84it/s]\u001b[0m\n",
      "\u001b[34m70%|   | 833/1188 [02:51<01:00,  5.86it/s]\u001b[0m\n",
      "\u001b[34m70%|   | 834/1188 [02:52<01:00,  5.87it/s]\u001b[0m\n",
      "\u001b[34m70%|   | 835/1188 [02:52<01:00,  5.88it/s]\u001b[0m\n",
      "\u001b[34m70%|   | 836/1188 [02:52<00:59,  5.89it/s]\u001b[0m\n",
      "\u001b[34m70%|   | 837/1188 [02:52<00:59,  5.88it/s]\u001b[0m\n",
      "\u001b[34m71%|   | 838/1188 [02:52<01:00,  5.80it/s]\u001b[0m\n",
      "\u001b[34m71%|   | 839/1188 [02:53<00:59,  5.83it/s]\u001b[0m\n",
      "\u001b[34m71%|   | 840/1188 [02:53<00:59,  5.84it/s]\u001b[0m\n",
      "\u001b[34m71%|   | 841/1188 [02:53<00:58,  5.88it/s]\u001b[0m\n",
      "\u001b[34m71%|   | 842/1188 [02:53<00:58,  5.90it/s]\u001b[0m\n",
      "\u001b[34m71%|   | 843/1188 [02:53<00:58,  5.90it/s]\u001b[0m\n",
      "\u001b[34m71%|   | 844/1188 [02:53<00:58,  5.90it/s]\u001b[0m\n",
      "\u001b[34m71%|   | 845/1188 [02:54<00:58,  5.88it/s]\u001b[0m\n",
      "\u001b[34m71%|   | 846/1188 [02:54<00:57,  5.91it/s]\u001b[0m\n",
      "\u001b[34m71%|  | 847/1188 [02:54<00:57,  5.92it/s]\u001b[0m\n",
      "\u001b[34m71%|  | 848/1188 [02:54<00:57,  5.93it/s]\u001b[0m\n",
      "\u001b[34m71%|  | 849/1188 [02:54<00:57,  5.93it/s]\u001b[0m\n",
      "\u001b[34m72%|  | 850/1188 [02:54<00:56,  5.93it/s]\u001b[0m\n",
      "\u001b[34m{'loss': 0.1822, 'grad_norm': 5.720522880554199, 'learning_rate': 2.4636627906976745e-05, 'epoch': 2.15}\u001b[0m\n",
      "\u001b[34m72%|  | 850/1188 [02:54<00:56,  5.93it/s]\u001b[0m\n",
      "\u001b[34m72%|  | 851/1188 [02:55<00:57,  5.89it/s]\u001b[0m\n",
      "\u001b[34m72%|  | 852/1188 [02:55<00:56,  5.95it/s]\u001b[0m\n",
      "\u001b[34m72%|  | 853/1188 [02:55<00:56,  5.96it/s]\u001b[0m\n",
      "\u001b[34m72%|  | 854/1188 [02:55<00:56,  5.96it/s]\u001b[0m\n",
      "\u001b[34m72%|  | 855/1188 [02:55<00:55,  5.95it/s]\u001b[0m\n",
      "\u001b[34m72%|  | 856/1188 [02:55<00:55,  5.96it/s]\u001b[0m\n",
      "\u001b[34m72%|  | 857/1188 [02:56<00:56,  5.89it/s]\u001b[0m\n",
      "\u001b[34m72%|  | 858/1188 [02:56<00:55,  5.92it/s]\u001b[0m\n",
      "\u001b[34m72%|  | 859/1188 [02:56<00:55,  5.91it/s]\u001b[0m\n",
      "\u001b[34m72%|  | 860/1188 [02:56<00:55,  5.93it/s]\u001b[0m\n",
      "\u001b[34m72%|  | 861/1188 [02:56<00:54,  5.97it/s]\u001b[0m\n",
      "\u001b[34m73%|  | 862/1188 [02:56<00:54,  5.98it/s]\u001b[0m\n",
      "\u001b[34m73%|  | 863/1188 [02:57<00:54,  5.97it/s]\u001b[0m\n",
      "\u001b[34m73%|  | 864/1188 [02:57<00:54,  5.99it/s]\u001b[0m\n",
      "\u001b[34m73%|  | 865/1188 [02:57<00:53,  6.01it/s]\u001b[0m\n",
      "\u001b[34m73%|  | 866/1188 [02:57<00:53,  6.02it/s]\u001b[0m\n",
      "\u001b[34m73%|  | 867/1188 [02:57<00:53,  6.04it/s]\u001b[0m\n",
      "\u001b[34m73%|  | 868/1188 [02:57<00:52,  6.04it/s]\u001b[0m\n",
      "\u001b[34m73%|  | 869/1188 [02:58<00:52,  6.04it/s]\u001b[0m\n",
      "\u001b[34m73%|  | 870/1188 [02:58<00:52,  6.03it/s]\u001b[0m\n",
      "\u001b[34m73%|  | 871/1188 [02:58<00:52,  6.02it/s]\u001b[0m\n",
      "\u001b[34m73%|  | 872/1188 [02:58<00:52,  6.01it/s]\u001b[0m\n",
      "\u001b[34m73%|  | 873/1188 [02:58<00:52,  5.97it/s]\u001b[0m\n",
      "\u001b[34m74%|  | 874/1188 [02:58<00:52,  5.97it/s]\u001b[0m\n",
      "\u001b[34m74%|  | 875/1188 [02:59<00:52,  5.96it/s]\u001b[0m\n",
      "\u001b[34m74%|  | 876/1188 [02:59<00:52,  5.96it/s]\u001b[0m\n",
      "\u001b[34m74%|  | 877/1188 [02:59<00:52,  5.98it/s]\u001b[0m\n",
      "\u001b[34m74%|  | 878/1188 [02:59<00:51,  6.00it/s]\u001b[0m\n",
      "\u001b[34m74%|  | 879/1188 [02:59<00:51,  5.99it/s]\u001b[0m\n",
      "\u001b[34m74%|  | 880/1188 [02:59<00:51,  5.99it/s]\u001b[0m\n",
      "\u001b[34m74%|  | 881/1188 [03:00<00:51,  5.96it/s]\u001b[0m\n",
      "\u001b[34m74%|  | 882/1188 [03:00<00:51,  5.96it/s]\u001b[0m\n",
      "\u001b[34m74%|  | 883/1188 [03:00<00:50,  5.98it/s]\u001b[0m\n",
      "\u001b[34m74%|  | 884/1188 [03:00<00:50,  6.00it/s]\u001b[0m\n",
      "\u001b[34m74%|  | 885/1188 [03:00<00:50,  5.96it/s]\u001b[0m\n",
      "\u001b[34m75%|  | 886/1188 [03:00<00:50,  5.96it/s]\u001b[0m\n",
      "\u001b[34m75%|  | 887/1188 [03:01<00:50,  5.93it/s]\u001b[0m\n",
      "\u001b[34m75%|  | 888/1188 [03:01<00:50,  5.95it/s]\u001b[0m\n",
      "\u001b[34m75%|  | 889/1188 [03:01<00:50,  5.98it/s]\u001b[0m\n",
      "\u001b[34m75%|  | 890/1188 [03:01<00:49,  6.00it/s]\u001b[0m\n",
      "\u001b[34m75%|  | 891/1188 [03:01<00:49,  6.02it/s]\u001b[0m\n",
      "\u001b[34m75%|  | 892/1188 [03:01<00:49,  5.99it/s]\u001b[0m\n",
      "\u001b[34m75%|  | 893/1188 [03:02<00:49,  6.00it/s]\u001b[0m\n",
      "\u001b[34m75%|  | 894/1188 [03:02<00:49,  6.00it/s]\u001b[0m\n",
      "\u001b[34m75%|  | 895/1188 [03:02<00:48,  6.04it/s]\u001b[0m\n",
      "\u001b[34m75%|  | 896/1188 [03:02<00:48,  6.05it/s]\u001b[0m\n",
      "\u001b[34m76%|  | 897/1188 [03:02<00:47,  6.08it/s]\u001b[0m\n",
      "\u001b[34m76%|  | 898/1188 [03:02<00:47,  6.05it/s]\u001b[0m\n",
      "\u001b[34m76%|  | 899/1188 [03:03<00:47,  6.05it/s]\u001b[0m\n",
      "\u001b[34m76%|  | 900/1188 [03:03<00:47,  6.01it/s]\u001b[0m\n",
      "\u001b[34m{'loss': 0.1289, 'grad_norm': 4.090610027313232, 'learning_rate': 2.100290697674419e-05, 'epoch': 2.27}\u001b[0m\n",
      "\u001b[34m76%|  | 900/1188 [03:03<00:47,  6.01it/s]\u001b[0m\n",
      "\u001b[34m76%|  | 901/1188 [03:03<00:47,  6.03it/s]\u001b[0m\n",
      "\u001b[34m76%|  | 902/1188 [03:03<00:47,  6.03it/s]\u001b[0m\n",
      "\u001b[34m76%|  | 903/1188 [03:03<00:47,  6.01it/s]\u001b[0m\n",
      "\u001b[34m76%|  | 904/1188 [03:03<00:47,  6.00it/s]\u001b[0m\n",
      "\u001b[34m76%|  | 905/1188 [03:04<00:47,  6.02it/s]\u001b[0m\n",
      "\u001b[34m76%|  | 906/1188 [03:04<00:46,  6.00it/s]\u001b[0m\n",
      "\u001b[34m76%|  | 907/1188 [03:04<00:46,  6.02it/s]\u001b[0m\n",
      "\u001b[34m76%|  | 908/1188 [03:04<00:46,  6.04it/s]\u001b[0m\n",
      "\u001b[34m77%|  | 909/1188 [03:04<00:46,  6.04it/s]\u001b[0m\n",
      "\u001b[34m77%|  | 910/1188 [03:04<00:46,  6.04it/s]\u001b[0m\n",
      "\u001b[34m77%|  | 911/1188 [03:05<00:45,  6.05it/s]\u001b[0m\n",
      "\u001b[34m77%|  | 912/1188 [03:05<00:45,  6.03it/s]\u001b[0m\n",
      "\u001b[34m77%|  | 913/1188 [03:05<00:45,  6.04it/s]\u001b[0m\n",
      "\u001b[34m77%|  | 914/1188 [03:05<00:45,  6.05it/s]\u001b[0m\n",
      "\u001b[34m77%|  | 915/1188 [03:05<00:45,  6.03it/s]\u001b[0m\n",
      "\u001b[34m77%|  | 916/1188 [03:05<00:45,  6.03it/s]\u001b[0m\n",
      "\u001b[34m77%|  | 917/1188 [03:06<00:44,  6.04it/s]\u001b[0m\n",
      "\u001b[34m77%|  | 918/1188 [03:06<00:45,  5.97it/s]\u001b[0m\n",
      "\u001b[34m77%|  | 919/1188 [03:06<00:44,  6.00it/s]\u001b[0m\n",
      "\u001b[34m77%|  | 920/1188 [03:06<00:44,  6.01it/s]\u001b[0m\n",
      "\u001b[34m78%|  | 921/1188 [03:06<00:44,  6.03it/s]\u001b[0m\n",
      "\u001b[34m78%|  | 922/1188 [03:06<00:43,  6.05it/s]\u001b[0m\n",
      "\u001b[34m78%|  | 923/1188 [03:07<00:43,  6.07it/s]\u001b[0m\n",
      "\u001b[34m78%|  | 924/1188 [03:07<00:43,  6.02it/s]\u001b[0m\n",
      "\u001b[34m78%|  | 925/1188 [03:07<00:43,  6.03it/s]\u001b[0m\n",
      "\u001b[34m78%|  | 926/1188 [03:07<00:43,  6.06it/s]\u001b[0m\n",
      "\u001b[34m78%|  | 927/1188 [03:07<00:42,  6.09it/s]\u001b[0m\n",
      "\u001b[34m78%|  | 928/1188 [03:07<00:43,  6.04it/s]\u001b[0m\n",
      "\u001b[34m78%|  | 929/1188 [03:08<00:42,  6.04it/s]\u001b[0m\n",
      "\u001b[34m78%|  | 930/1188 [03:08<00:43,  6.00it/s]\u001b[0m\n",
      "\u001b[34m78%|  | 931/1188 [03:08<00:42,  6.01it/s]\u001b[0m\n",
      "\u001b[34m78%|  | 932/1188 [03:08<00:42,  6.04it/s]\u001b[0m\n",
      "\u001b[34m79%|  | 933/1188 [03:08<00:42,  6.05it/s]\u001b[0m\n",
      "\u001b[34m79%|  | 934/1188 [03:08<00:41,  6.05it/s]\u001b[0m\n",
      "\u001b[34m79%|  | 935/1188 [03:09<00:41,  6.05it/s]\u001b[0m\n",
      "\u001b[34m79%|  | 936/1188 [03:09<00:41,  6.01it/s]\u001b[0m\n",
      "\u001b[34m79%|  | 937/1188 [03:09<00:41,  6.03it/s]\u001b[0m\n",
      "\u001b[34m79%|  | 938/1188 [03:09<00:41,  6.07it/s]\u001b[0m\n",
      "\u001b[34m79%|  | 939/1188 [03:09<00:40,  6.09it/s]\u001b[0m\n",
      "\u001b[34m79%|  | 940/1188 [03:09<00:40,  6.06it/s]\u001b[0m\n",
      "\u001b[34m79%|  | 941/1188 [03:10<00:40,  6.08it/s]\u001b[0m\n",
      "\u001b[34m79%|  | 942/1188 [03:10<00:40,  6.03it/s]\u001b[0m\n",
      "\u001b[34m79%|  | 943/1188 [03:10<00:40,  6.06it/s]\u001b[0m\n",
      "\u001b[34m79%|  | 944/1188 [03:10<00:40,  6.08it/s]\u001b[0m\n",
      "\u001b[34m80%|  | 945/1188 [03:10<00:39,  6.08it/s]\u001b[0m\n",
      "\u001b[34m80%|  | 946/1188 [03:10<00:40,  5.99it/s]\u001b[0m\n",
      "\u001b[34m80%|  | 947/1188 [03:11<00:40,  6.01it/s]\u001b[0m\n",
      "\u001b[34m80%|  | 948/1188 [03:11<00:40,  5.98it/s]\u001b[0m\n",
      "\u001b[34m80%|  | 949/1188 [03:11<00:39,  5.99it/s]\u001b[0m\n",
      "\u001b[34m80%|  | 950/1188 [03:11<00:39,  6.03it/s]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0985, 'grad_norm': 7.520749092102051, 'learning_rate': 1.7369186046511627e-05, 'epoch': 2.4}\u001b[0m\n",
      "\u001b[34m80%|  | 950/1188 [03:11<00:39,  6.03it/s]\u001b[0m\n",
      "\u001b[34m80%|  | 951/1188 [03:11<00:39,  6.05it/s]\u001b[0m\n",
      "\u001b[34m80%|  | 952/1188 [03:11<00:38,  6.07it/s]\u001b[0m\n",
      "\u001b[34m80%|  | 953/1188 [03:11<00:38,  6.06it/s]\u001b[0m\n",
      "\u001b[34m80%|  | 954/1188 [03:12<00:38,  6.04it/s]\u001b[0m\n",
      "\u001b[34m80%|  | 955/1188 [03:12<00:38,  6.03it/s]\u001b[0m\n",
      "\u001b[34m80%|  | 956/1188 [03:12<00:38,  6.06it/s]\u001b[0m\n",
      "\u001b[34m81%|  | 957/1188 [03:12<00:37,  6.09it/s]\u001b[0m\n",
      "\u001b[34m81%|  | 958/1188 [03:12<00:37,  6.07it/s]\u001b[0m\n",
      "\u001b[34m81%|  | 959/1188 [03:12<00:37,  6.08it/s]\u001b[0m\n",
      "\u001b[34m81%|  | 960/1188 [03:13<00:37,  6.05it/s]\u001b[0m\n",
      "\u001b[34m81%|  | 961/1188 [03:13<00:37,  6.05it/s]\u001b[0m\n",
      "\u001b[34m81%|  | 962/1188 [03:13<00:37,  6.07it/s]\u001b[0m\n",
      "\u001b[34m81%|  | 963/1188 [03:13<00:37,  6.06it/s]\u001b[0m\n",
      "\u001b[34m81%|  | 964/1188 [03:13<00:38,  5.84it/s]\u001b[0m\n",
      "\u001b[34m81%|  | 965/1188 [03:14<00:40,  5.57it/s]\u001b[0m\n",
      "\u001b[34m81%| | 966/1188 [03:14<00:39,  5.64it/s]\u001b[0m\n",
      "\u001b[34m81%| | 967/1188 [03:14<00:38,  5.76it/s]\u001b[0m\n",
      "\u001b[34m81%| | 968/1188 [03:14<00:37,  5.86it/s]\u001b[0m\n",
      "\u001b[34m82%| | 969/1188 [03:14<00:37,  5.90it/s]\u001b[0m\n",
      "\u001b[34m82%| | 970/1188 [03:14<00:36,  5.93it/s]\u001b[0m\n",
      "\u001b[34m82%| | 971/1188 [03:15<00:36,  5.97it/s]\u001b[0m\n",
      "\u001b[34m82%| | 972/1188 [03:15<00:36,  5.98it/s]\u001b[0m\n",
      "\u001b[34m82%| | 973/1188 [03:15<00:35,  6.01it/s]\u001b[0m\n",
      "\u001b[34m82%| | 974/1188 [03:15<00:35,  6.03it/s]\u001b[0m\n",
      "\u001b[34m82%| | 975/1188 [03:15<00:35,  6.01it/s]\u001b[0m\n",
      "\u001b[34m82%| | 976/1188 [03:15<00:35,  6.02it/s]\u001b[0m\n",
      "\u001b[34m82%| | 977/1188 [03:16<00:35,  6.02it/s]\u001b[0m\n",
      "\u001b[34m82%| | 978/1188 [03:16<00:35,  5.96it/s]\u001b[0m\n",
      "\u001b[34m82%| | 979/1188 [03:16<00:35,  5.95it/s]\u001b[0m\n",
      "\u001b[34m82%| | 980/1188 [03:16<00:34,  5.96it/s]\u001b[0m\n",
      "\u001b[34m83%| | 981/1188 [03:16<00:34,  6.00it/s]\u001b[0m\n",
      "\u001b[34m83%| | 982/1188 [03:16<00:34,  6.02it/s]\u001b[0m\n",
      "\u001b[34m83%| | 983/1188 [03:17<00:34,  6.03it/s]\u001b[0m\n",
      "\u001b[34m83%| | 984/1188 [03:17<00:33,  6.01it/s]\u001b[0m\n",
      "\u001b[34m83%| | 985/1188 [03:17<00:33,  6.02it/s]\u001b[0m\n",
      "\u001b[34m83%| | 986/1188 [03:17<00:33,  6.02it/s]\u001b[0m\n",
      "\u001b[34m83%| | 987/1188 [03:17<00:33,  6.02it/s]\u001b[0m\n",
      "\u001b[34m83%| | 988/1188 [03:17<00:33,  6.02it/s]\u001b[0m\n",
      "\u001b[34m83%| | 989/1188 [03:18<00:33,  6.02it/s]\u001b[0m\n",
      "\u001b[34m83%| | 990/1188 [03:18<00:32,  6.01it/s]\u001b[0m\n",
      "\u001b[34m83%| | 991/1188 [03:18<00:32,  6.00it/s]\u001b[0m\n",
      "\u001b[34m84%| | 992/1188 [03:18<00:32,  6.02it/s]\u001b[0m\n",
      "\u001b[34m84%| | 993/1188 [03:18<00:32,  6.03it/s]\u001b[0m\n",
      "\u001b[34m84%| | 994/1188 [03:18<00:32,  6.01it/s]\u001b[0m\n",
      "\u001b[34m84%| | 995/1188 [03:19<00:32,  6.01it/s]\u001b[0m\n",
      "\u001b[34m84%| | 996/1188 [03:19<00:32,  5.98it/s]\u001b[0m\n",
      "\u001b[34m84%| | 997/1188 [03:19<00:32,  5.95it/s]\u001b[0m\n",
      "\u001b[34m84%| | 998/1188 [03:19<00:31,  5.97it/s]\u001b[0m\n",
      "\u001b[34m84%| | 999/1188 [03:19<00:31,  5.99it/s]\u001b[0m\n",
      "\u001b[34m84%| | 1000/1188 [03:19<00:31,  5.98it/s]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0887, 'grad_norm': 8.379691123962402, 'learning_rate': 1.373546511627907e-05, 'epoch': 2.53}\u001b[0m\n",
      "\u001b[34m84%| | 1000/1188 [03:19<00:31,  5.98it/s]\u001b[0m\n",
      "\u001b[34m84%| | 1001/1188 [03:20<00:31,  5.96it/s]\u001b[0m\n",
      "\u001b[34m84%| | 1002/1188 [03:20<00:31,  5.96it/s]\u001b[0m\n",
      "\u001b[34m84%| | 1003/1188 [03:20<00:31,  5.96it/s]\u001b[0m\n",
      "\u001b[34m85%| | 1004/1188 [03:20<00:30,  5.98it/s]\u001b[0m\n",
      "\u001b[34m85%| | 1005/1188 [03:20<00:30,  5.94it/s]\u001b[0m\n",
      "\u001b[34m85%| | 1006/1188 [03:20<00:30,  5.95it/s]\u001b[0m\n",
      "\u001b[34m85%| | 1007/1188 [03:21<00:30,  5.98it/s]\u001b[0m\n",
      "\u001b[34m85%| | 1008/1188 [03:21<00:30,  5.96it/s]\u001b[0m\n",
      "\u001b[34m85%| | 1009/1188 [03:21<00:30,  5.96it/s]\u001b[0m\n",
      "\u001b[34m85%| | 1010/1188 [03:21<00:29,  5.98it/s]\u001b[0m\n",
      "\u001b[34m85%| | 1011/1188 [03:21<00:29,  6.00it/s]\u001b[0m\n",
      "\u001b[34m85%| | 1012/1188 [03:21<00:29,  6.00it/s]\u001b[0m\n",
      "\u001b[34m85%| | 1013/1188 [03:22<00:29,  6.01it/s]\u001b[0m\n",
      "\u001b[34m85%| | 1014/1188 [03:22<00:29,  6.00it/s]\u001b[0m\n",
      "\u001b[34m85%| | 1015/1188 [03:22<00:28,  6.00it/s]\u001b[0m\n",
      "\u001b[34m86%| | 1016/1188 [03:22<00:28,  6.00it/s]\u001b[0m\n",
      "\u001b[34m86%| | 1017/1188 [03:22<00:28,  6.02it/s]\u001b[0m\n",
      "\u001b[34m86%| | 1018/1188 [03:22<00:28,  6.04it/s]\u001b[0m\n",
      "\u001b[34m86%| | 1019/1188 [03:23<00:27,  6.05it/s]\u001b[0m\n",
      "\u001b[34m86%| | 1020/1188 [03:23<00:27,  6.04it/s]\u001b[0m\n",
      "\u001b[34m86%| | 1021/1188 [03:23<00:27,  6.02it/s]\u001b[0m\n",
      "\u001b[34m86%| | 1022/1188 [03:23<00:27,  6.04it/s]\u001b[0m\n",
      "\u001b[34m86%| | 1023/1188 [03:23<00:27,  6.03it/s]\u001b[0m\n",
      "\u001b[34m86%| | 1024/1188 [03:23<00:27,  6.00it/s]\u001b[0m\n",
      "\u001b[34m86%| | 1025/1188 [03:24<00:27,  6.00it/s]\u001b[0m\n",
      "\u001b[34m86%| | 1026/1188 [03:24<00:27,  6.00it/s]\u001b[0m\n",
      "\u001b[34m86%| | 1027/1188 [03:24<00:26,  5.99it/s]\u001b[0m\n",
      "\u001b[34m87%| | 1028/1188 [03:24<00:26,  6.01it/s]\u001b[0m\n",
      "\u001b[34m87%| | 1029/1188 [03:24<00:26,  6.00it/s]\u001b[0m\n",
      "\u001b[34m87%| | 1030/1188 [03:24<00:26,  6.01it/s]\u001b[0m\n",
      "\u001b[34m87%| | 1031/1188 [03:25<00:26,  6.02it/s]\u001b[0m\n",
      "\u001b[34m87%| | 1032/1188 [03:25<00:25,  6.02it/s]\u001b[0m\n",
      "\u001b[34m87%| | 1033/1188 [03:25<00:25,  6.01it/s]\u001b[0m\n",
      "\u001b[34m87%| | 1034/1188 [03:25<00:25,  6.06it/s]\u001b[0m\n",
      "\u001b[34m87%| | 1035/1188 [03:25<00:25,  6.08it/s]\u001b[0m\n",
      "\u001b[34m87%| | 1036/1188 [03:25<00:25,  6.05it/s]\u001b[0m\n",
      "\u001b[34m87%| | 1037/1188 [03:26<00:24,  6.06it/s]\u001b[0m\n",
      "\u001b[34m87%| | 1038/1188 [03:26<00:24,  6.01it/s]\u001b[0m\n",
      "\u001b[34m87%| | 1039/1188 [03:26<00:24,  6.01it/s]\u001b[0m\n",
      "\u001b[34m88%| | 1040/1188 [03:26<00:24,  6.01it/s]\u001b[0m\n",
      "\u001b[34m88%| | 1041/1188 [03:26<00:24,  6.03it/s]\u001b[0m\n",
      "\u001b[34m88%| | 1042/1188 [03:26<00:24,  6.03it/s]\u001b[0m\n",
      "\u001b[34m88%| | 1043/1188 [03:27<00:24,  6.02it/s]\u001b[0m\n",
      "\u001b[34m88%| | 1044/1188 [03:27<00:23,  6.01it/s]\u001b[0m\n",
      "\u001b[34m88%| | 1045/1188 [03:27<00:23,  6.00it/s]\u001b[0m\n",
      "\u001b[34m88%| | 1046/1188 [03:27<00:23,  6.00it/s]\u001b[0m\n",
      "\u001b[34m88%| | 1047/1188 [03:27<00:23,  6.03it/s]\u001b[0m\n",
      "\u001b[34m88%| | 1048/1188 [03:27<00:23,  6.04it/s]\u001b[0m\n",
      "\u001b[34m88%| | 1049/1188 [03:28<00:22,  6.06it/s]\u001b[0m\n",
      "\u001b[34m88%| | 1050/1188 [03:28<00:22,  6.05it/s]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0928, 'grad_norm': 3.7408626079559326, 'learning_rate': 1.0101744186046512e-05, 'epoch': 2.65}\u001b[0m\n",
      "\u001b[34m88%| | 1050/1188 [03:28<00:22,  6.05it/s]\u001b[0m\n",
      "\u001b[34m88%| | 1051/1188 [03:28<00:22,  6.01it/s]\u001b[0m\n",
      "\u001b[34m89%| | 1052/1188 [03:28<00:22,  6.03it/s]\u001b[0m\n",
      "\u001b[34m89%| | 1053/1188 [03:28<00:22,  6.03it/s]\u001b[0m\n",
      "\u001b[34m89%| | 1054/1188 [03:28<00:22,  6.00it/s]\u001b[0m\n",
      "\u001b[34m89%| | 1055/1188 [03:29<00:22,  6.01it/s]\u001b[0m\n",
      "\u001b[34m89%| | 1056/1188 [03:29<00:21,  6.00it/s]\u001b[0m\n",
      "\u001b[34m89%| | 1057/1188 [03:29<00:21,  6.01it/s]\u001b[0m\n",
      "\u001b[34m89%| | 1058/1188 [03:29<00:21,  6.02it/s]\u001b[0m\n",
      "\u001b[34m89%| | 1059/1188 [03:29<00:21,  6.07it/s]\u001b[0m\n",
      "\u001b[34m89%| | 1060/1188 [03:29<00:21,  6.06it/s]\u001b[0m\n",
      "\u001b[34m89%| | 1061/1188 [03:29<00:20,  6.06it/s]\u001b[0m\n",
      "\u001b[34m89%| | 1062/1188 [03:30<00:20,  6.06it/s]\u001b[0m\n",
      "\u001b[34m89%| | 1063/1188 [03:30<00:20,  6.03it/s]\u001b[0m\n",
      "\u001b[34m90%| | 1064/1188 [03:30<00:20,  6.02it/s]\u001b[0m\n",
      "\u001b[34m90%| | 1065/1188 [03:30<00:20,  6.02it/s]\u001b[0m\n",
      "\u001b[34m90%| | 1066/1188 [03:30<00:20,  5.99it/s]\u001b[0m\n",
      "\u001b[34m90%| | 1067/1188 [03:30<00:20,  6.01it/s]\u001b[0m\n",
      "\u001b[34m90%| | 1068/1188 [03:31<00:19,  6.01it/s]\u001b[0m\n",
      "\u001b[34m90%| | 1069/1188 [03:31<00:19,  5.99it/s]\u001b[0m\n",
      "\u001b[34m90%| | 1070/1188 [03:31<00:19,  5.99it/s]\u001b[0m\n",
      "\u001b[34m90%| | 1071/1188 [03:31<00:19,  6.01it/s]\u001b[0m\n",
      "\u001b[34m90%| | 1072/1188 [03:31<00:19,  6.01it/s]\u001b[0m\n",
      "\u001b[34m90%| | 1073/1188 [03:31<00:19,  6.01it/s]\u001b[0m\n",
      "\u001b[34m90%| | 1074/1188 [03:32<00:18,  6.04it/s]\u001b[0m\n",
      "\u001b[34m90%| | 1075/1188 [03:32<00:18,  6.04it/s]\u001b[0m\n",
      "\u001b[34m91%| | 1076/1188 [03:32<00:18,  6.04it/s]\u001b[0m\n",
      "\u001b[34m91%| | 1077/1188 [03:32<00:18,  6.04it/s]\u001b[0m\n",
      "\u001b[34m91%| | 1078/1188 [03:32<00:18,  6.05it/s]\u001b[0m\n",
      "\u001b[34m91%| | 1079/1188 [03:32<00:18,  6.04it/s]\u001b[0m\n",
      "\u001b[34m91%| | 1080/1188 [03:33<00:17,  6.03it/s]\u001b[0m\n",
      "\u001b[34m91%| | 1081/1188 [03:33<00:17,  6.04it/s]\u001b[0m\n",
      "\u001b[34m91%| | 1082/1188 [03:33<00:17,  6.03it/s]\u001b[0m\n",
      "\u001b[34m91%| | 1083/1188 [03:33<00:17,  6.04it/s]\u001b[0m\n",
      "\u001b[34m91%| | 1084/1188 [03:33<00:17,  6.03it/s]\u001b[0m\n",
      "\u001b[34m91%|| 1085/1188 [03:33<00:17,  6.05it/s]\u001b[0m\n",
      "\u001b[34m91%|| 1086/1188 [03:34<00:16,  6.03it/s]\u001b[0m\n",
      "\u001b[34m91%|| 1087/1188 [03:34<00:16,  6.04it/s]\u001b[0m\n",
      "\u001b[34m92%|| 1088/1188 [03:34<00:16,  6.02it/s]\u001b[0m\n",
      "\u001b[34m92%|| 1089/1188 [03:34<00:16,  6.04it/s]\u001b[0m\n",
      "\u001b[34m92%|| 1090/1188 [03:34<00:16,  6.02it/s]\u001b[0m\n",
      "\u001b[34m92%|| 1091/1188 [03:34<00:16,  6.04it/s]\u001b[0m\n",
      "\u001b[34m92%|| 1092/1188 [03:35<00:15,  6.05it/s]\u001b[0m\n",
      "\u001b[34m92%|| 1093/1188 [03:35<00:15,  6.04it/s]\u001b[0m\n",
      "\u001b[34m92%|| 1094/1188 [03:35<00:15,  6.03it/s]\u001b[0m\n",
      "\u001b[34m92%|| 1095/1188 [03:35<00:15,  6.04it/s]\u001b[0m\n",
      "\u001b[34m92%|| 1096/1188 [03:35<00:15,  5.98it/s]\u001b[0m\n",
      "\u001b[34m92%|| 1097/1188 [03:35<00:15,  6.00it/s]\u001b[0m\n",
      "\u001b[34m92%|| 1098/1188 [03:36<00:14,  6.01it/s]\u001b[0m\n",
      "\u001b[34m93%|| 1099/1188 [03:36<00:14,  6.00it/s]\u001b[0m\n",
      "\u001b[34m93%|| 1100/1188 [03:36<00:14,  5.99it/s]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0783, 'grad_norm': 5.462686538696289, 'learning_rate': 6.4680232558139545e-06, 'epoch': 2.78}\u001b[0m\n",
      "\u001b[34m93%|| 1100/1188 [03:36<00:14,  5.99it/s]\u001b[0m\n",
      "\u001b[34m93%|| 1101/1188 [03:36<00:14,  5.99it/s]\u001b[0m\n",
      "\u001b[34m93%|| 1102/1188 [03:36<00:14,  6.00it/s]\u001b[0m\n",
      "\u001b[34m93%|| 1103/1188 [03:36<00:14,  6.02it/s]\u001b[0m\n",
      "\u001b[34m93%|| 1104/1188 [03:37<00:13,  6.01it/s]\u001b[0m\n",
      "\u001b[34m93%|| 1105/1188 [03:37<00:13,  5.99it/s]\u001b[0m\n",
      "\u001b[34m93%|| 1106/1188 [03:37<00:13,  5.99it/s]\u001b[0m\n",
      "\u001b[34m93%|| 1107/1188 [03:37<00:13,  6.02it/s]\u001b[0m\n",
      "\u001b[34m93%|| 1108/1188 [03:37<00:13,  6.01it/s]\u001b[0m\n",
      "\u001b[34m93%|| 1109/1188 [03:37<00:13,  6.02it/s]\u001b[0m\n",
      "\u001b[34m93%|| 1110/1188 [03:38<00:12,  6.05it/s]\u001b[0m\n",
      "\u001b[34m94%|| 1111/1188 [03:38<00:12,  6.06it/s]\u001b[0m\n",
      "\u001b[34m94%|| 1112/1188 [03:38<00:12,  6.05it/s]\u001b[0m\n",
      "\u001b[34m94%|| 1113/1188 [03:38<00:12,  6.03it/s]\u001b[0m\n",
      "\u001b[34m94%|| 1114/1188 [03:38<00:12,  6.04it/s]\u001b[0m\n",
      "\u001b[34m94%|| 1115/1188 [03:38<00:12,  6.05it/s]\u001b[0m\n",
      "\u001b[34m94%|| 1116/1188 [03:39<00:11,  6.06it/s]\u001b[0m\n",
      "\u001b[34m94%|| 1117/1188 [03:39<00:11,  6.06it/s]\u001b[0m\n",
      "\u001b[34m94%|| 1118/1188 [03:39<00:11,  6.04it/s]\u001b[0m\n",
      "\u001b[34m94%|| 1119/1188 [03:39<00:11,  6.07it/s]\u001b[0m\n",
      "\u001b[34m94%|| 1120/1188 [03:39<00:11,  6.08it/s]\u001b[0m\n",
      "\u001b[34m94%|| 1121/1188 [03:39<00:11,  6.05it/s]\u001b[0m\n",
      "\u001b[34m94%|| 1122/1188 [03:40<00:10,  6.05it/s]\u001b[0m\n",
      "\u001b[34m95%|| 1123/1188 [03:40<00:10,  6.04it/s]\u001b[0m\n",
      "\u001b[34m95%|| 1124/1188 [03:40<00:10,  6.04it/s]\u001b[0m\n",
      "\u001b[34m95%|| 1125/1188 [03:40<00:10,  6.07it/s]\u001b[0m\n",
      "\u001b[34m95%|| 1126/1188 [03:40<00:10,  6.02it/s]\u001b[0m\n",
      "\u001b[34m95%|| 1127/1188 [03:40<00:10,  6.01it/s]\u001b[0m\n",
      "\u001b[34m95%|| 1128/1188 [03:41<00:09,  6.02it/s]\u001b[0m\n",
      "\u001b[34m95%|| 1129/1188 [03:41<00:09,  5.99it/s]\u001b[0m\n",
      "\u001b[34m95%|| 1130/1188 [03:41<00:09,  5.99it/s]\u001b[0m\n",
      "\u001b[34m95%|| 1131/1188 [03:41<00:09,  6.02it/s]\u001b[0m\n",
      "\u001b[34m95%|| 1132/1188 [03:41<00:09,  6.06it/s]\u001b[0m\n",
      "\u001b[34m95%|| 1133/1188 [03:41<00:09,  6.04it/s]\u001b[0m\n",
      "\u001b[34m95%|| 1134/1188 [03:42<00:08,  6.04it/s]\u001b[0m\n",
      "\u001b[34m96%|| 1135/1188 [03:42<00:08,  6.02it/s]\u001b[0m\n",
      "\u001b[34m96%|| 1136/1188 [03:42<00:08,  6.02it/s]\u001b[0m\n",
      "\u001b[34m96%|| 1137/1188 [03:42<00:08,  6.02it/s]\u001b[0m\n",
      "\u001b[34m96%|| 1138/1188 [03:42<00:08,  6.03it/s]\u001b[0m\n",
      "\u001b[34m96%|| 1139/1188 [03:42<00:08,  6.03it/s]\u001b[0m\n",
      "\u001b[34m96%|| 1140/1188 [03:43<00:07,  6.03it/s]\u001b[0m\n",
      "\u001b[34m96%|| 1141/1188 [03:43<00:07,  6.04it/s]\u001b[0m\n",
      "\u001b[34m96%|| 1142/1188 [03:43<00:07,  6.04it/s]\u001b[0m\n",
      "\u001b[34m96%|| 1143/1188 [03:43<00:07,  6.03it/s]\u001b[0m\n",
      "\u001b[34m96%|| 1144/1188 [03:43<00:07,  6.04it/s]\u001b[0m\n",
      "\u001b[34m96%|| 1145/1188 [03:43<00:07,  6.02it/s]\u001b[0m\n",
      "\u001b[34m96%|| 1146/1188 [03:44<00:07,  6.00it/s]\u001b[0m\n",
      "\u001b[34m97%|| 1147/1188 [03:44<00:06,  5.98it/s]\u001b[0m\n",
      "\u001b[34m97%|| 1148/1188 [03:44<00:06,  5.99it/s]\u001b[0m\n",
      "\u001b[34m97%|| 1149/1188 [03:44<00:06,  6.00it/s]\u001b[0m\n",
      "\u001b[34m97%|| 1150/1188 [03:44<00:06,  6.03it/s]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0771, 'grad_norm': 5.980572700500488, 'learning_rate': 2.8343023255813953e-06, 'epoch': 2.9}\u001b[0m\n",
      "\u001b[34m97%|| 1150/1188 [03:44<00:06,  6.03it/s]\u001b[0m\n",
      "\u001b[34m97%|| 1151/1188 [03:44<00:06,  5.99it/s]\u001b[0m\n",
      "\u001b[34m97%|| 1152/1188 [03:45<00:06,  5.99it/s]\u001b[0m\n",
      "\u001b[34m97%|| 1153/1188 [03:45<00:05,  5.98it/s]\u001b[0m\n",
      "\u001b[34m97%|| 1154/1188 [03:45<00:05,  6.00it/s]\u001b[0m\n",
      "\u001b[34m97%|| 1155/1188 [03:45<00:05,  6.00it/s]\u001b[0m\n",
      "\u001b[34m97%|| 1156/1188 [03:45<00:05,  5.96it/s]\u001b[0m\n",
      "\u001b[34m97%|| 1157/1188 [03:45<00:05,  5.98it/s]\u001b[0m\n",
      "\u001b[34m97%|| 1158/1188 [03:46<00:05,  5.98it/s]\u001b[0m\n",
      "\u001b[34m98%|| 1159/1188 [03:46<00:04,  6.00it/s]\u001b[0m\n",
      "\u001b[34m98%|| 1160/1188 [03:46<00:04,  5.98it/s]\u001b[0m\n",
      "\u001b[34m98%|| 1161/1188 [03:46<00:04,  5.97it/s]\u001b[0m\n",
      "\u001b[34m98%|| 1162/1188 [03:46<00:04,  6.00it/s]\u001b[0m\n",
      "\u001b[34m98%|| 1163/1188 [03:46<00:04,  5.99it/s]\u001b[0m\n",
      "\u001b[34m98%|| 1164/1188 [03:47<00:03,  6.01it/s]\u001b[0m\n",
      "\u001b[34m98%|| 1165/1188 [03:47<00:03,  6.03it/s]\u001b[0m\n",
      "\u001b[34m98%|| 1166/1188 [03:47<00:03,  6.02it/s]\u001b[0m\n",
      "\u001b[34m98%|| 1167/1188 [03:47<00:03,  6.01it/s]\u001b[0m\n",
      "\u001b[34m98%|| 1168/1188 [03:47<00:03,  6.03it/s]\u001b[0m\n",
      "\u001b[34m98%|| 1169/1188 [03:47<00:03,  6.03it/s]\u001b[0m\n",
      "\u001b[34m98%|| 1170/1188 [03:48<00:02,  6.03it/s]\u001b[0m\n",
      "\u001b[34m99%|| 1171/1188 [03:48<00:02,  6.01it/s]\u001b[0m\n",
      "\u001b[34m99%|| 1172/1188 [03:48<00:02,  6.04it/s]\u001b[0m\n",
      "\u001b[34m99%|| 1173/1188 [03:48<00:02,  6.00it/s]\u001b[0m\n",
      "\u001b[34m99%|| 1174/1188 [03:48<00:02,  6.00it/s]\u001b[0m\n",
      "\u001b[34m99%|| 1175/1188 [03:48<00:02,  5.99it/s]\u001b[0m\n",
      "\u001b[34m99%|| 1176/1188 [03:49<00:01,  6.00it/s]\u001b[0m\n",
      "\u001b[34m99%|| 1177/1188 [03:49<00:01,  6.00it/s]\u001b[0m\n",
      "\u001b[34m99%|| 1178/1188 [03:49<00:01,  6.01it/s]\u001b[0m\n",
      "\u001b[34m99%|| 1179/1188 [03:49<00:01,  6.00it/s]\u001b[0m\n",
      "\u001b[34m99%|| 1180/1188 [03:49<00:01,  6.00it/s]\u001b[0m\n",
      "\u001b[34m99%|| 1181/1188 [03:49<00:01,  5.98it/s]\u001b[0m\n",
      "\u001b[34m99%|| 1182/1188 [03:50<00:01,  5.99it/s]\u001b[0m\n",
      "\u001b[34m100%|| 1183/1188 [03:50<00:00,  5.99it/s]\u001b[0m\n",
      "\u001b[34m100%|| 1184/1188 [03:50<00:00,  6.00it/s]\u001b[0m\n",
      "\u001b[34m100%|| 1185/1188 [03:50<00:00,  6.00it/s]\u001b[0m\n",
      "\u001b[34m100%|| 1186/1188 [03:50<00:00,  5.96it/s]\u001b[0m\n",
      "\u001b[34m100%|| 1187/1188 [03:50<00:00,  5.97it/s]\u001b[0m\n",
      "\u001b[34m100%|| 1188/1188 [03:51<00:00,  6.02it/s]\u001b[0m\n",
      "\u001b[34m0%|          | 0/396 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m2%|         | 7/396 [00:00<00:06, 58.88it/s]#033[A\u001b[0m\n",
      "\u001b[34m3%|         | 13/396 [00:00<00:07, 53.89it/s]#033[A\u001b[0m\n",
      "\u001b[34m5%|         | 19/396 [00:00<00:07, 52.83it/s]#033[A\u001b[0m\n",
      "\u001b[34m6%|         | 25/396 [00:00<00:07, 51.66it/s]#033[A\u001b[0m\n",
      "\u001b[34m8%|         | 31/396 [00:00<00:07, 51.51it/s]#033[A\u001b[0m\n",
      "\u001b[34m9%|         | 37/396 [00:00<00:06, 51.41it/s]#033[A\u001b[0m\n",
      "\u001b[34m11%|         | 43/396 [00:00<00:06, 51.19it/s]#033[A\u001b[0m\n",
      "\u001b[34m12%|        | 49/396 [00:00<00:06, 50.83it/s]#033[A\u001b[0m\n",
      "\u001b[34m14%|        | 55/396 [00:01<00:06, 50.85it/s]#033[A\u001b[0m\n",
      "\u001b[34m15%|        | 61/396 [00:01<00:06, 50.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m17%|        | 67/396 [00:01<00:06, 51.04it/s]#033[A\u001b[0m\n",
      "\u001b[34m18%|        | 73/396 [00:01<00:06, 50.89it/s]#033[A\u001b[0m\n",
      "\u001b[34m20%|        | 79/396 [00:01<00:06, 50.32it/s]#033[A\u001b[0m\n",
      "\u001b[34m21%|       | 85/396 [00:01<00:06, 50.18it/s]#033[A\u001b[0m\n",
      "\u001b[34m23%|       | 91/396 [00:01<00:06, 50.41it/s]#033[A\u001b[0m\n",
      "\u001b[34m24%|       | 97/396 [00:01<00:05, 50.66it/s]#033[A\u001b[0m\n",
      "\u001b[34m26%|       | 103/396 [00:02<00:05, 50.75it/s]#033[A\u001b[0m\n",
      "\u001b[34m28%|       | 109/396 [00:02<00:05, 50.80it/s]#033[A\u001b[0m\n",
      "\u001b[34m29%|       | 115/396 [00:02<00:05, 51.09it/s]#033[A\u001b[0m\n",
      "\u001b[34m31%|       | 121/396 [00:02<00:05, 51.37it/s]#033[A\u001b[0m\n",
      "\u001b[34m32%|      | 127/396 [00:02<00:05, 51.29it/s]#033[A\u001b[0m\n",
      "\u001b[34m34%|      | 133/396 [00:02<00:05, 51.39it/s]#033[A\u001b[0m\n",
      "\u001b[34m35%|      | 139/396 [00:02<00:05, 51.37it/s]#033[A\u001b[0m\n",
      "\u001b[34m37%|      | 145/396 [00:02<00:04, 51.39it/s]#033[A\u001b[0m\n",
      "\u001b[34m38%|      | 151/396 [00:02<00:04, 51.46it/s]#033[A\u001b[0m\n",
      "\u001b[34m40%|      | 157/396 [00:03<00:04, 51.43it/s]#033[A\u001b[0m\n",
      "\u001b[34m41%|      | 163/396 [00:03<00:04, 51.71it/s]#033[A\u001b[0m\n",
      "\u001b[34m43%|     | 169/396 [00:03<00:04, 51.58it/s]#033[A\u001b[0m\n",
      "\u001b[34m44%|     | 175/396 [00:03<00:04, 51.38it/s]#033[A\u001b[0m\n",
      "\u001b[34m46%|     | 181/396 [00:03<00:04, 51.35it/s]#033[A\u001b[0m\n",
      "\u001b[34m47%|     | 187/396 [00:03<00:04, 51.27it/s]#033[A\u001b[0m\n",
      "\u001b[34m49%|     | 193/396 [00:03<00:03, 51.49it/s]#033[A\u001b[0m\n",
      "\u001b[34m50%|     | 199/396 [00:03<00:03, 51.44it/s]#033[A\u001b[0m\n",
      "\u001b[34m52%|    | 205/396 [00:03<00:03, 51.43it/s]#033[A\u001b[0m\n",
      "\u001b[34m53%|    | 211/396 [00:04<00:03, 51.30it/s]#033[A\u001b[0m\n",
      "\u001b[34m55%|    | 217/396 [00:04<00:03, 51.59it/s]#033[A\u001b[0m\n",
      "\u001b[34m56%|    | 223/396 [00:04<00:03, 51.79it/s]#033[A\u001b[0m\n",
      "\u001b[34m58%|    | 229/396 [00:04<00:03, 51.60it/s]#033[A\u001b[0m\n",
      "\u001b[34m59%|    | 235/396 [00:04<00:03, 51.21it/s]#033[A\u001b[0m\n",
      "\u001b[34m61%|    | 241/396 [00:04<00:03, 51.31it/s]#033[A\u001b[0m\n",
      "\u001b[34m62%|   | 247/396 [00:04<00:02, 51.81it/s]#033[A\u001b[0m\n",
      "\u001b[34m64%|   | 253/396 [00:04<00:02, 51.50it/s]#033[A\u001b[0m\n",
      "\u001b[34m65%|   | 259/396 [00:05<00:02, 51.44it/s]#033[A\u001b[0m\n",
      "\u001b[34m67%|   | 265/396 [00:05<00:02, 51.50it/s]#033[A\u001b[0m\n",
      "\u001b[34m68%|   | 271/396 [00:05<00:02, 51.22it/s]#033[A\u001b[0m\n",
      "\u001b[34m70%|   | 277/396 [00:05<00:02, 51.35it/s]#033[A\u001b[0m\n",
      "\u001b[34m71%|  | 283/396 [00:05<00:02, 51.16it/s]#033[A\u001b[0m\n",
      "\u001b[34m73%|  | 289/396 [00:05<00:02, 51.34it/s]#033[A\u001b[0m\n",
      "\u001b[34m74%|  | 295/396 [00:05<00:01, 51.47it/s]#033[A\u001b[0m\n",
      "\u001b[34m76%|  | 301/396 [00:05<00:01, 51.27it/s]#033[A\u001b[0m\n",
      "\u001b[34m78%|  | 307/396 [00:05<00:01, 51.14it/s]#033[A\u001b[0m\n",
      "\u001b[34m79%|  | 313/396 [00:06<00:01, 51.14it/s]#033[A\u001b[0m\n",
      "\u001b[34m81%|  | 319/396 [00:06<00:01, 51.22it/s]#033[A\u001b[0m\n",
      "\u001b[34m82%| | 325/396 [00:06<00:01, 51.21it/s]#033[A\u001b[0m\n",
      "\u001b[34m84%| | 331/396 [00:06<00:01, 51.08it/s]#033[A\u001b[0m\n",
      "\u001b[34m85%| | 337/396 [00:06<00:01, 51.13it/s]#033[A\u001b[0m\n",
      "\u001b[34m87%| | 343/396 [00:06<00:01, 51.25it/s]#033[A\u001b[0m\n",
      "\u001b[34m88%| | 349/396 [00:06<00:00, 51.62it/s]#033[A\u001b[0m\n",
      "\u001b[34m90%| | 355/396 [00:06<00:00, 51.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m91%| | 361/396 [00:07<00:00, 52.19it/s]#033[A\u001b[0m\n",
      "\u001b[34m93%|| 367/396 [00:07<00:00, 52.27it/s]#033[A\u001b[0m\n",
      "\u001b[34m94%|| 373/396 [00:07<00:00, 52.32it/s]#033[A\u001b[0m\n",
      "\u001b[34m96%|| 379/396 [00:07<00:00, 52.48it/s]#033[A\u001b[0m\n",
      "\u001b[34m97%|| 385/396 [00:07<00:00, 51.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m99%|| 391/396 [00:07<00:00, 51.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.03887168690562248, 'eval_f1': 0.9905768011387814, 'eval_runtime': 7.7312, 'eval_samples_per_second': 819.019, 'eval_steps_per_second': 51.221, 'epoch': 3.0}\u001b[0m\n",
      "\u001b[34m100%|| 1188/1188 [03:58<00:00,  6.02it/s]\u001b[0m\n",
      "\u001b[34m#015100%|| 396/396 [00:07<00:00, 51.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m{'train_runtime': 241.9417, 'train_samples_per_second': 314.034, 'train_steps_per_second': 4.91, 'train_loss': 1.6992395576403196, 'epoch': 3.0}\u001b[0m\n",
      "\u001b[34m100%|| 1188/1188 [04:01<00:00,  6.02it/s]\u001b[0m\n",
      "\u001b[34m100%|| 1188/1188 [04:01<00:00,  4.91it/s]\u001b[0m\n",
      "\u001b[34m2025-08-04 16:35:49,854 - __main__ - INFO - Training completed!\u001b[0m\n",
      "\u001b[34m0%|          | 0/396 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m2%|         | 7/396 [00:00<00:06, 58.20it/s]\u001b[0m\n",
      "\u001b[34m3%|         | 13/396 [00:00<00:06, 54.99it/s]\u001b[0m\n",
      "\u001b[34m5%|         | 19/396 [00:00<00:07, 53.39it/s]\u001b[0m\n",
      "\u001b[34m6%|         | 25/396 [00:00<00:07, 52.39it/s]\u001b[0m\n",
      "\u001b[34m8%|         | 31/396 [00:00<00:07, 51.92it/s]\u001b[0m\n",
      "\u001b[34m9%|         | 37/396 [00:00<00:06, 51.87it/s]\u001b[0m\n",
      "\u001b[34m11%|         | 43/396 [00:00<00:06, 52.48it/s]\u001b[0m\n",
      "\u001b[34m12%|        | 49/396 [00:00<00:06, 52.77it/s]\u001b[0m\n",
      "\u001b[34m14%|        | 55/396 [00:01<00:06, 53.04it/s]\u001b[0m\n",
      "\u001b[34m15%|        | 61/396 [00:01<00:06, 52.97it/s]\u001b[0m\n",
      "\u001b[34m17%|        | 67/396 [00:01<00:06, 53.01it/s]\u001b[0m\n",
      "\u001b[34m18%|        | 73/396 [00:01<00:06, 53.08it/s]\u001b[0m\n",
      "\u001b[34m20%|        | 79/396 [00:01<00:05, 53.23it/s]\u001b[0m\n",
      "\u001b[34m21%|       | 85/396 [00:01<00:05, 53.23it/s]\u001b[0m\n",
      "\u001b[34m23%|       | 91/396 [00:01<00:05, 52.77it/s]\u001b[0m\n",
      "\u001b[34m24%|       | 97/396 [00:01<00:05, 52.52it/s]\u001b[0m\n",
      "\u001b[34m26%|       | 103/396 [00:01<00:05, 52.80it/s]\u001b[0m\n",
      "\u001b[34m28%|       | 109/396 [00:02<00:05, 52.63it/s]\u001b[0m\n",
      "\u001b[34m29%|       | 115/396 [00:02<00:05, 52.55it/s]\u001b[0m\n",
      "\u001b[34m31%|       | 121/396 [00:02<00:05, 52.48it/s]\u001b[0m\n",
      "\u001b[34m32%|      | 127/396 [00:02<00:05, 52.59it/s]\u001b[0m\n",
      "\u001b[34m34%|      | 133/396 [00:02<00:05, 52.55it/s]\u001b[0m\n",
      "\u001b[34m35%|      | 139/396 [00:02<00:04, 52.55it/s]\u001b[0m\n",
      "\u001b[34m37%|      | 145/396 [00:02<00:04, 52.37it/s]\u001b[0m\n",
      "\u001b[34m38%|      | 151/396 [00:02<00:04, 52.20it/s]\u001b[0m\n",
      "\u001b[34m40%|      | 157/396 [00:02<00:04, 52.11it/s]\u001b[0m\n",
      "\u001b[34m41%|      | 163/396 [00:03<00:04, 52.12it/s]\u001b[0m\n",
      "\u001b[34m43%|     | 169/396 [00:03<00:04, 52.19it/s]\u001b[0m\n",
      "\u001b[34m44%|     | 175/396 [00:03<00:04, 52.19it/s]\u001b[0m\n",
      "\u001b[34m46%|     | 181/396 [00:03<00:04, 52.45it/s]\u001b[0m\n",
      "\u001b[34m47%|     | 187/396 [00:03<00:03, 52.55it/s]\u001b[0m\n",
      "\u001b[34m49%|     | 193/396 [00:03<00:03, 52.48it/s]\u001b[0m\n",
      "\u001b[34m50%|     | 199/396 [00:03<00:03, 51.61it/s]\u001b[0m\n",
      "\u001b[34m52%|    | 205/396 [00:03<00:03, 51.65it/s]\u001b[0m\n",
      "\u001b[34m53%|    | 211/396 [00:04<00:03, 51.85it/s]\u001b[0m\n",
      "\u001b[34m55%|    | 217/396 [00:04<00:03, 51.95it/s]\u001b[0m\n",
      "\u001b[34m56%|    | 223/396 [00:04<00:03, 52.07it/s]\u001b[0m\n",
      "\u001b[34m58%|    | 229/396 [00:04<00:03, 52.06it/s]\u001b[0m\n",
      "\u001b[34m59%|    | 235/396 [00:04<00:03, 52.33it/s]\u001b[0m\n",
      "\u001b[34m61%|    | 241/396 [00:04<00:02, 52.64it/s]\u001b[0m\n",
      "\u001b[34m62%|   | 247/396 [00:04<00:02, 52.52it/s]\u001b[0m\n",
      "\u001b[34m64%|   | 253/396 [00:04<00:02, 52.39it/s]\u001b[0m\n",
      "\u001b[34m65%|   | 259/396 [00:04<00:02, 52.38it/s]\u001b[0m\n",
      "\u001b[34m67%|   | 265/396 [00:05<00:02, 52.43it/s]\u001b[0m\n",
      "\u001b[34m68%|   | 271/396 [00:05<00:02, 52.03it/s]\u001b[0m\n",
      "\u001b[34m70%|   | 277/396 [00:05<00:02, 52.19it/s]\u001b[0m\n",
      "\u001b[34m71%|  | 283/396 [00:05<00:02, 52.45it/s]\u001b[0m\n",
      "\u001b[34m73%|  | 289/396 [00:05<00:02, 52.82it/s]\u001b[0m\n",
      "\u001b[34m74%|  | 295/396 [00:05<00:01, 52.60it/s]\u001b[0m\n",
      "\u001b[34m76%|  | 301/396 [00:05<00:01, 51.46it/s]\u001b[0m\n",
      "\u001b[34m78%|  | 307/396 [00:05<00:01, 51.08it/s]\u001b[0m\n",
      "\u001b[34m79%|  | 313/396 [00:05<00:01, 50.91it/s]\u001b[0m\n",
      "\u001b[34m81%|  | 319/396 [00:06<00:01, 50.94it/s]\u001b[0m\n",
      "\u001b[34m82%| | 325/396 [00:06<00:01, 50.97it/s]\u001b[0m\n",
      "\u001b[34m84%| | 331/396 [00:06<00:01, 50.99it/s]\u001b[0m\n",
      "\u001b[34m85%| | 337/396 [00:06<00:01, 50.80it/s]\u001b[0m\n",
      "\u001b[34m87%| | 343/396 [00:06<00:01, 50.69it/s]\u001b[0m\n",
      "\u001b[34m88%| | 349/396 [00:06<00:00, 50.96it/s]\u001b[0m\n",
      "\u001b[34m90%| | 355/396 [00:06<00:00, 50.83it/s]\u001b[0m\n",
      "\u001b[34m91%| | 361/396 [00:06<00:00, 50.88it/s]\u001b[0m\n",
      "\u001b[34m93%|| 367/396 [00:07<00:00, 51.08it/s]\u001b[0m\n",
      "\u001b[34m94%|| 373/396 [00:07<00:00, 51.21it/s]\u001b[0m\n",
      "\u001b[34m96%|| 379/396 [00:07<00:00, 51.20it/s]\u001b[0m\n",
      "\u001b[34m97%|| 385/396 [00:07<00:00, 51.14it/s]\u001b[0m\n",
      "\u001b[34m99%|| 391/396 [00:07<00:00, 50.79it/s]\u001b[0m\n",
      "\u001b[34mearly stopping required metric_for_best_model, but did not find eval_f1 so early stopping is disabled\u001b[0m\n",
      "\u001b[34mearly stopping required metric_for_best_model, but did not find eval_f1 so early stopping is disabled\u001b[0m\n",
      "\u001b[34m100%|| 396/396 [00:07<00:00, 52.07it/s]\u001b[0m\n",
      "\u001b[34m***** Eval results *****\u001b[0m\n",
      "\u001b[34m2025-08-04 16:36:01,427 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2025-08-04 16:36:01,427 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2025-08-04 16:36:01,428 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2025-08-04 16:36:25 Uploading - Uploading generated training model\n",
      "2025-08-04 16:37:29 Completed - Instances not retained as a result of warmpool resource limits being exceeded\n",
      "Training seconds: 757\n",
      "Billable seconds: 757\n"
     ]
    }
   ],
   "source": [
    "estimator.fit(\n",
    "  {'train': s3_path_train, 'test': s3_path_test}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695d2636-74ac-400c-ad71-75ce529d1490",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "178283e4-137e-4386-aaa2-9669cf94f5d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-04T16:48:06.639390Z",
     "iopub.status.busy": "2025-08-04T16:48:06.639113Z",
     "iopub.status.idle": "2025-08-04T16:48:06.685072Z",
     "shell.execute_reply": "2025-08-04T16:48:06.684337Z",
     "shell.execute_reply.started": "2025-08-04T16:48:06.639371Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-2-207567795090/training-output/Modernbert-training-2025-08-04-16-24-04-240/output/model.tar.gz'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# s3 model artefacts\n",
    "model_data = estimator.latest_training_job.describe()[\"ModelArtifacts\"][\"S3ModelArtifacts\"]\n",
    "model_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c812775-c084-46bb-87c2-2d7ec0330f56",
   "metadata": {},
   "source": [
    "# 3. Deploy the Model for Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c6f939-8e75-4542-91a4-65b9f9ad8c85",
   "metadata": {},
   "source": [
    "## 3.1 Load model Artifacts from S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "02101d83-fc73-43ea-b51f-dd114d2e92ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-04T16:48:54.799324Z",
     "iopub.status.busy": "2025-08-04T16:48:54.799037Z",
     "iopub.status.idle": "2025-08-04T16:48:54.831907Z",
     "shell.execute_reply": "2025-08-04T16:48:54.831157Z",
     "shell.execute_reply.started": "2025-08-04T16:48:54.799304Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import Model\n",
    "from sagemaker.serializers import JSONSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "\n",
    "\n",
    "# model_data = 's3://sagemaker-us-east-2-207567795090/training-output/Modernbert-training-2025-06-27-20-07-05-940/output/model.tar.gz'\n",
    "container = '763104351884.dkr.ecr.us-east-2.amazonaws.com/pytorch-inference:2.6.0-gpu-py312-cu124-ubuntu22.04-sagemaker'\n",
    "\n",
    "# Create model object\n",
    "model = Model(\n",
    "    entry_point=\"inference.py\",\n",
    "    source_dir=\"inference\",\n",
    "    model_data=model_data,\n",
    "    image_uri=container,\n",
    "    role=get_execution_role(),\n",
    "    predictor_cls=None,\n",
    "    env={\n",
    "        'CHECKPOINT_SELECTION': 'latest',  # or 'specific' or 'best'\n",
    "        'MODEL_CHECKPOINT': 'checkpoint-1188',  # used if CHECKPOINT_SELECTION='specific'\n",
    "        # 'SAGEMAKER_MODEL_SERVER_TIMEOUT': '3600',\n",
    "        # 'SAGEMAKER_MODEL_SERVER_WORKERS': '1'\n",
    "    }\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76cab97-d065-4480-90fa-0a7eecbf9fdd",
   "metadata": {},
   "source": [
    "## 3.2 Create Realtime Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f9e6225d-d836-47e7-ac2b-2caec666fe2b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-04T16:48:55.892119Z",
     "iopub.status.busy": "2025-08-04T16:48:55.891327Z",
     "iopub.status.idle": "2025-08-04T16:59:32.636999Z",
     "shell.execute_reply": "2025-08-04T16:59:32.636165Z",
     "shell.execute_reply.started": "2025-08-04T16:48:55.892089Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Repacking model artifact (s3://sagemaker-us-east-2-207567795090/training-output/Modernbert-training-2025-08-04-16-24-04-240/output/model.tar.gz), script artifact (inference), and dependencies ([]) into single tar.gz file located at s3://sagemaker-us-east-2-207567795090/pytorch-inference-2025-08-04-16-48-55-920/model.tar.gz. This may take some time depending on model size...\n",
      "INFO:sagemaker:Creating model with name: pytorch-inference-2025-08-04-16-53-30-116\n",
      "INFO:sagemaker:Creating endpoint-config with name modernBert-intentClassifier\n",
      "INFO:sagemaker:Creating endpoint with name modernBert-intentClassifier\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------!"
     ]
    }
   ],
   "source": [
    "# Deploy the model to a GPU instance\n",
    "predictor = model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type='ml.g5.xlarge',  # GPU instance\n",
    "    endpoint_name='modernBert-intentClassifier',\n",
    "    serializer=JSONSerializer(),\n",
    "    deserializer=JSONDeserializer()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e805429c-65ce-4c38-b907-cc88638a0af3",
   "metadata": {},
   "source": [
    "# 4 Make test predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bad3b9f9-886d-4270-b102-dd03ca188744",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-04T17:02:24.732323Z",
     "iopub.status.busy": "2025-08-04T17:02:24.731931Z",
     "iopub.status.idle": "2025-08-04T17:02:24.737307Z",
     "shell.execute_reply": "2025-08-04T17:02:24.736258Z",
     "shell.execute_reply.started": "2025-08-04T17:02:24.732296Z"
    }
   },
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "from sagemaker import Predictor\n",
    "\n",
    "# Create predictor from endpoint\n",
    "predictor = Predictor(\n",
    "    endpoint_name='modernBert-intentClassifier',\n",
    "    sagemaker_session=sess,\n",
    "    serializer=JSONSerializer(),\n",
    "    deserializer=JSONDeserializer()\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a77f75f0-0653-41d6-a799-b7a25f7a07f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-04T17:02:27.828061Z",
     "iopub.status.busy": "2025-08-04T17:02:27.827565Z",
     "iopub.status.idle": "2025-08-04T17:02:32.065055Z",
     "shell.execute_reply": "2025-08-04T17:02:32.063754Z",
     "shell.execute_reply.started": "2025-08-04T17:02:27.828033Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'predicted_class': 'TIME', 'confidence': 0.9996291399002075}\n"
     ]
    }
   ],
   "source": [
    "# Make prediction\n",
    "prompt = \"what time is my flight ?\"\n",
    "response = predictor.predict({'text': prompt})\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "990eb25b-dcdc-4246-be1b-98c848a561dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-04T17:02:35.491554Z",
     "iopub.status.busy": "2025-08-04T17:02:35.491161Z",
     "iopub.status.idle": "2025-08-04T17:02:35.557993Z",
     "shell.execute_reply": "2025-08-04T17:02:35.557084Z",
     "shell.execute_reply.started": "2025-08-04T17:02:35.491529Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'predicted_class': 'FLIGHT', 'confidence': 0.7404236793518066}\n"
     ]
    }
   ],
   "source": [
    "# Make prediction\n",
    "prompt = \"where is the gate of my flight ?\"\n",
    "response = predictor.predict({'text': prompt})\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a17cff74-e004-4bf0-9ebc-32ab5c9923b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-04T17:02:59.831466Z",
     "iopub.status.busy": "2025-08-04T17:02:59.831190Z",
     "iopub.status.idle": "2025-08-04T17:02:59.891689Z",
     "shell.execute_reply": "2025-08-04T17:02:59.887435Z",
     "shell.execute_reply.started": "2025-08-04T17:02:59.831446Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'predicted_class': 'BAGGAGE', 'confidence': 0.7879071831703186}\n"
     ]
    }
   ],
   "source": [
    "# Make prediction\n",
    "prompt = \"where can i store my bags ?\"\n",
    "response = predictor.predict({'text': prompt})\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6b049b-1a54-4740-9729-1c5e19709918",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c4668fd3-124d-4e26-96ab-2e713d8053c4",
   "metadata": {},
   "source": [
    "# 5 cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7ba6e9-12fb-47a9-b0b2-f29cffecb186",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()\n",
    "predictor.delete_endpoint_config()\n",
    "predictor.delete_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ModernBert",
   "language": "python",
   "name": "modernbert"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
